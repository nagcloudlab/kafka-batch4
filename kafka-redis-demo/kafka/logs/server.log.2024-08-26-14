[2024-08-26 15:17:19,130] INFO Creating topic __transaction_state with configuration {compression.type=uncompressed, cleanup.policy=compact, min.insync.replicas=2, segment.bytes=104857600, unclean.leader.election.enable=false} and initial partition assignment HashMap(0 -> ArrayBuffer(102, 101, 103), 1 -> ArrayBuffer(101, 103, 102), 2 -> ArrayBuffer(103, 102, 101), 3 -> ArrayBuffer(102, 103, 101), 4 -> ArrayBuffer(101, 102, 103), 5 -> ArrayBuffer(103, 101, 102), 6 -> ArrayBuffer(102, 101, 103), 7 -> ArrayBuffer(101, 103, 102), 8 -> ArrayBuffer(103, 102, 101), 9 -> ArrayBuffer(102, 103, 101), 10 -> ArrayBuffer(101, 102, 103), 11 -> ArrayBuffer(103, 101, 102), 12 -> ArrayBuffer(102, 101, 103), 13 -> ArrayBuffer(101, 103, 102), 14 -> ArrayBuffer(103, 102, 101), 15 -> ArrayBuffer(102, 103, 101), 16 -> ArrayBuffer(101, 102, 103), 17 -> ArrayBuffer(103, 101, 102), 18 -> ArrayBuffer(102, 101, 103), 19 -> ArrayBuffer(101, 103, 102), 20 -> ArrayBuffer(103, 102, 101), 21 -> ArrayBuffer(102, 103, 101), 22 -> ArrayBuffer(101, 102, 103), 23 -> ArrayBuffer(103, 101, 102), 24 -> ArrayBuffer(102, 101, 103), 25 -> ArrayBuffer(101, 103, 102), 26 -> ArrayBuffer(103, 102, 101), 27 -> ArrayBuffer(102, 103, 101), 28 -> ArrayBuffer(101, 102, 103), 29 -> ArrayBuffer(103, 101, 102), 30 -> ArrayBuffer(102, 101, 103), 31 -> ArrayBuffer(101, 103, 102), 32 -> ArrayBuffer(103, 102, 101), 33 -> ArrayBuffer(102, 103, 101), 34 -> ArrayBuffer(101, 102, 103), 35 -> ArrayBuffer(103, 101, 102), 36 -> ArrayBuffer(102, 101, 103), 37 -> ArrayBuffer(101, 103, 102), 38 -> ArrayBuffer(103, 102, 101), 39 -> ArrayBuffer(102, 103, 101), 40 -> ArrayBuffer(101, 102, 103), 41 -> ArrayBuffer(103, 101, 102), 42 -> ArrayBuffer(102, 101, 103), 43 -> ArrayBuffer(101, 103, 102), 44 -> ArrayBuffer(103, 102, 101), 45 -> ArrayBuffer(102, 103, 101), 46 -> ArrayBuffer(101, 102, 103), 47 -> ArrayBuffer(103, 101, 102), 48 -> ArrayBuffer(102, 101, 103), 49 -> ArrayBuffer(101, 103, 102)) (kafka.zk.AdminZkClient)
[2024-08-26 15:17:19,576] INFO [ReplicaFetcherManager on broker 102] Removed fetcher for partitions HashSet(__transaction_state-42, __transaction_state-45, __transaction_state-48, __transaction_state-24, __transaction_state-0, __transaction_state-39, __transaction_state-6, __transaction_state-9, __transaction_state-18, __transaction_state-36, __transaction_state-27, __transaction_state-15, __transaction_state-12, __transaction_state-3, __transaction_state-21, __transaction_state-30, __transaction_state-33) (kafka.server.ReplicaFetcherManager)
[2024-08-26 15:17:19,587] INFO [LogLoader partition=__transaction_state-24, dir=/tmp/kafka-logs-102] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-08-26 15:17:19,588] INFO Created log for partition __transaction_state-24 in /tmp/kafka-logs-102/__transaction_state-24 with properties {cleanup.policy=compact, compression.type="uncompressed", min.insync.replicas=2, segment.bytes=104857600, unclean.leader.election.enable=false} (kafka.log.LogManager)
[2024-08-26 15:17:19,589] INFO [Partition __transaction_state-24 broker=102] No checkpointed highwatermark is found for partition __transaction_state-24 (kafka.cluster.Partition)
[2024-08-26 15:17:19,589] INFO [Partition __transaction_state-24 broker=102] Log loaded for partition __transaction_state-24 with initial high watermark 0 (kafka.cluster.Partition)
[2024-08-26 15:17:19,622] INFO [LogLoader partition=__transaction_state-39, dir=/tmp/kafka-logs-102] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-08-26 15:17:19,622] INFO Created log for partition __transaction_state-39 in /tmp/kafka-logs-102/__transaction_state-39 with properties {cleanup.policy=compact, compression.type="uncompressed", min.insync.replicas=2, segment.bytes=104857600, unclean.leader.election.enable=false} (kafka.log.LogManager)
[2024-08-26 15:17:19,623] INFO [Partition __transaction_state-39 broker=102] No checkpointed highwatermark is found for partition __transaction_state-39 (kafka.cluster.Partition)
[2024-08-26 15:17:19,623] INFO [Partition __transaction_state-39 broker=102] Log loaded for partition __transaction_state-39 with initial high watermark 0 (kafka.cluster.Partition)
[2024-08-26 15:17:19,649] INFO [LogLoader partition=__transaction_state-3, dir=/tmp/kafka-logs-102] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-08-26 15:17:19,649] INFO Created log for partition __transaction_state-3 in /tmp/kafka-logs-102/__transaction_state-3 with properties {cleanup.policy=compact, compression.type="uncompressed", min.insync.replicas=2, segment.bytes=104857600, unclean.leader.election.enable=false} (kafka.log.LogManager)
[2024-08-26 15:17:19,650] INFO [Partition __transaction_state-3 broker=102] No checkpointed highwatermark is found for partition __transaction_state-3 (kafka.cluster.Partition)
[2024-08-26 15:17:19,650] INFO [Partition __transaction_state-3 broker=102] Log loaded for partition __transaction_state-3 with initial high watermark 0 (kafka.cluster.Partition)
[2024-08-26 15:17:19,692] INFO [LogLoader partition=__transaction_state-18, dir=/tmp/kafka-logs-102] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-08-26 15:17:19,692] INFO Created log for partition __transaction_state-18 in /tmp/kafka-logs-102/__transaction_state-18 with properties {cleanup.policy=compact, compression.type="uncompressed", min.insync.replicas=2, segment.bytes=104857600, unclean.leader.election.enable=false} (kafka.log.LogManager)
[2024-08-26 15:17:19,693] INFO [Partition __transaction_state-18 broker=102] No checkpointed highwatermark is found for partition __transaction_state-18 (kafka.cluster.Partition)
[2024-08-26 15:17:19,693] INFO [Partition __transaction_state-18 broker=102] Log loaded for partition __transaction_state-18 with initial high watermark 0 (kafka.cluster.Partition)
[2024-08-26 15:17:19,788] INFO [LogLoader partition=__transaction_state-33, dir=/tmp/kafka-logs-102] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-08-26 15:17:19,789] INFO Created log for partition __transaction_state-33 in /tmp/kafka-logs-102/__transaction_state-33 with properties {cleanup.policy=compact, compression.type="uncompressed", min.insync.replicas=2, segment.bytes=104857600, unclean.leader.election.enable=false} (kafka.log.LogManager)
[2024-08-26 15:17:19,789] INFO [Partition __transaction_state-33 broker=102] No checkpointed highwatermark is found for partition __transaction_state-33 (kafka.cluster.Partition)
[2024-08-26 15:17:19,789] INFO [Partition __transaction_state-33 broker=102] Log loaded for partition __transaction_state-33 with initial high watermark 0 (kafka.cluster.Partition)
[2024-08-26 15:17:19,840] INFO [LogLoader partition=__transaction_state-0, dir=/tmp/kafka-logs-102] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-08-26 15:17:19,841] INFO Created log for partition __transaction_state-0 in /tmp/kafka-logs-102/__transaction_state-0 with properties {cleanup.policy=compact, compression.type="uncompressed", min.insync.replicas=2, segment.bytes=104857600, unclean.leader.election.enable=false} (kafka.log.LogManager)
[2024-08-26 15:17:19,841] INFO [Partition __transaction_state-0 broker=102] No checkpointed highwatermark is found for partition __transaction_state-0 (kafka.cluster.Partition)
[2024-08-26 15:17:19,841] INFO [Partition __transaction_state-0 broker=102] Log loaded for partition __transaction_state-0 with initial high watermark 0 (kafka.cluster.Partition)
[2024-08-26 15:17:19,888] INFO [LogLoader partition=__transaction_state-15, dir=/tmp/kafka-logs-102] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-08-26 15:17:19,888] INFO Created log for partition __transaction_state-15 in /tmp/kafka-logs-102/__transaction_state-15 with properties {cleanup.policy=compact, compression.type="uncompressed", min.insync.replicas=2, segment.bytes=104857600, unclean.leader.election.enable=false} (kafka.log.LogManager)
[2024-08-26 15:17:19,894] INFO [Partition __transaction_state-15 broker=102] No checkpointed highwatermark is found for partition __transaction_state-15 (kafka.cluster.Partition)
[2024-08-26 15:17:19,894] INFO [Partition __transaction_state-15 broker=102] Log loaded for partition __transaction_state-15 with initial high watermark 0 (kafka.cluster.Partition)
[2024-08-26 15:17:19,995] INFO [LogLoader partition=__transaction_state-30, dir=/tmp/kafka-logs-102] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-08-26 15:17:19,995] INFO Created log for partition __transaction_state-30 in /tmp/kafka-logs-102/__transaction_state-30 with properties {cleanup.policy=compact, compression.type="uncompressed", min.insync.replicas=2, segment.bytes=104857600, unclean.leader.election.enable=false} (kafka.log.LogManager)
[2024-08-26 15:17:19,995] INFO [Partition __transaction_state-30 broker=102] No checkpointed highwatermark is found for partition __transaction_state-30 (kafka.cluster.Partition)
[2024-08-26 15:17:19,995] INFO [Partition __transaction_state-30 broker=102] Log loaded for partition __transaction_state-30 with initial high watermark 0 (kafka.cluster.Partition)
[2024-08-26 15:17:20,076] INFO [LogLoader partition=__transaction_state-45, dir=/tmp/kafka-logs-102] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-08-26 15:17:20,077] INFO Created log for partition __transaction_state-45 in /tmp/kafka-logs-102/__transaction_state-45 with properties {cleanup.policy=compact, compression.type="uncompressed", min.insync.replicas=2, segment.bytes=104857600, unclean.leader.election.enable=false} (kafka.log.LogManager)
[2024-08-26 15:17:20,077] INFO [Partition __transaction_state-45 broker=102] No checkpointed highwatermark is found for partition __transaction_state-45 (kafka.cluster.Partition)
[2024-08-26 15:17:20,077] INFO [Partition __transaction_state-45 broker=102] Log loaded for partition __transaction_state-45 with initial high watermark 0 (kafka.cluster.Partition)
[2024-08-26 15:17:20,175] INFO [LogLoader partition=__transaction_state-9, dir=/tmp/kafka-logs-102] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-08-26 15:17:20,175] INFO Created log for partition __transaction_state-9 in /tmp/kafka-logs-102/__transaction_state-9 with properties {cleanup.policy=compact, compression.type="uncompressed", min.insync.replicas=2, segment.bytes=104857600, unclean.leader.election.enable=false} (kafka.log.LogManager)
[2024-08-26 15:17:20,175] INFO [Partition __transaction_state-9 broker=102] No checkpointed highwatermark is found for partition __transaction_state-9 (kafka.cluster.Partition)
[2024-08-26 15:17:20,176] INFO [Partition __transaction_state-9 broker=102] Log loaded for partition __transaction_state-9 with initial high watermark 0 (kafka.cluster.Partition)
[2024-08-26 15:17:20,233] INFO [LogLoader partition=__transaction_state-6, dir=/tmp/kafka-logs-102] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-08-26 15:17:20,234] INFO Created log for partition __transaction_state-6 in /tmp/kafka-logs-102/__transaction_state-6 with properties {cleanup.policy=compact, compression.type="uncompressed", min.insync.replicas=2, segment.bytes=104857600, unclean.leader.election.enable=false} (kafka.log.LogManager)
[2024-08-26 15:17:20,234] INFO [Partition __transaction_state-6 broker=102] No checkpointed highwatermark is found for partition __transaction_state-6 (kafka.cluster.Partition)
[2024-08-26 15:17:20,235] INFO [Partition __transaction_state-6 broker=102] Log loaded for partition __transaction_state-6 with initial high watermark 0 (kafka.cluster.Partition)
[2024-08-26 15:17:20,290] INFO [LogLoader partition=__transaction_state-21, dir=/tmp/kafka-logs-102] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-08-26 15:17:20,291] INFO Created log for partition __transaction_state-21 in /tmp/kafka-logs-102/__transaction_state-21 with properties {cleanup.policy=compact, compression.type="uncompressed", min.insync.replicas=2, segment.bytes=104857600, unclean.leader.election.enable=false} (kafka.log.LogManager)
[2024-08-26 15:17:20,291] INFO [Partition __transaction_state-21 broker=102] No checkpointed highwatermark is found for partition __transaction_state-21 (kafka.cluster.Partition)
[2024-08-26 15:17:20,291] INFO [Partition __transaction_state-21 broker=102] Log loaded for partition __transaction_state-21 with initial high watermark 0 (kafka.cluster.Partition)
[2024-08-26 15:17:20,330] INFO [LogLoader partition=__transaction_state-36, dir=/tmp/kafka-logs-102] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-08-26 15:17:20,330] INFO Created log for partition __transaction_state-36 in /tmp/kafka-logs-102/__transaction_state-36 with properties {cleanup.policy=compact, compression.type="uncompressed", min.insync.replicas=2, segment.bytes=104857600, unclean.leader.election.enable=false} (kafka.log.LogManager)
[2024-08-26 15:17:20,330] INFO [Partition __transaction_state-36 broker=102] No checkpointed highwatermark is found for partition __transaction_state-36 (kafka.cluster.Partition)
[2024-08-26 15:17:20,330] INFO [Partition __transaction_state-36 broker=102] Log loaded for partition __transaction_state-36 with initial high watermark 0 (kafka.cluster.Partition)
[2024-08-26 15:17:20,374] INFO [LogLoader partition=__transaction_state-48, dir=/tmp/kafka-logs-102] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-08-26 15:17:20,374] INFO Created log for partition __transaction_state-48 in /tmp/kafka-logs-102/__transaction_state-48 with properties {cleanup.policy=compact, compression.type="uncompressed", min.insync.replicas=2, segment.bytes=104857600, unclean.leader.election.enable=false} (kafka.log.LogManager)
[2024-08-26 15:17:20,375] INFO [Partition __transaction_state-48 broker=102] No checkpointed highwatermark is found for partition __transaction_state-48 (kafka.cluster.Partition)
[2024-08-26 15:17:20,375] INFO [Partition __transaction_state-48 broker=102] Log loaded for partition __transaction_state-48 with initial high watermark 0 (kafka.cluster.Partition)
[2024-08-26 15:17:20,411] INFO [LogLoader partition=__transaction_state-12, dir=/tmp/kafka-logs-102] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-08-26 15:17:20,412] INFO Created log for partition __transaction_state-12 in /tmp/kafka-logs-102/__transaction_state-12 with properties {cleanup.policy=compact, compression.type="uncompressed", min.insync.replicas=2, segment.bytes=104857600, unclean.leader.election.enable=false} (kafka.log.LogManager)
[2024-08-26 15:17:20,413] INFO [Partition __transaction_state-12 broker=102] No checkpointed highwatermark is found for partition __transaction_state-12 (kafka.cluster.Partition)
[2024-08-26 15:17:20,413] INFO [Partition __transaction_state-12 broker=102] Log loaded for partition __transaction_state-12 with initial high watermark 0 (kafka.cluster.Partition)
[2024-08-26 15:17:20,452] INFO [LogLoader partition=__transaction_state-27, dir=/tmp/kafka-logs-102] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-08-26 15:17:20,452] INFO Created log for partition __transaction_state-27 in /tmp/kafka-logs-102/__transaction_state-27 with properties {cleanup.policy=compact, compression.type="uncompressed", min.insync.replicas=2, segment.bytes=104857600, unclean.leader.election.enable=false} (kafka.log.LogManager)
[2024-08-26 15:17:20,452] INFO [Partition __transaction_state-27 broker=102] No checkpointed highwatermark is found for partition __transaction_state-27 (kafka.cluster.Partition)
[2024-08-26 15:17:20,452] INFO [Partition __transaction_state-27 broker=102] Log loaded for partition __transaction_state-27 with initial high watermark 0 (kafka.cluster.Partition)
[2024-08-26 15:17:20,532] INFO [LogLoader partition=__transaction_state-42, dir=/tmp/kafka-logs-102] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-08-26 15:17:20,543] INFO Created log for partition __transaction_state-42 in /tmp/kafka-logs-102/__transaction_state-42 with properties {cleanup.policy=compact, compression.type="uncompressed", min.insync.replicas=2, segment.bytes=104857600, unclean.leader.election.enable=false} (kafka.log.LogManager)
[2024-08-26 15:17:20,546] INFO [Partition __transaction_state-42 broker=102] No checkpointed highwatermark is found for partition __transaction_state-42 (kafka.cluster.Partition)
[2024-08-26 15:17:20,546] INFO [Partition __transaction_state-42 broker=102] Log loaded for partition __transaction_state-42 with initial high watermark 0 (kafka.cluster.Partition)
[2024-08-26 15:17:20,628] INFO [LogLoader partition=__transaction_state-7, dir=/tmp/kafka-logs-102] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-08-26 15:17:20,629] INFO Created log for partition __transaction_state-7 in /tmp/kafka-logs-102/__transaction_state-7 with properties {cleanup.policy=compact, compression.type="uncompressed", min.insync.replicas=2, segment.bytes=104857600, unclean.leader.election.enable=false} (kafka.log.LogManager)
[2024-08-26 15:17:20,629] INFO [Partition __transaction_state-7 broker=102] No checkpointed highwatermark is found for partition __transaction_state-7 (kafka.cluster.Partition)
[2024-08-26 15:17:20,629] INFO [Partition __transaction_state-7 broker=102] Log loaded for partition __transaction_state-7 with initial high watermark 0 (kafka.cluster.Partition)
[2024-08-26 15:17:20,651] INFO [LogLoader partition=__transaction_state-22, dir=/tmp/kafka-logs-102] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-08-26 15:17:20,665] INFO Created log for partition __transaction_state-22 in /tmp/kafka-logs-102/__transaction_state-22 with properties {cleanup.policy=compact, compression.type="uncompressed", min.insync.replicas=2, segment.bytes=104857600, unclean.leader.election.enable=false} (kafka.log.LogManager)
[2024-08-26 15:17:20,665] INFO [Partition __transaction_state-22 broker=102] No checkpointed highwatermark is found for partition __transaction_state-22 (kafka.cluster.Partition)
[2024-08-26 15:17:20,665] INFO [Partition __transaction_state-22 broker=102] Log loaded for partition __transaction_state-22 with initial high watermark 0 (kafka.cluster.Partition)
[2024-08-26 15:17:20,683] INFO [LogLoader partition=__transaction_state-37, dir=/tmp/kafka-logs-102] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-08-26 15:17:20,684] INFO Created log for partition __transaction_state-37 in /tmp/kafka-logs-102/__transaction_state-37 with properties {cleanup.policy=compact, compression.type="uncompressed", min.insync.replicas=2, segment.bytes=104857600, unclean.leader.election.enable=false} (kafka.log.LogManager)
[2024-08-26 15:17:20,684] INFO [Partition __transaction_state-37 broker=102] No checkpointed highwatermark is found for partition __transaction_state-37 (kafka.cluster.Partition)
[2024-08-26 15:17:20,684] INFO [Partition __transaction_state-37 broker=102] Log loaded for partition __transaction_state-37 with initial high watermark 0 (kafka.cluster.Partition)
[2024-08-26 15:17:20,706] INFO [LogLoader partition=__transaction_state-11, dir=/tmp/kafka-logs-102] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-08-26 15:17:20,707] INFO Created log for partition __transaction_state-11 in /tmp/kafka-logs-102/__transaction_state-11 with properties {cleanup.policy=compact, compression.type="uncompressed", min.insync.replicas=2, segment.bytes=104857600, unclean.leader.election.enable=false} (kafka.log.LogManager)
[2024-08-26 15:17:20,707] INFO [Partition __transaction_state-11 broker=102] No checkpointed highwatermark is found for partition __transaction_state-11 (kafka.cluster.Partition)
[2024-08-26 15:17:20,708] INFO [Partition __transaction_state-11 broker=102] Log loaded for partition __transaction_state-11 with initial high watermark 0 (kafka.cluster.Partition)
[2024-08-26 15:17:20,716] INFO [LogLoader partition=__transaction_state-26, dir=/tmp/kafka-logs-102] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-08-26 15:17:20,734] INFO Created log for partition __transaction_state-26 in /tmp/kafka-logs-102/__transaction_state-26 with properties {cleanup.policy=compact, compression.type="uncompressed", min.insync.replicas=2, segment.bytes=104857600, unclean.leader.election.enable=false} (kafka.log.LogManager)
[2024-08-26 15:17:20,734] INFO [Partition __transaction_state-26 broker=102] No checkpointed highwatermark is found for partition __transaction_state-26 (kafka.cluster.Partition)
[2024-08-26 15:17:20,734] INFO [Partition __transaction_state-26 broker=102] Log loaded for partition __transaction_state-26 with initial high watermark 0 (kafka.cluster.Partition)
[2024-08-26 15:17:20,738] INFO [LogLoader partition=__transaction_state-41, dir=/tmp/kafka-logs-102] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-08-26 15:17:20,743] INFO Created log for partition __transaction_state-41 in /tmp/kafka-logs-102/__transaction_state-41 with properties {cleanup.policy=compact, compression.type="uncompressed", min.insync.replicas=2, segment.bytes=104857600, unclean.leader.election.enable=false} (kafka.log.LogManager)
[2024-08-26 15:17:20,744] INFO [Partition __transaction_state-41 broker=102] No checkpointed highwatermark is found for partition __transaction_state-41 (kafka.cluster.Partition)
[2024-08-26 15:17:20,759] INFO [Partition __transaction_state-41 broker=102] Log loaded for partition __transaction_state-41 with initial high watermark 0 (kafka.cluster.Partition)
[2024-08-26 15:17:20,804] INFO [LogLoader partition=__transaction_state-8, dir=/tmp/kafka-logs-102] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-08-26 15:17:20,805] INFO Created log for partition __transaction_state-8 in /tmp/kafka-logs-102/__transaction_state-8 with properties {cleanup.policy=compact, compression.type="uncompressed", min.insync.replicas=2, segment.bytes=104857600, unclean.leader.election.enable=false} (kafka.log.LogManager)
[2024-08-26 15:17:20,805] INFO [Partition __transaction_state-8 broker=102] No checkpointed highwatermark is found for partition __transaction_state-8 (kafka.cluster.Partition)
[2024-08-26 15:17:20,805] INFO [Partition __transaction_state-8 broker=102] Log loaded for partition __transaction_state-8 with initial high watermark 0 (kafka.cluster.Partition)
[2024-08-26 15:17:20,809] INFO [LogLoader partition=__transaction_state-23, dir=/tmp/kafka-logs-102] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-08-26 15:17:20,833] INFO Created log for partition __transaction_state-23 in /tmp/kafka-logs-102/__transaction_state-23 with properties {cleanup.policy=compact, compression.type="uncompressed", min.insync.replicas=2, segment.bytes=104857600, unclean.leader.election.enable=false} (kafka.log.LogManager)
[2024-08-26 15:17:20,833] INFO [Partition __transaction_state-23 broker=102] No checkpointed highwatermark is found for partition __transaction_state-23 (kafka.cluster.Partition)
[2024-08-26 15:17:20,833] INFO [Partition __transaction_state-23 broker=102] Log loaded for partition __transaction_state-23 with initial high watermark 0 (kafka.cluster.Partition)
[2024-08-26 15:17:20,843] INFO [LogLoader partition=__transaction_state-38, dir=/tmp/kafka-logs-102] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-08-26 15:17:20,845] INFO Created log for partition __transaction_state-38 in /tmp/kafka-logs-102/__transaction_state-38 with properties {cleanup.policy=compact, compression.type="uncompressed", min.insync.replicas=2, segment.bytes=104857600, unclean.leader.election.enable=false} (kafka.log.LogManager)
[2024-08-26 15:17:20,857] INFO [Partition __transaction_state-38 broker=102] No checkpointed highwatermark is found for partition __transaction_state-38 (kafka.cluster.Partition)
[2024-08-26 15:17:20,857] INFO [Partition __transaction_state-38 broker=102] Log loaded for partition __transaction_state-38 with initial high watermark 0 (kafka.cluster.Partition)
[2024-08-26 15:17:20,901] INFO [LogLoader partition=__transaction_state-4, dir=/tmp/kafka-logs-102] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-08-26 15:17:20,902] INFO Created log for partition __transaction_state-4 in /tmp/kafka-logs-102/__transaction_state-4 with properties {cleanup.policy=compact, compression.type="uncompressed", min.insync.replicas=2, segment.bytes=104857600, unclean.leader.election.enable=false} (kafka.log.LogManager)
[2024-08-26 15:17:20,902] INFO [Partition __transaction_state-4 broker=102] No checkpointed highwatermark is found for partition __transaction_state-4 (kafka.cluster.Partition)
[2024-08-26 15:17:20,902] INFO [Partition __transaction_state-4 broker=102] Log loaded for partition __transaction_state-4 with initial high watermark 0 (kafka.cluster.Partition)
[2024-08-26 15:17:20,940] INFO [LogLoader partition=__transaction_state-19, dir=/tmp/kafka-logs-102] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-08-26 15:17:20,941] INFO Created log for partition __transaction_state-19 in /tmp/kafka-logs-102/__transaction_state-19 with properties {cleanup.policy=compact, compression.type="uncompressed", min.insync.replicas=2, segment.bytes=104857600, unclean.leader.election.enable=false} (kafka.log.LogManager)
[2024-08-26 15:17:20,941] INFO [Partition __transaction_state-19 broker=102] No checkpointed highwatermark is found for partition __transaction_state-19 (kafka.cluster.Partition)
[2024-08-26 15:17:20,941] INFO [Partition __transaction_state-19 broker=102] Log loaded for partition __transaction_state-19 with initial high watermark 0 (kafka.cluster.Partition)
[2024-08-26 15:17:20,945] INFO [LogLoader partition=__transaction_state-34, dir=/tmp/kafka-logs-102] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-08-26 15:17:20,951] INFO Created log for partition __transaction_state-34 in /tmp/kafka-logs-102/__transaction_state-34 with properties {cleanup.policy=compact, compression.type="uncompressed", min.insync.replicas=2, segment.bytes=104857600, unclean.leader.election.enable=false} (kafka.log.LogManager)
[2024-08-26 15:17:20,951] INFO [Partition __transaction_state-34 broker=102] No checkpointed highwatermark is found for partition __transaction_state-34 (kafka.cluster.Partition)
[2024-08-26 15:17:20,965] INFO [Partition __transaction_state-34 broker=102] Log loaded for partition __transaction_state-34 with initial high watermark 0 (kafka.cluster.Partition)
[2024-08-26 15:17:21,013] INFO [LogLoader partition=__transaction_state-49, dir=/tmp/kafka-logs-102] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-08-26 15:17:21,013] INFO Created log for partition __transaction_state-49 in /tmp/kafka-logs-102/__transaction_state-49 with properties {cleanup.policy=compact, compression.type="uncompressed", min.insync.replicas=2, segment.bytes=104857600, unclean.leader.election.enable=false} (kafka.log.LogManager)
[2024-08-26 15:17:21,013] INFO [Partition __transaction_state-49 broker=102] No checkpointed highwatermark is found for partition __transaction_state-49 (kafka.cluster.Partition)
[2024-08-26 15:17:21,014] INFO [Partition __transaction_state-49 broker=102] Log loaded for partition __transaction_state-49 with initial high watermark 0 (kafka.cluster.Partition)
[2024-08-26 15:17:21,023] INFO [LogLoader partition=__transaction_state-16, dir=/tmp/kafka-logs-102] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-08-26 15:17:21,043] INFO Created log for partition __transaction_state-16 in /tmp/kafka-logs-102/__transaction_state-16 with properties {cleanup.policy=compact, compression.type="uncompressed", min.insync.replicas=2, segment.bytes=104857600, unclean.leader.election.enable=false} (kafka.log.LogManager)
[2024-08-26 15:17:21,043] INFO [Partition __transaction_state-16 broker=102] No checkpointed highwatermark is found for partition __transaction_state-16 (kafka.cluster.Partition)
[2024-08-26 15:17:21,043] INFO [Partition __transaction_state-16 broker=102] Log loaded for partition __transaction_state-16 with initial high watermark 0 (kafka.cluster.Partition)
[2024-08-26 15:17:21,048] INFO [LogLoader partition=__transaction_state-31, dir=/tmp/kafka-logs-102] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-08-26 15:17:21,049] INFO Created log for partition __transaction_state-31 in /tmp/kafka-logs-102/__transaction_state-31 with properties {cleanup.policy=compact, compression.type="uncompressed", min.insync.replicas=2, segment.bytes=104857600, unclean.leader.election.enable=false} (kafka.log.LogManager)
[2024-08-26 15:17:21,049] INFO [Partition __transaction_state-31 broker=102] No checkpointed highwatermark is found for partition __transaction_state-31 (kafka.cluster.Partition)
[2024-08-26 15:17:21,049] INFO [Partition __transaction_state-31 broker=102] Log loaded for partition __transaction_state-31 with initial high watermark 0 (kafka.cluster.Partition)
[2024-08-26 15:17:21,117] INFO [LogLoader partition=__transaction_state-46, dir=/tmp/kafka-logs-102] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-08-26 15:17:21,118] INFO Created log for partition __transaction_state-46 in /tmp/kafka-logs-102/__transaction_state-46 with properties {cleanup.policy=compact, compression.type="uncompressed", min.insync.replicas=2, segment.bytes=104857600, unclean.leader.election.enable=false} (kafka.log.LogManager)
[2024-08-26 15:17:21,118] INFO [Partition __transaction_state-46 broker=102] No checkpointed highwatermark is found for partition __transaction_state-46 (kafka.cluster.Partition)
[2024-08-26 15:17:21,118] INFO [Partition __transaction_state-46 broker=102] Log loaded for partition __transaction_state-46 with initial high watermark 0 (kafka.cluster.Partition)
[2024-08-26 15:17:21,122] INFO [LogLoader partition=__transaction_state-5, dir=/tmp/kafka-logs-102] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-08-26 15:17:21,150] INFO Created log for partition __transaction_state-5 in /tmp/kafka-logs-102/__transaction_state-5 with properties {cleanup.policy=compact, compression.type="uncompressed", min.insync.replicas=2, segment.bytes=104857600, unclean.leader.election.enable=false} (kafka.log.LogManager)
[2024-08-26 15:17:21,150] INFO [Partition __transaction_state-5 broker=102] No checkpointed highwatermark is found for partition __transaction_state-5 (kafka.cluster.Partition)
[2024-08-26 15:17:21,150] INFO [Partition __transaction_state-5 broker=102] Log loaded for partition __transaction_state-5 with initial high watermark 0 (kafka.cluster.Partition)
[2024-08-26 15:17:21,155] INFO [LogLoader partition=__transaction_state-20, dir=/tmp/kafka-logs-102] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-08-26 15:17:21,155] INFO Created log for partition __transaction_state-20 in /tmp/kafka-logs-102/__transaction_state-20 with properties {cleanup.policy=compact, compression.type="uncompressed", min.insync.replicas=2, segment.bytes=104857600, unclean.leader.election.enable=false} (kafka.log.LogManager)
[2024-08-26 15:17:21,195] INFO [Partition __transaction_state-20 broker=102] No checkpointed highwatermark is found for partition __transaction_state-20 (kafka.cluster.Partition)
[2024-08-26 15:17:21,207] INFO [Partition __transaction_state-20 broker=102] Log loaded for partition __transaction_state-20 with initial high watermark 0 (kafka.cluster.Partition)
[2024-08-26 15:17:21,242] INFO [LogLoader partition=__transaction_state-35, dir=/tmp/kafka-logs-102] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-08-26 15:17:21,247] INFO Created log for partition __transaction_state-35 in /tmp/kafka-logs-102/__transaction_state-35 with properties {cleanup.policy=compact, compression.type="uncompressed", min.insync.replicas=2, segment.bytes=104857600, unclean.leader.election.enable=false} (kafka.log.LogManager)
[2024-08-26 15:17:21,251] INFO [Partition __transaction_state-35 broker=102] No checkpointed highwatermark is found for partition __transaction_state-35 (kafka.cluster.Partition)
[2024-08-26 15:17:21,266] INFO [Partition __transaction_state-35 broker=102] Log loaded for partition __transaction_state-35 with initial high watermark 0 (kafka.cluster.Partition)
[2024-08-26 15:17:21,286] INFO [LogLoader partition=__transaction_state-1, dir=/tmp/kafka-logs-102] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-08-26 15:17:21,286] INFO Created log for partition __transaction_state-1 in /tmp/kafka-logs-102/__transaction_state-1 with properties {cleanup.policy=compact, compression.type="uncompressed", min.insync.replicas=2, segment.bytes=104857600, unclean.leader.election.enable=false} (kafka.log.LogManager)
[2024-08-26 15:17:21,286] INFO [Partition __transaction_state-1 broker=102] No checkpointed highwatermark is found for partition __transaction_state-1 (kafka.cluster.Partition)
[2024-08-26 15:17:21,286] INFO [Partition __transaction_state-1 broker=102] Log loaded for partition __transaction_state-1 with initial high watermark 0 (kafka.cluster.Partition)
[2024-08-26 15:17:21,323] INFO [LogLoader partition=__transaction_state-32, dir=/tmp/kafka-logs-102] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-08-26 15:17:21,324] INFO Created log for partition __transaction_state-32 in /tmp/kafka-logs-102/__transaction_state-32 with properties {cleanup.policy=compact, compression.type="uncompressed", min.insync.replicas=2, segment.bytes=104857600, unclean.leader.election.enable=false} (kafka.log.LogManager)
[2024-08-26 15:17:21,324] INFO [Partition __transaction_state-32 broker=102] No checkpointed highwatermark is found for partition __transaction_state-32 (kafka.cluster.Partition)
[2024-08-26 15:17:21,324] INFO [Partition __transaction_state-32 broker=102] Log loaded for partition __transaction_state-32 with initial high watermark 0 (kafka.cluster.Partition)
[2024-08-26 15:17:21,328] INFO [LogLoader partition=__transaction_state-47, dir=/tmp/kafka-logs-102] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-08-26 15:17:21,336] INFO Created log for partition __transaction_state-47 in /tmp/kafka-logs-102/__transaction_state-47 with properties {cleanup.policy=compact, compression.type="uncompressed", min.insync.replicas=2, segment.bytes=104857600, unclean.leader.election.enable=false} (kafka.log.LogManager)
[2024-08-26 15:17:21,351] INFO [Partition __transaction_state-47 broker=102] No checkpointed highwatermark is found for partition __transaction_state-47 (kafka.cluster.Partition)
[2024-08-26 15:17:21,352] INFO [Partition __transaction_state-47 broker=102] Log loaded for partition __transaction_state-47 with initial high watermark 0 (kafka.cluster.Partition)
[2024-08-26 15:17:21,385] INFO [LogLoader partition=__transaction_state-13, dir=/tmp/kafka-logs-102] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-08-26 15:17:21,386] INFO Created log for partition __transaction_state-13 in /tmp/kafka-logs-102/__transaction_state-13 with properties {cleanup.policy=compact, compression.type="uncompressed", min.insync.replicas=2, segment.bytes=104857600, unclean.leader.election.enable=false} (kafka.log.LogManager)
[2024-08-26 15:17:21,386] INFO [Partition __transaction_state-13 broker=102] No checkpointed highwatermark is found for partition __transaction_state-13 (kafka.cluster.Partition)
[2024-08-26 15:17:21,386] INFO [Partition __transaction_state-13 broker=102] Log loaded for partition __transaction_state-13 with initial high watermark 0 (kafka.cluster.Partition)
[2024-08-26 15:17:21,408] INFO [LogLoader partition=__transaction_state-28, dir=/tmp/kafka-logs-102] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-08-26 15:17:21,409] INFO Created log for partition __transaction_state-28 in /tmp/kafka-logs-102/__transaction_state-28 with properties {cleanup.policy=compact, compression.type="uncompressed", min.insync.replicas=2, segment.bytes=104857600, unclean.leader.election.enable=false} (kafka.log.LogManager)
[2024-08-26 15:17:21,409] INFO [Partition __transaction_state-28 broker=102] No checkpointed highwatermark is found for partition __transaction_state-28 (kafka.cluster.Partition)
[2024-08-26 15:17:21,409] INFO [Partition __transaction_state-28 broker=102] Log loaded for partition __transaction_state-28 with initial high watermark 0 (kafka.cluster.Partition)
[2024-08-26 15:17:21,413] INFO [LogLoader partition=__transaction_state-43, dir=/tmp/kafka-logs-102] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-08-26 15:17:21,436] INFO Created log for partition __transaction_state-43 in /tmp/kafka-logs-102/__transaction_state-43 with properties {cleanup.policy=compact, compression.type="uncompressed", min.insync.replicas=2, segment.bytes=104857600, unclean.leader.election.enable=false} (kafka.log.LogManager)
[2024-08-26 15:17:21,437] INFO [Partition __transaction_state-43 broker=102] No checkpointed highwatermark is found for partition __transaction_state-43 (kafka.cluster.Partition)
[2024-08-26 15:17:21,437] INFO [Partition __transaction_state-43 broker=102] Log loaded for partition __transaction_state-43 with initial high watermark 0 (kafka.cluster.Partition)
[2024-08-26 15:17:21,465] INFO [LogLoader partition=__transaction_state-40, dir=/tmp/kafka-logs-102] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-08-26 15:17:21,477] INFO Created log for partition __transaction_state-40 in /tmp/kafka-logs-102/__transaction_state-40 with properties {cleanup.policy=compact, compression.type="uncompressed", min.insync.replicas=2, segment.bytes=104857600, unclean.leader.election.enable=false} (kafka.log.LogManager)
[2024-08-26 15:17:21,477] INFO [Partition __transaction_state-40 broker=102] No checkpointed highwatermark is found for partition __transaction_state-40 (kafka.cluster.Partition)
[2024-08-26 15:17:21,477] INFO [Partition __transaction_state-40 broker=102] Log loaded for partition __transaction_state-40 with initial high watermark 0 (kafka.cluster.Partition)
[2024-08-26 15:17:21,481] INFO [LogLoader partition=__transaction_state-2, dir=/tmp/kafka-logs-102] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-08-26 15:17:21,484] INFO Created log for partition __transaction_state-2 in /tmp/kafka-logs-102/__transaction_state-2 with properties {cleanup.policy=compact, compression.type="uncompressed", min.insync.replicas=2, segment.bytes=104857600, unclean.leader.election.enable=false} (kafka.log.LogManager)
[2024-08-26 15:17:21,484] INFO [Partition __transaction_state-2 broker=102] No checkpointed highwatermark is found for partition __transaction_state-2 (kafka.cluster.Partition)
[2024-08-26 15:17:21,485] INFO [Partition __transaction_state-2 broker=102] Log loaded for partition __transaction_state-2 with initial high watermark 0 (kafka.cluster.Partition)
[2024-08-26 15:17:21,509] INFO [LogLoader partition=__transaction_state-17, dir=/tmp/kafka-logs-102] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-08-26 15:17:21,509] INFO Created log for partition __transaction_state-17 in /tmp/kafka-logs-102/__transaction_state-17 with properties {cleanup.policy=compact, compression.type="uncompressed", min.insync.replicas=2, segment.bytes=104857600, unclean.leader.election.enable=false} (kafka.log.LogManager)
[2024-08-26 15:17:21,509] INFO [Partition __transaction_state-17 broker=102] No checkpointed highwatermark is found for partition __transaction_state-17 (kafka.cluster.Partition)
[2024-08-26 15:17:21,509] INFO [Partition __transaction_state-17 broker=102] Log loaded for partition __transaction_state-17 with initial high watermark 0 (kafka.cluster.Partition)
[2024-08-26 15:17:21,513] INFO [LogLoader partition=__transaction_state-14, dir=/tmp/kafka-logs-102] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-08-26 15:17:21,539] INFO Created log for partition __transaction_state-14 in /tmp/kafka-logs-102/__transaction_state-14 with properties {cleanup.policy=compact, compression.type="uncompressed", min.insync.replicas=2, segment.bytes=104857600, unclean.leader.election.enable=false} (kafka.log.LogManager)
[2024-08-26 15:17:21,551] INFO [Partition __transaction_state-14 broker=102] No checkpointed highwatermark is found for partition __transaction_state-14 (kafka.cluster.Partition)
[2024-08-26 15:17:21,551] INFO [Partition __transaction_state-14 broker=102] Log loaded for partition __transaction_state-14 with initial high watermark 0 (kafka.cluster.Partition)
[2024-08-26 15:17:21,556] INFO [LogLoader partition=__transaction_state-29, dir=/tmp/kafka-logs-102] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-08-26 15:17:21,557] INFO Created log for partition __transaction_state-29 in /tmp/kafka-logs-102/__transaction_state-29 with properties {cleanup.policy=compact, compression.type="uncompressed", min.insync.replicas=2, segment.bytes=104857600, unclean.leader.election.enable=false} (kafka.log.LogManager)
[2024-08-26 15:17:21,557] INFO [Partition __transaction_state-29 broker=102] No checkpointed highwatermark is found for partition __transaction_state-29 (kafka.cluster.Partition)
[2024-08-26 15:17:21,592] INFO [Partition __transaction_state-29 broker=102] Log loaded for partition __transaction_state-29 with initial high watermark 0 (kafka.cluster.Partition)
[2024-08-26 15:17:21,611] INFO [LogLoader partition=__transaction_state-44, dir=/tmp/kafka-logs-102] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-08-26 15:17:21,612] INFO Created log for partition __transaction_state-44 in /tmp/kafka-logs-102/__transaction_state-44 with properties {cleanup.policy=compact, compression.type="uncompressed", min.insync.replicas=2, segment.bytes=104857600, unclean.leader.election.enable=false} (kafka.log.LogManager)
[2024-08-26 15:17:21,616] INFO [Partition __transaction_state-44 broker=102] No checkpointed highwatermark is found for partition __transaction_state-44 (kafka.cluster.Partition)
[2024-08-26 15:17:21,616] INFO [Partition __transaction_state-44 broker=102] Log loaded for partition __transaction_state-44 with initial high watermark 0 (kafka.cluster.Partition)
[2024-08-26 15:17:21,648] INFO [LogLoader partition=__transaction_state-10, dir=/tmp/kafka-logs-102] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-08-26 15:17:21,649] INFO Created log for partition __transaction_state-10 in /tmp/kafka-logs-102/__transaction_state-10 with properties {cleanup.policy=compact, compression.type="uncompressed", min.insync.replicas=2, segment.bytes=104857600, unclean.leader.election.enable=false} (kafka.log.LogManager)
[2024-08-26 15:17:21,649] INFO [Partition __transaction_state-10 broker=102] No checkpointed highwatermark is found for partition __transaction_state-10 (kafka.cluster.Partition)
[2024-08-26 15:17:21,649] INFO [Partition __transaction_state-10 broker=102] Log loaded for partition __transaction_state-10 with initial high watermark 0 (kafka.cluster.Partition)
[2024-08-26 15:17:21,652] INFO [LogLoader partition=__transaction_state-25, dir=/tmp/kafka-logs-102] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-08-26 15:17:21,653] INFO Created log for partition __transaction_state-25 in /tmp/kafka-logs-102/__transaction_state-25 with properties {cleanup.policy=compact, compression.type="uncompressed", min.insync.replicas=2, segment.bytes=104857600, unclean.leader.election.enable=false} (kafka.log.LogManager)
[2024-08-26 15:17:21,653] INFO [Partition __transaction_state-25 broker=102] No checkpointed highwatermark is found for partition __transaction_state-25 (kafka.cluster.Partition)
[2024-08-26 15:17:21,684] INFO [Partition __transaction_state-25 broker=102] Log loaded for partition __transaction_state-25 with initial high watermark 0 (kafka.cluster.Partition)
[2024-08-26 15:17:21,697] INFO [ReplicaFetcherManager on broker 102] Removed fetcher for partitions HashSet(__transaction_state-11, __transaction_state-44, __transaction_state-13, __transaction_state-46, __transaction_state-17, __transaction_state-34, __transaction_state-5, __transaction_state-38, __transaction_state-7, __transaction_state-40, __transaction_state-26, __transaction_state-28, __transaction_state-32, __transaction_state-1, __transaction_state-20, __transaction_state-22, __transaction_state-10, __transaction_state-43, __transaction_state-14, __transaction_state-47, __transaction_state-16, __transaction_state-49, __transaction_state-2, __transaction_state-35, __transaction_state-4, __transaction_state-37, __transaction_state-8, __transaction_state-41, __transaction_state-29, __transaction_state-31, __transaction_state-19, __transaction_state-23, __transaction_state-25) (kafka.server.ReplicaFetcherManager)
[2024-08-26 15:17:21,700] INFO [ReplicaFetcherManager on broker 102] Added fetcher to broker 101 for partitions HashMap(__transaction_state-31 -> InitialFetchState(Some(GeNTnPQnQvCfhJ6N7pXZsQ),BrokerEndPoint(id=101, host=localhost:9092),0,0), __transaction_state-7 -> InitialFetchState(Some(GeNTnPQnQvCfhJ6N7pXZsQ),BrokerEndPoint(id=101, host=localhost:9092),0,0), __transaction_state-28 -> InitialFetchState(Some(GeNTnPQnQvCfhJ6N7pXZsQ),BrokerEndPoint(id=101, host=localhost:9092),0,0), __transaction_state-13 -> InitialFetchState(Some(GeNTnPQnQvCfhJ6N7pXZsQ),BrokerEndPoint(id=101, host=localhost:9092),0,0), __transaction_state-37 -> InitialFetchState(Some(GeNTnPQnQvCfhJ6N7pXZsQ),BrokerEndPoint(id=101, host=localhost:9092),0,0), __transaction_state-10 -> InitialFetchState(Some(GeNTnPQnQvCfhJ6N7pXZsQ),BrokerEndPoint(id=101, host=localhost:9092),0,0), __transaction_state-25 -> InitialFetchState(Some(GeNTnPQnQvCfhJ6N7pXZsQ),BrokerEndPoint(id=101, host=localhost:9092),0,0), __transaction_state-16 -> InitialFetchState(Some(GeNTnPQnQvCfhJ6N7pXZsQ),BrokerEndPoint(id=101, host=localhost:9092),0,0), __transaction_state-40 -> InitialFetchState(Some(GeNTnPQnQvCfhJ6N7pXZsQ),BrokerEndPoint(id=101, host=localhost:9092),0,0), __transaction_state-19 -> InitialFetchState(Some(GeNTnPQnQvCfhJ6N7pXZsQ),BrokerEndPoint(id=101, host=localhost:9092),0,0), __transaction_state-46 -> InitialFetchState(Some(GeNTnPQnQvCfhJ6N7pXZsQ),BrokerEndPoint(id=101, host=localhost:9092),0,0), __transaction_state-49 -> InitialFetchState(Some(GeNTnPQnQvCfhJ6N7pXZsQ),BrokerEndPoint(id=101, host=localhost:9092),0,0), __transaction_state-22 -> InitialFetchState(Some(GeNTnPQnQvCfhJ6N7pXZsQ),BrokerEndPoint(id=101, host=localhost:9092),0,0), __transaction_state-43 -> InitialFetchState(Some(GeNTnPQnQvCfhJ6N7pXZsQ),BrokerEndPoint(id=101, host=localhost:9092),0,0), __transaction_state-4 -> InitialFetchState(Some(GeNTnPQnQvCfhJ6N7pXZsQ),BrokerEndPoint(id=101, host=localhost:9092),0,0), __transaction_state-1 -> InitialFetchState(Some(GeNTnPQnQvCfhJ6N7pXZsQ),BrokerEndPoint(id=101, host=localhost:9092),0,0), __transaction_state-34 -> InitialFetchState(Some(GeNTnPQnQvCfhJ6N7pXZsQ),BrokerEndPoint(id=101, host=localhost:9092),0,0)) (kafka.server.ReplicaFetcherManager)
[2024-08-26 15:17:21,747] INFO [ReplicaFetcherManager on broker 102] Added fetcher to broker 103 for partitions HashMap(__transaction_state-29 -> InitialFetchState(Some(GeNTnPQnQvCfhJ6N7pXZsQ),BrokerEndPoint(id=103, host=localhost:9094),0,0), __transaction_state-38 -> InitialFetchState(Some(GeNTnPQnQvCfhJ6N7pXZsQ),BrokerEndPoint(id=103, host=localhost:9094),0,0), __transaction_state-32 -> InitialFetchState(Some(GeNTnPQnQvCfhJ6N7pXZsQ),BrokerEndPoint(id=103, host=localhost:9094),0,0), __transaction_state-17 -> InitialFetchState(Some(GeNTnPQnQvCfhJ6N7pXZsQ),BrokerEndPoint(id=103, host=localhost:9094),0,0), __transaction_state-11 -> InitialFetchState(Some(GeNTnPQnQvCfhJ6N7pXZsQ),BrokerEndPoint(id=103, host=localhost:9094),0,0), __transaction_state-41 -> InitialFetchState(Some(GeNTnPQnQvCfhJ6N7pXZsQ),BrokerEndPoint(id=103, host=localhost:9094),0,0), __transaction_state-35 -> InitialFetchState(Some(GeNTnPQnQvCfhJ6N7pXZsQ),BrokerEndPoint(id=103, host=localhost:9094),0,0), __transaction_state-2 -> InitialFetchState(Some(GeNTnPQnQvCfhJ6N7pXZsQ),BrokerEndPoint(id=103, host=localhost:9094),0,0), __transaction_state-20 -> InitialFetchState(Some(GeNTnPQnQvCfhJ6N7pXZsQ),BrokerEndPoint(id=103, host=localhost:9094),0,0), __transaction_state-14 -> InitialFetchState(Some(GeNTnPQnQvCfhJ6N7pXZsQ),BrokerEndPoint(id=103, host=localhost:9094),0,0), __transaction_state-44 -> InitialFetchState(Some(GeNTnPQnQvCfhJ6N7pXZsQ),BrokerEndPoint(id=103, host=localhost:9094),0,0), __transaction_state-23 -> InitialFetchState(Some(GeNTnPQnQvCfhJ6N7pXZsQ),BrokerEndPoint(id=103, host=localhost:9094),0,0), __transaction_state-47 -> InitialFetchState(Some(GeNTnPQnQvCfhJ6N7pXZsQ),BrokerEndPoint(id=103, host=localhost:9094),0,0), __transaction_state-26 -> InitialFetchState(Some(GeNTnPQnQvCfhJ6N7pXZsQ),BrokerEndPoint(id=103, host=localhost:9094),0,0), __transaction_state-5 -> InitialFetchState(Some(GeNTnPQnQvCfhJ6N7pXZsQ),BrokerEndPoint(id=103, host=localhost:9094),0,0), __transaction_state-8 -> InitialFetchState(Some(GeNTnPQnQvCfhJ6N7pXZsQ),BrokerEndPoint(id=103, host=localhost:9094),0,0)) (kafka.server.ReplicaFetcherManager)
[2024-08-26 15:17:21,758] INFO [TransactionCoordinator id=102] Elected as the txn coordinator for partition 24 at epoch 0 (kafka.coordinator.transaction.TransactionCoordinator)
[2024-08-26 15:17:21,765] INFO [TransactionCoordinator id=102] Elected as the txn coordinator for partition 39 at epoch 0 (kafka.coordinator.transaction.TransactionCoordinator)
[2024-08-26 15:17:21,765] INFO [TransactionCoordinator id=102] Elected as the txn coordinator for partition 3 at epoch 0 (kafka.coordinator.transaction.TransactionCoordinator)
[2024-08-26 15:17:21,766] INFO [TransactionCoordinator id=102] Elected as the txn coordinator for partition 18 at epoch 0 (kafka.coordinator.transaction.TransactionCoordinator)
[2024-08-26 15:17:21,766] INFO [TransactionCoordinator id=102] Elected as the txn coordinator for partition 33 at epoch 0 (kafka.coordinator.transaction.TransactionCoordinator)
[2024-08-26 15:17:21,766] INFO [TransactionCoordinator id=102] Elected as the txn coordinator for partition 0 at epoch 0 (kafka.coordinator.transaction.TransactionCoordinator)
[2024-08-26 15:17:21,766] INFO [Transaction State Manager 102]: Loading transaction metadata from __transaction_state-24 at epoch 0 (kafka.coordinator.transaction.TransactionStateManager)
[2024-08-26 15:17:21,783] INFO [TransactionCoordinator id=102] Elected as the txn coordinator for partition 15 at epoch 0 (kafka.coordinator.transaction.TransactionCoordinator)
[2024-08-26 15:17:21,783] INFO [TransactionCoordinator id=102] Elected as the txn coordinator for partition 30 at epoch 0 (kafka.coordinator.transaction.TransactionCoordinator)
[2024-08-26 15:17:21,783] INFO [TransactionCoordinator id=102] Elected as the txn coordinator for partition 45 at epoch 0 (kafka.coordinator.transaction.TransactionCoordinator)
[2024-08-26 15:17:21,783] INFO [TransactionCoordinator id=102] Elected as the txn coordinator for partition 9 at epoch 0 (kafka.coordinator.transaction.TransactionCoordinator)
[2024-08-26 15:17:21,783] INFO [TransactionCoordinator id=102] Elected as the txn coordinator for partition 6 at epoch 0 (kafka.coordinator.transaction.TransactionCoordinator)
[2024-08-26 15:17:21,784] INFO [TransactionCoordinator id=102] Elected as the txn coordinator for partition 21 at epoch 0 (kafka.coordinator.transaction.TransactionCoordinator)
[2024-08-26 15:17:21,784] INFO [TransactionCoordinator id=102] Elected as the txn coordinator for partition 36 at epoch 0 (kafka.coordinator.transaction.TransactionCoordinator)
[2024-08-26 15:17:21,784] INFO [TransactionCoordinator id=102] Elected as the txn coordinator for partition 48 at epoch 0 (kafka.coordinator.transaction.TransactionCoordinator)
[2024-08-26 15:17:21,784] INFO [TransactionCoordinator id=102] Elected as the txn coordinator for partition 12 at epoch 0 (kafka.coordinator.transaction.TransactionCoordinator)
[2024-08-26 15:17:21,784] INFO [TransactionCoordinator id=102] Elected as the txn coordinator for partition 27 at epoch 0 (kafka.coordinator.transaction.TransactionCoordinator)
[2024-08-26 15:17:21,784] INFO [TransactionCoordinator id=102] Elected as the txn coordinator for partition 42 at epoch 0 (kafka.coordinator.transaction.TransactionCoordinator)
[2024-08-26 15:17:21,785] INFO [TransactionCoordinator id=102] Resigned as the txn coordinator for partition 7 at epoch Some(0) (kafka.coordinator.transaction.TransactionCoordinator)
[2024-08-26 15:17:21,786] INFO [Transaction State Manager 102]: No cached transaction metadata found for __transaction_state-7 during become-follower transition (kafka.coordinator.transaction.TransactionStateManager)
[2024-08-26 15:17:21,786] INFO [TransactionCoordinator id=102] Resigned as the txn coordinator for partition 22 at epoch Some(0) (kafka.coordinator.transaction.TransactionCoordinator)
[2024-08-26 15:17:21,786] INFO [Transaction State Manager 102]: No cached transaction metadata found for __transaction_state-22 during become-follower transition (kafka.coordinator.transaction.TransactionStateManager)
[2024-08-26 15:17:21,786] INFO [TransactionCoordinator id=102] Resigned as the txn coordinator for partition 37 at epoch Some(0) (kafka.coordinator.transaction.TransactionCoordinator)
[2024-08-26 15:17:21,787] INFO [Transaction State Manager 102]: No cached transaction metadata found for __transaction_state-37 during become-follower transition (kafka.coordinator.transaction.TransactionStateManager)
[2024-08-26 15:17:21,787] INFO [TransactionCoordinator id=102] Resigned as the txn coordinator for partition 11 at epoch Some(0) (kafka.coordinator.transaction.TransactionCoordinator)
[2024-08-26 15:17:21,787] INFO [Transaction State Manager 102]: No cached transaction metadata found for __transaction_state-11 during become-follower transition (kafka.coordinator.transaction.TransactionStateManager)
[2024-08-26 15:17:21,787] INFO [TransactionCoordinator id=102] Resigned as the txn coordinator for partition 26 at epoch Some(0) (kafka.coordinator.transaction.TransactionCoordinator)
[2024-08-26 15:17:21,787] INFO [Transaction State Manager 102]: No cached transaction metadata found for __transaction_state-26 during become-follower transition (kafka.coordinator.transaction.TransactionStateManager)
[2024-08-26 15:17:21,787] INFO [TransactionCoordinator id=102] Resigned as the txn coordinator for partition 41 at epoch Some(0) (kafka.coordinator.transaction.TransactionCoordinator)
[2024-08-26 15:17:21,787] INFO [Transaction State Manager 102]: No cached transaction metadata found for __transaction_state-41 during become-follower transition (kafka.coordinator.transaction.TransactionStateManager)
[2024-08-26 15:17:21,787] INFO [TransactionCoordinator id=102] Resigned as the txn coordinator for partition 8 at epoch Some(0) (kafka.coordinator.transaction.TransactionCoordinator)
[2024-08-26 15:17:21,787] INFO [Transaction State Manager 102]: No cached transaction metadata found for __transaction_state-8 during become-follower transition (kafka.coordinator.transaction.TransactionStateManager)
[2024-08-26 15:17:21,788] INFO [TransactionCoordinator id=102] Resigned as the txn coordinator for partition 23 at epoch Some(0) (kafka.coordinator.transaction.TransactionCoordinator)
[2024-08-26 15:17:21,788] INFO [Transaction State Manager 102]: No cached transaction metadata found for __transaction_state-23 during become-follower transition (kafka.coordinator.transaction.TransactionStateManager)
[2024-08-26 15:17:21,788] INFO [TransactionCoordinator id=102] Resigned as the txn coordinator for partition 38 at epoch Some(0) (kafka.coordinator.transaction.TransactionCoordinator)
[2024-08-26 15:17:21,788] INFO [Transaction State Manager 102]: No cached transaction metadata found for __transaction_state-38 during become-follower transition (kafka.coordinator.transaction.TransactionStateManager)
[2024-08-26 15:17:21,788] INFO [TransactionCoordinator id=102] Resigned as the txn coordinator for partition 4 at epoch Some(0) (kafka.coordinator.transaction.TransactionCoordinator)
[2024-08-26 15:17:21,788] INFO [Transaction State Manager 102]: No cached transaction metadata found for __transaction_state-4 during become-follower transition (kafka.coordinator.transaction.TransactionStateManager)
[2024-08-26 15:17:21,788] INFO [TransactionCoordinator id=102] Resigned as the txn coordinator for partition 19 at epoch Some(0) (kafka.coordinator.transaction.TransactionCoordinator)
[2024-08-26 15:17:21,788] INFO [Transaction State Manager 102]: No cached transaction metadata found for __transaction_state-19 during become-follower transition (kafka.coordinator.transaction.TransactionStateManager)
[2024-08-26 15:17:21,788] INFO [TransactionCoordinator id=102] Resigned as the txn coordinator for partition 34 at epoch Some(0) (kafka.coordinator.transaction.TransactionCoordinator)
[2024-08-26 15:17:21,788] INFO [Transaction State Manager 102]: No cached transaction metadata found for __transaction_state-34 during become-follower transition (kafka.coordinator.transaction.TransactionStateManager)
[2024-08-26 15:17:21,788] INFO [TransactionCoordinator id=102] Resigned as the txn coordinator for partition 49 at epoch Some(0) (kafka.coordinator.transaction.TransactionCoordinator)
[2024-08-26 15:17:21,788] INFO [Transaction State Manager 102]: No cached transaction metadata found for __transaction_state-49 during become-follower transition (kafka.coordinator.transaction.TransactionStateManager)
[2024-08-26 15:17:21,788] INFO [TransactionCoordinator id=102] Resigned as the txn coordinator for partition 16 at epoch Some(0) (kafka.coordinator.transaction.TransactionCoordinator)
[2024-08-26 15:17:21,788] INFO [Transaction State Manager 102]: No cached transaction metadata found for __transaction_state-16 during become-follower transition (kafka.coordinator.transaction.TransactionStateManager)
[2024-08-26 15:17:21,789] INFO [TransactionCoordinator id=102] Resigned as the txn coordinator for partition 31 at epoch Some(0) (kafka.coordinator.transaction.TransactionCoordinator)
[2024-08-26 15:17:21,789] INFO [Transaction State Manager 102]: No cached transaction metadata found for __transaction_state-31 during become-follower transition (kafka.coordinator.transaction.TransactionStateManager)
[2024-08-26 15:17:21,789] INFO [TransactionCoordinator id=102] Resigned as the txn coordinator for partition 46 at epoch Some(0) (kafka.coordinator.transaction.TransactionCoordinator)
[2024-08-26 15:17:21,789] INFO [Transaction State Manager 102]: No cached transaction metadata found for __transaction_state-46 during become-follower transition (kafka.coordinator.transaction.TransactionStateManager)
[2024-08-26 15:17:21,789] INFO [TransactionCoordinator id=102] Resigned as the txn coordinator for partition 5 at epoch Some(0) (kafka.coordinator.transaction.TransactionCoordinator)
[2024-08-26 15:17:21,789] INFO [Transaction State Manager 102]: No cached transaction metadata found for __transaction_state-5 during become-follower transition (kafka.coordinator.transaction.TransactionStateManager)
[2024-08-26 15:17:21,789] INFO [TransactionCoordinator id=102] Resigned as the txn coordinator for partition 20 at epoch Some(0) (kafka.coordinator.transaction.TransactionCoordinator)
[2024-08-26 15:17:21,789] INFO [Transaction State Manager 102]: No cached transaction metadata found for __transaction_state-20 during become-follower transition (kafka.coordinator.transaction.TransactionStateManager)
[2024-08-26 15:17:21,789] INFO [TransactionCoordinator id=102] Resigned as the txn coordinator for partition 35 at epoch Some(0) (kafka.coordinator.transaction.TransactionCoordinator)
[2024-08-26 15:17:21,789] INFO [Transaction State Manager 102]: No cached transaction metadata found for __transaction_state-35 during become-follower transition (kafka.coordinator.transaction.TransactionStateManager)
[2024-08-26 15:17:21,789] INFO [TransactionCoordinator id=102] Resigned as the txn coordinator for partition 1 at epoch Some(0) (kafka.coordinator.transaction.TransactionCoordinator)
[2024-08-26 15:17:21,789] INFO [Transaction State Manager 102]: No cached transaction metadata found for __transaction_state-1 during become-follower transition (kafka.coordinator.transaction.TransactionStateManager)
[2024-08-26 15:17:21,789] INFO [TransactionCoordinator id=102] Resigned as the txn coordinator for partition 32 at epoch Some(0) (kafka.coordinator.transaction.TransactionCoordinator)
[2024-08-26 15:17:21,789] INFO [Transaction State Manager 102]: No cached transaction metadata found for __transaction_state-32 during become-follower transition (kafka.coordinator.transaction.TransactionStateManager)
[2024-08-26 15:17:21,789] INFO [TransactionCoordinator id=102] Resigned as the txn coordinator for partition 47 at epoch Some(0) (kafka.coordinator.transaction.TransactionCoordinator)
[2024-08-26 15:17:21,789] INFO [Transaction State Manager 102]: No cached transaction metadata found for __transaction_state-47 during become-follower transition (kafka.coordinator.transaction.TransactionStateManager)
[2024-08-26 15:17:21,790] INFO [TransactionCoordinator id=102] Resigned as the txn coordinator for partition 13 at epoch Some(0) (kafka.coordinator.transaction.TransactionCoordinator)
[2024-08-26 15:17:21,790] INFO [Transaction State Manager 102]: No cached transaction metadata found for __transaction_state-13 during become-follower transition (kafka.coordinator.transaction.TransactionStateManager)
[2024-08-26 15:17:21,790] INFO [TransactionCoordinator id=102] Resigned as the txn coordinator for partition 28 at epoch Some(0) (kafka.coordinator.transaction.TransactionCoordinator)
[2024-08-26 15:17:21,790] INFO [Transaction State Manager 102]: No cached transaction metadata found for __transaction_state-28 during become-follower transition (kafka.coordinator.transaction.TransactionStateManager)
[2024-08-26 15:17:21,790] INFO [TransactionCoordinator id=102] Resigned as the txn coordinator for partition 43 at epoch Some(0) (kafka.coordinator.transaction.TransactionCoordinator)
[2024-08-26 15:17:21,790] INFO [Transaction State Manager 102]: No cached transaction metadata found for __transaction_state-43 during become-follower transition (kafka.coordinator.transaction.TransactionStateManager)
[2024-08-26 15:17:21,790] INFO [TransactionCoordinator id=102] Resigned as the txn coordinator for partition 40 at epoch Some(0) (kafka.coordinator.transaction.TransactionCoordinator)
[2024-08-26 15:17:21,790] INFO [Transaction State Manager 102]: No cached transaction metadata found for __transaction_state-40 during become-follower transition (kafka.coordinator.transaction.TransactionStateManager)
[2024-08-26 15:17:21,790] INFO [TransactionCoordinator id=102] Resigned as the txn coordinator for partition 2 at epoch Some(0) (kafka.coordinator.transaction.TransactionCoordinator)
[2024-08-26 15:17:21,790] INFO [Transaction State Manager 102]: No cached transaction metadata found for __transaction_state-2 during become-follower transition (kafka.coordinator.transaction.TransactionStateManager)
[2024-08-26 15:17:21,790] INFO [TransactionCoordinator id=102] Resigned as the txn coordinator for partition 17 at epoch Some(0) (kafka.coordinator.transaction.TransactionCoordinator)
[2024-08-26 15:17:21,790] INFO [Transaction State Manager 102]: No cached transaction metadata found for __transaction_state-17 during become-follower transition (kafka.coordinator.transaction.TransactionStateManager)
[2024-08-26 15:17:21,790] INFO [TransactionCoordinator id=102] Resigned as the txn coordinator for partition 14 at epoch Some(0) (kafka.coordinator.transaction.TransactionCoordinator)
[2024-08-26 15:17:21,790] INFO [Transaction State Manager 102]: No cached transaction metadata found for __transaction_state-14 during become-follower transition (kafka.coordinator.transaction.TransactionStateManager)
[2024-08-26 15:17:21,790] INFO [TransactionCoordinator id=102] Resigned as the txn coordinator for partition 29 at epoch Some(0) (kafka.coordinator.transaction.TransactionCoordinator)
[2024-08-26 15:17:21,790] INFO [Transaction State Manager 102]: No cached transaction metadata found for __transaction_state-29 during become-follower transition (kafka.coordinator.transaction.TransactionStateManager)
[2024-08-26 15:17:21,790] INFO [TransactionCoordinator id=102] Resigned as the txn coordinator for partition 44 at epoch Some(0) (kafka.coordinator.transaction.TransactionCoordinator)
[2024-08-26 15:17:21,791] INFO [Transaction State Manager 102]: No cached transaction metadata found for __transaction_state-44 during become-follower transition (kafka.coordinator.transaction.TransactionStateManager)
[2024-08-26 15:17:21,791] INFO [TransactionCoordinator id=102] Resigned as the txn coordinator for partition 10 at epoch Some(0) (kafka.coordinator.transaction.TransactionCoordinator)
[2024-08-26 15:17:21,791] INFO [Transaction State Manager 102]: No cached transaction metadata found for __transaction_state-10 during become-follower transition (kafka.coordinator.transaction.TransactionStateManager)
[2024-08-26 15:17:21,791] INFO [TransactionCoordinator id=102] Resigned as the txn coordinator for partition 25 at epoch Some(0) (kafka.coordinator.transaction.TransactionCoordinator)
[2024-08-26 15:17:21,791] INFO [Transaction State Manager 102]: No cached transaction metadata found for __transaction_state-25 during become-follower transition (kafka.coordinator.transaction.TransactionStateManager)
[2024-08-26 15:17:21,795] INFO [Transaction State Manager 102]: Finished loading 0 transaction metadata from __transaction_state-24 in 29 milliseconds, of which 1 milliseconds was spent in the scheduler. (kafka.coordinator.transaction.TransactionStateManager)
[2024-08-26 15:17:21,799] INFO [Transaction State Manager 102]: Completed loading transaction metadata from __transaction_state-24 for coordinator epoch 0 (kafka.coordinator.transaction.TransactionStateManager)
[2024-08-26 15:17:21,800] INFO [Transaction State Manager 102]: Loading transaction metadata from __transaction_state-39 at epoch 0 (kafka.coordinator.transaction.TransactionStateManager)
[2024-08-26 15:17:21,802] INFO [Transaction State Manager 102]: Finished loading 0 transaction metadata from __transaction_state-39 in 37 milliseconds, of which 35 milliseconds was spent in the scheduler. (kafka.coordinator.transaction.TransactionStateManager)
[2024-08-26 15:17:21,802] INFO [Transaction State Manager 102]: Completed loading transaction metadata from __transaction_state-39 for coordinator epoch 0 (kafka.coordinator.transaction.TransactionStateManager)
[2024-08-26 15:17:21,802] INFO [Transaction State Manager 102]: Loading transaction metadata from __transaction_state-3 at epoch 0 (kafka.coordinator.transaction.TransactionStateManager)
[2024-08-26 15:17:21,836] INFO [Transaction State Manager 102]: Finished loading 0 transaction metadata from __transaction_state-3 in 71 milliseconds, of which 37 milliseconds was spent in the scheduler. (kafka.coordinator.transaction.TransactionStateManager)
[2024-08-26 15:17:21,836] INFO [Transaction State Manager 102]: Completed loading transaction metadata from __transaction_state-3 for coordinator epoch 0 (kafka.coordinator.transaction.TransactionStateManager)
[2024-08-26 15:17:21,836] INFO [Transaction State Manager 102]: Loading transaction metadata from __transaction_state-18 at epoch 0 (kafka.coordinator.transaction.TransactionStateManager)
[2024-08-26 15:17:21,839] INFO [Transaction State Manager 102]: Finished loading 0 transaction metadata from __transaction_state-18 in 73 milliseconds, of which 70 milliseconds was spent in the scheduler. (kafka.coordinator.transaction.TransactionStateManager)
[2024-08-26 15:17:21,839] INFO [Transaction State Manager 102]: Completed loading transaction metadata from __transaction_state-18 for coordinator epoch 0 (kafka.coordinator.transaction.TransactionStateManager)
[2024-08-26 15:17:21,839] INFO [Transaction State Manager 102]: Loading transaction metadata from __transaction_state-33 at epoch 0 (kafka.coordinator.transaction.TransactionStateManager)
[2024-08-26 15:17:21,842] INFO [Transaction State Manager 102]: Finished loading 0 transaction metadata from __transaction_state-33 in 76 milliseconds, of which 73 milliseconds was spent in the scheduler. (kafka.coordinator.transaction.TransactionStateManager)
[2024-08-26 15:17:21,842] INFO [Transaction State Manager 102]: Completed loading transaction metadata from __transaction_state-33 for coordinator epoch 0 (kafka.coordinator.transaction.TransactionStateManager)
[2024-08-26 15:17:21,842] INFO [Transaction State Manager 102]: Loading transaction metadata from __transaction_state-0 at epoch 0 (kafka.coordinator.transaction.TransactionStateManager)
[2024-08-26 15:17:21,844] INFO [Transaction State Manager 102]: Finished loading 0 transaction metadata from __transaction_state-0 in 61 milliseconds, of which 59 milliseconds was spent in the scheduler. (kafka.coordinator.transaction.TransactionStateManager)
[2024-08-26 15:17:21,844] INFO [Transaction State Manager 102]: Completed loading transaction metadata from __transaction_state-0 for coordinator epoch 0 (kafka.coordinator.transaction.TransactionStateManager)
[2024-08-26 15:17:21,844] INFO [Transaction State Manager 102]: Loading transaction metadata from __transaction_state-15 at epoch 0 (kafka.coordinator.transaction.TransactionStateManager)
[2024-08-26 15:17:21,846] INFO [Transaction State Manager 102]: Finished loading 0 transaction metadata from __transaction_state-15 in 63 milliseconds, of which 61 milliseconds was spent in the scheduler. (kafka.coordinator.transaction.TransactionStateManager)
[2024-08-26 15:17:21,847] INFO [Transaction State Manager 102]: Completed loading transaction metadata from __transaction_state-15 for coordinator epoch 0 (kafka.coordinator.transaction.TransactionStateManager)
[2024-08-26 15:17:21,847] INFO [Transaction State Manager 102]: Loading transaction metadata from __transaction_state-30 at epoch 0 (kafka.coordinator.transaction.TransactionStateManager)
[2024-08-26 15:17:21,849] INFO [Transaction State Manager 102]: Finished loading 0 transaction metadata from __transaction_state-30 in 66 milliseconds, of which 64 milliseconds was spent in the scheduler. (kafka.coordinator.transaction.TransactionStateManager)
[2024-08-26 15:17:21,849] INFO [Transaction State Manager 102]: Completed loading transaction metadata from __transaction_state-30 for coordinator epoch 0 (kafka.coordinator.transaction.TransactionStateManager)
[2024-08-26 15:17:21,849] INFO [Transaction State Manager 102]: Loading transaction metadata from __transaction_state-45 at epoch 0 (kafka.coordinator.transaction.TransactionStateManager)
[2024-08-26 15:17:21,851] INFO [Transaction State Manager 102]: Finished loading 0 transaction metadata from __transaction_state-45 in 68 milliseconds, of which 66 milliseconds was spent in the scheduler. (kafka.coordinator.transaction.TransactionStateManager)
[2024-08-26 15:17:21,851] INFO [Transaction State Manager 102]: Completed loading transaction metadata from __transaction_state-45 for coordinator epoch 0 (kafka.coordinator.transaction.TransactionStateManager)
[2024-08-26 15:17:21,883] INFO [Transaction State Manager 102]: Loading transaction metadata from __transaction_state-9 at epoch 0 (kafka.coordinator.transaction.TransactionStateManager)
[2024-08-26 15:17:21,886] INFO [Transaction State Manager 102]: Finished loading 0 transaction metadata from __transaction_state-9 in 103 milliseconds, of which 100 milliseconds was spent in the scheduler. (kafka.coordinator.transaction.TransactionStateManager)
[2024-08-26 15:17:21,887] INFO [Transaction State Manager 102]: Completed loading transaction metadata from __transaction_state-9 for coordinator epoch 0 (kafka.coordinator.transaction.TransactionStateManager)
[2024-08-26 15:17:21,887] INFO [Transaction State Manager 102]: Loading transaction metadata from __transaction_state-6 at epoch 0 (kafka.coordinator.transaction.TransactionStateManager)
[2024-08-26 15:17:21,889] INFO [Transaction State Manager 102]: Finished loading 0 transaction metadata from __transaction_state-6 in 105 milliseconds, of which 103 milliseconds was spent in the scheduler. (kafka.coordinator.transaction.TransactionStateManager)
[2024-08-26 15:17:21,889] INFO [Transaction State Manager 102]: Completed loading transaction metadata from __transaction_state-6 for coordinator epoch 0 (kafka.coordinator.transaction.TransactionStateManager)
[2024-08-26 15:17:21,890] INFO [Transaction State Manager 102]: Loading transaction metadata from __transaction_state-21 at epoch 0 (kafka.coordinator.transaction.TransactionStateManager)
[2024-08-26 15:17:21,892] INFO [Transaction State Manager 102]: Finished loading 0 transaction metadata from __transaction_state-21 in 108 milliseconds, of which 106 milliseconds was spent in the scheduler. (kafka.coordinator.transaction.TransactionStateManager)
[2024-08-26 15:17:21,892] INFO [Transaction State Manager 102]: Completed loading transaction metadata from __transaction_state-21 for coordinator epoch 0 (kafka.coordinator.transaction.TransactionStateManager)
[2024-08-26 15:17:21,892] INFO [Transaction State Manager 102]: Loading transaction metadata from __transaction_state-36 at epoch 0 (kafka.coordinator.transaction.TransactionStateManager)
[2024-08-26 15:17:21,894] INFO [Transaction State Manager 102]: Finished loading 0 transaction metadata from __transaction_state-36 in 110 milliseconds, of which 108 milliseconds was spent in the scheduler. (kafka.coordinator.transaction.TransactionStateManager)
[2024-08-26 15:17:21,894] INFO [Transaction State Manager 102]: Completed loading transaction metadata from __transaction_state-36 for coordinator epoch 0 (kafka.coordinator.transaction.TransactionStateManager)
[2024-08-26 15:17:21,894] INFO [Transaction State Manager 102]: Loading transaction metadata from __transaction_state-48 at epoch 0 (kafka.coordinator.transaction.TransactionStateManager)
[2024-08-26 15:17:21,895] INFO [Transaction State Manager 102]: Finished loading 0 transaction metadata from __transaction_state-48 in 111 milliseconds, of which 110 milliseconds was spent in the scheduler. (kafka.coordinator.transaction.TransactionStateManager)
[2024-08-26 15:17:21,896] INFO [Transaction State Manager 102]: Completed loading transaction metadata from __transaction_state-48 for coordinator epoch 0 (kafka.coordinator.transaction.TransactionStateManager)
[2024-08-26 15:17:21,896] INFO [Transaction State Manager 102]: Loading transaction metadata from __transaction_state-12 at epoch 0 (kafka.coordinator.transaction.TransactionStateManager)
[2024-08-26 15:17:21,898] INFO [Transaction State Manager 102]: Finished loading 0 transaction metadata from __transaction_state-12 in 114 milliseconds, of which 112 milliseconds was spent in the scheduler. (kafka.coordinator.transaction.TransactionStateManager)
[2024-08-26 15:17:21,898] INFO [Transaction State Manager 102]: Completed loading transaction metadata from __transaction_state-12 for coordinator epoch 0 (kafka.coordinator.transaction.TransactionStateManager)
[2024-08-26 15:17:21,898] INFO [Transaction State Manager 102]: Loading transaction metadata from __transaction_state-27 at epoch 0 (kafka.coordinator.transaction.TransactionStateManager)
[2024-08-26 15:17:21,900] INFO [Transaction State Manager 102]: Finished loading 0 transaction metadata from __transaction_state-27 in 116 milliseconds, of which 114 milliseconds was spent in the scheduler. (kafka.coordinator.transaction.TransactionStateManager)
[2024-08-26 15:17:21,900] INFO [Transaction State Manager 102]: Completed loading transaction metadata from __transaction_state-27 for coordinator epoch 0 (kafka.coordinator.transaction.TransactionStateManager)
[2024-08-26 15:17:21,900] INFO [Transaction State Manager 102]: Loading transaction metadata from __transaction_state-42 at epoch 0 (kafka.coordinator.transaction.TransactionStateManager)
[2024-08-26 15:17:21,902] INFO [Transaction State Manager 102]: Finished loading 0 transaction metadata from __transaction_state-42 in 118 milliseconds, of which 116 milliseconds was spent in the scheduler. (kafka.coordinator.transaction.TransactionStateManager)
[2024-08-26 15:17:21,933] INFO [Transaction State Manager 102]: Completed loading transaction metadata from __transaction_state-42 for coordinator epoch 0 (kafka.coordinator.transaction.TransactionStateManager)
[2024-08-26 15:17:22,038] INFO [ReplicaFetcher replicaId=102, leaderId=103, fetcherId=0] Truncating partition __transaction_state-11 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:17:22,039] INFO [UnifiedLog partition=__transaction_state-11, dir=/tmp/kafka-logs-102] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2024-08-26 15:17:22,039] INFO [ReplicaFetcher replicaId=102, leaderId=103, fetcherId=0] Truncating partition __transaction_state-44 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:17:22,039] INFO [UnifiedLog partition=__transaction_state-44, dir=/tmp/kafka-logs-102] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2024-08-26 15:17:22,039] INFO [ReplicaFetcher replicaId=102, leaderId=103, fetcherId=0] Truncating partition __transaction_state-14 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:17:22,039] INFO [UnifiedLog partition=__transaction_state-14, dir=/tmp/kafka-logs-102] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2024-08-26 15:17:22,039] INFO [ReplicaFetcher replicaId=102, leaderId=103, fetcherId=0] Truncating partition __transaction_state-47 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:17:22,039] INFO [UnifiedLog partition=__transaction_state-47, dir=/tmp/kafka-logs-102] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2024-08-26 15:17:22,039] INFO [ReplicaFetcher replicaId=102, leaderId=103, fetcherId=0] Truncating partition __transaction_state-17 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:17:22,039] INFO [UnifiedLog partition=__transaction_state-17, dir=/tmp/kafka-logs-102] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2024-08-26 15:17:22,039] INFO [ReplicaFetcher replicaId=102, leaderId=103, fetcherId=0] Truncating partition __transaction_state-2 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:17:22,039] INFO [UnifiedLog partition=__transaction_state-2, dir=/tmp/kafka-logs-102] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2024-08-26 15:17:22,040] INFO [ReplicaFetcher replicaId=102, leaderId=103, fetcherId=0] Truncating partition __transaction_state-35 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:17:22,040] INFO [UnifiedLog partition=__transaction_state-35, dir=/tmp/kafka-logs-102] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2024-08-26 15:17:22,040] INFO [ReplicaFetcher replicaId=102, leaderId=103, fetcherId=0] Truncating partition __transaction_state-5 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:17:22,040] INFO [UnifiedLog partition=__transaction_state-5, dir=/tmp/kafka-logs-102] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2024-08-26 15:17:22,040] INFO [ReplicaFetcher replicaId=102, leaderId=103, fetcherId=0] Truncating partition __transaction_state-38 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:17:22,040] INFO [UnifiedLog partition=__transaction_state-38, dir=/tmp/kafka-logs-102] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2024-08-26 15:17:22,040] INFO [ReplicaFetcher replicaId=102, leaderId=103, fetcherId=0] Truncating partition __transaction_state-8 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:17:22,040] INFO [UnifiedLog partition=__transaction_state-8, dir=/tmp/kafka-logs-102] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2024-08-26 15:17:22,040] INFO [ReplicaFetcher replicaId=102, leaderId=103, fetcherId=0] Truncating partition __transaction_state-41 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:17:22,040] INFO [UnifiedLog partition=__transaction_state-41, dir=/tmp/kafka-logs-102] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2024-08-26 15:17:22,040] INFO [ReplicaFetcher replicaId=102, leaderId=103, fetcherId=0] Truncating partition __transaction_state-26 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:17:22,041] INFO [UnifiedLog partition=__transaction_state-26, dir=/tmp/kafka-logs-102] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2024-08-26 15:17:22,041] INFO [ReplicaFetcher replicaId=102, leaderId=103, fetcherId=0] Truncating partition __transaction_state-29 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:17:22,041] INFO [UnifiedLog partition=__transaction_state-29, dir=/tmp/kafka-logs-102] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2024-08-26 15:17:22,041] INFO [ReplicaFetcher replicaId=102, leaderId=103, fetcherId=0] Truncating partition __transaction_state-32 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:17:22,041] INFO [UnifiedLog partition=__transaction_state-32, dir=/tmp/kafka-logs-102] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2024-08-26 15:17:22,041] INFO [ReplicaFetcher replicaId=102, leaderId=103, fetcherId=0] Truncating partition __transaction_state-20 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:17:22,041] INFO [UnifiedLog partition=__transaction_state-20, dir=/tmp/kafka-logs-102] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2024-08-26 15:17:22,041] INFO [ReplicaFetcher replicaId=102, leaderId=103, fetcherId=0] Truncating partition __transaction_state-23 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:17:22,041] INFO [UnifiedLog partition=__transaction_state-23, dir=/tmp/kafka-logs-102] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2024-08-26 15:17:22,059] INFO [ReplicaFetcher replicaId=102, leaderId=101, fetcherId=0] Truncating partition __transaction_state-10 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:17:22,071] INFO [UnifiedLog partition=__transaction_state-10, dir=/tmp/kafka-logs-102] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2024-08-26 15:17:22,071] INFO [ReplicaFetcher replicaId=102, leaderId=101, fetcherId=0] Truncating partition __transaction_state-43 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:17:22,072] INFO [UnifiedLog partition=__transaction_state-43, dir=/tmp/kafka-logs-102] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2024-08-26 15:17:22,072] INFO [ReplicaFetcher replicaId=102, leaderId=101, fetcherId=0] Truncating partition __transaction_state-13 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:17:22,083] INFO [UnifiedLog partition=__transaction_state-13, dir=/tmp/kafka-logs-102] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2024-08-26 15:17:22,083] INFO [ReplicaFetcher replicaId=102, leaderId=101, fetcherId=0] Truncating partition __transaction_state-46 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:17:22,083] INFO [UnifiedLog partition=__transaction_state-46, dir=/tmp/kafka-logs-102] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2024-08-26 15:17:22,084] INFO [ReplicaFetcher replicaId=102, leaderId=101, fetcherId=0] Truncating partition __transaction_state-16 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:17:22,084] INFO [UnifiedLog partition=__transaction_state-16, dir=/tmp/kafka-logs-102] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2024-08-26 15:17:22,085] INFO [ReplicaFetcher replicaId=102, leaderId=101, fetcherId=0] Truncating partition __transaction_state-49 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:17:22,086] INFO [UnifiedLog partition=__transaction_state-49, dir=/tmp/kafka-logs-102] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2024-08-26 15:17:22,086] INFO [ReplicaFetcher replicaId=102, leaderId=101, fetcherId=0] Truncating partition __transaction_state-34 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:17:22,086] INFO [UnifiedLog partition=__transaction_state-34, dir=/tmp/kafka-logs-102] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2024-08-26 15:17:22,086] INFO [ReplicaFetcher replicaId=102, leaderId=101, fetcherId=0] Truncating partition __transaction_state-4 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:17:22,086] INFO [UnifiedLog partition=__transaction_state-4, dir=/tmp/kafka-logs-102] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2024-08-26 15:17:22,086] INFO [ReplicaFetcher replicaId=102, leaderId=101, fetcherId=0] Truncating partition __transaction_state-37 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:17:22,087] INFO [UnifiedLog partition=__transaction_state-37, dir=/tmp/kafka-logs-102] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2024-08-26 15:17:22,087] INFO [ReplicaFetcher replicaId=102, leaderId=101, fetcherId=0] Truncating partition __transaction_state-7 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:17:22,087] INFO [UnifiedLog partition=__transaction_state-7, dir=/tmp/kafka-logs-102] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2024-08-26 15:17:22,087] INFO [ReplicaFetcher replicaId=102, leaderId=101, fetcherId=0] Truncating partition __transaction_state-40 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:17:22,087] INFO [UnifiedLog partition=__transaction_state-40, dir=/tmp/kafka-logs-102] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2024-08-26 15:17:22,087] INFO [ReplicaFetcher replicaId=102, leaderId=101, fetcherId=0] Truncating partition __transaction_state-28 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:17:22,087] INFO [UnifiedLog partition=__transaction_state-28, dir=/tmp/kafka-logs-102] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2024-08-26 15:17:22,087] INFO [ReplicaFetcher replicaId=102, leaderId=101, fetcherId=0] Truncating partition __transaction_state-31 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:17:22,088] INFO [UnifiedLog partition=__transaction_state-31, dir=/tmp/kafka-logs-102] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2024-08-26 15:17:22,088] INFO [ReplicaFetcher replicaId=102, leaderId=101, fetcherId=0] Truncating partition __transaction_state-1 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:17:22,088] INFO [UnifiedLog partition=__transaction_state-1, dir=/tmp/kafka-logs-102] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2024-08-26 15:17:22,088] INFO [ReplicaFetcher replicaId=102, leaderId=101, fetcherId=0] Truncating partition __transaction_state-19 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:17:22,088] INFO [UnifiedLog partition=__transaction_state-19, dir=/tmp/kafka-logs-102] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2024-08-26 15:17:22,096] INFO [ReplicaFetcher replicaId=102, leaderId=101, fetcherId=0] Truncating partition __transaction_state-22 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:17:22,114] INFO [UnifiedLog partition=__transaction_state-22, dir=/tmp/kafka-logs-102] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2024-08-26 15:17:22,114] INFO [ReplicaFetcher replicaId=102, leaderId=101, fetcherId=0] Truncating partition __transaction_state-25 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:17:22,114] INFO [UnifiedLog partition=__transaction_state-25, dir=/tmp/kafka-logs-102] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2024-08-26 15:17:22,137] INFO [TransactionCoordinator id=102] Initialized transactionalId streams-client-0_0 with producerId 1000 and producer epoch 0 on partition __transaction_state-3 (kafka.coordinator.transaction.TransactionCoordinator)
[2024-08-26 15:20:45,977] INFO [TransactionCoordinator id=102] Initialized transactionalId streams-client-0_0 with producerId 1000 and producer epoch 1 on partition __transaction_state-3 (kafka.coordinator.transaction.TransactionCoordinator)
[2024-08-26 15:21:13,245] INFO [ReplicaFetcherManager on broker 102] Removed fetcher for partitions Set(doubled-numbers-2) (kafka.server.ReplicaFetcherManager)
[2024-08-26 15:21:13,250] INFO [LogLoader partition=doubled-numbers-2, dir=/tmp/kafka-logs-102] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-08-26 15:21:13,251] INFO Created log for partition doubled-numbers-2 in /tmp/kafka-logs-102/doubled-numbers-2 with properties {cleanup.policy=delete} (kafka.log.LogManager)
[2024-08-26 15:21:13,252] INFO [Partition doubled-numbers-2 broker=102] No checkpointed highwatermark is found for partition doubled-numbers-2 (kafka.cluster.Partition)
[2024-08-26 15:21:13,275] INFO [Partition doubled-numbers-2 broker=102] Log loaded for partition doubled-numbers-2 with initial high watermark 0 (kafka.cluster.Partition)
[2024-08-26 15:21:24,438] INFO [TransactionCoordinator id=102] Initialized transactionalId streams-client-0_0 with producerId 1000 and producer epoch 2 on partition __transaction_state-3 (kafka.coordinator.transaction.TransactionCoordinator)
[2024-08-26 15:22:28,091] INFO [TransactionCoordinator id=102] Initialized transactionalId streams-client-0_0 with producerId 1000 and producer epoch 3 on partition __transaction_state-3 (kafka.coordinator.transaction.TransactionCoordinator)
[2024-08-26 15:27:21,953] INFO [NodeToControllerChannelManager id=102 name=forwarding] Node 101 disconnected. (org.apache.kafka.clients.NetworkClient)
[2024-08-26 15:28:26,518] INFO [ReplicaFetcherManager on broker 102] Removed fetcher for partitions Set(merged-numbers-1) (kafka.server.ReplicaFetcherManager)
[2024-08-26 15:28:26,525] INFO [LogLoader partition=merged-numbers-1, dir=/tmp/kafka-logs-102] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-08-26 15:28:26,526] INFO Created log for partition merged-numbers-1 in /tmp/kafka-logs-102/merged-numbers-1 with properties {cleanup.policy=delete} (kafka.log.LogManager)
[2024-08-26 15:28:26,527] INFO [Partition merged-numbers-1 broker=102] No checkpointed highwatermark is found for partition merged-numbers-1 (kafka.cluster.Partition)
[2024-08-26 15:28:26,527] INFO [Partition merged-numbers-1 broker=102] Log loaded for partition merged-numbers-1 with initial high watermark 0 (kafka.cluster.Partition)
[2024-08-26 15:28:55,243] INFO [TransactionCoordinator id=102] Initialized transactionalId streams-client-0_0 with producerId 1000 and producer epoch 4 on partition __transaction_state-3 (kafka.coordinator.transaction.TransactionCoordinator)
[2024-08-26 15:30:51,330] INFO [ReplicaFetcher replicaId=102, leaderId=101, fetcherId=0] Disconnecting from node 101 due to request timeout. (org.apache.kafka.clients.NetworkClient)
[2024-08-26 15:30:51,488] WARN Client session timed out, have not heard from server in 49309ms for session id 0x1000014c98f0001 (org.apache.zookeeper.ClientCnxn)
[2024-08-26 15:30:51,333] INFO [ReplicaFetcher replicaId=102, leaderId=103, fetcherId=0] Disconnecting from node 103 due to request timeout. (org.apache.kafka.clients.NetworkClient)
[2024-08-26 15:30:52,534] INFO [ReplicaFetcher replicaId=102, leaderId=103, fetcherId=0] Cancelled in-flight FETCH request with correlation id 33324 due to node 103 being disconnected (elapsed time since creation: 62286ms, elapsed time since send: 62286ms, request timeout: 30000ms) (org.apache.kafka.clients.NetworkClient)
[2024-08-26 15:30:52,534] INFO [ReplicaFetcher replicaId=102, leaderId=101, fetcherId=0] Cancelled in-flight FETCH request with correlation id 15917 due to node 101 being disconnected (elapsed time since creation: 62287ms, elapsed time since send: 62287ms, request timeout: 30000ms) (org.apache.kafka.clients.NetworkClient)
[2024-08-26 15:30:52,702] INFO [ReplicaFetcher replicaId=102, leaderId=101, fetcherId=0] Client requested connection close from node 101 (org.apache.kafka.clients.NetworkClient)
[2024-08-26 15:30:52,702] INFO [ReplicaFetcher replicaId=102, leaderId=103, fetcherId=0] Client requested connection close from node 103 (org.apache.kafka.clients.NetworkClient)
[2024-08-26 15:30:53,011] INFO [ReplicaFetcher replicaId=102, leaderId=101, fetcherId=0] Error sending fetch request (sessionId=1560371175, epoch=15915) to node 101: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Connection to 101 was disconnected before the response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:100)
	at kafka.server.BrokerBlockingSender.sendRequest(BrokerBlockingSender.scala:113)
	at kafka.server.RemoteLeaderEndPoint.fetch(RemoteLeaderEndPoint.scala:79)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:317)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:131)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:130)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:113)
	at kafka.server.ReplicaFetcherThread.doWork(ReplicaFetcherThread.scala:98)
	at org.apache.kafka.server.util.ShutdownableThread.run(ShutdownableThread.java:135)
[2024-08-26 15:30:53,011] INFO [ReplicaFetcher replicaId=102, leaderId=103, fetcherId=0] Error sending fetch request (sessionId=204427536, epoch=33322) to node 103: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Connection to 103 was disconnected before the response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:100)
	at kafka.server.BrokerBlockingSender.sendRequest(BrokerBlockingSender.scala:113)
	at kafka.server.RemoteLeaderEndPoint.fetch(RemoteLeaderEndPoint.scala:79)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:317)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:131)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:130)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:113)
	at kafka.server.ReplicaFetcherThread.doWork(ReplicaFetcherThread.scala:98)
	at org.apache.kafka.server.util.ShutdownableThread.run(ShutdownableThread.java:135)
[2024-08-26 15:30:53,011] WARN Session 0x1000014c98f0001 for server localhost/127.0.0.1:2181, Closing socket connection. Attempting reconnect except it is a SessionExpiredException. (org.apache.zookeeper.ClientCnxn)
org.apache.zookeeper.ClientCnxn$SessionTimeoutException: Client session timed out, have not heard from server in 49309ms for session id 0x1000014c98f0001
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1257)
[2024-08-26 15:30:53,785] WARN [ReplicaFetcher replicaId=102, leaderId=101, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=102, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={__transaction_state-1=PartitionData(topicId=GeNTnPQnQvCfhJ6N7pXZsQ, fetchOffset=12997, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[0], lastFetchedEpoch=Optional[0])}, isolationLevel=READ_UNCOMMITTED, removed=, replaced=, metadata=(sessionId=1560371175, epoch=15915), rackId=) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to 101 was disconnected before the response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:100)
	at kafka.server.BrokerBlockingSender.sendRequest(BrokerBlockingSender.scala:113)
	at kafka.server.RemoteLeaderEndPoint.fetch(RemoteLeaderEndPoint.scala:79)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:317)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:131)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:130)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:113)
	at kafka.server.ReplicaFetcherThread.doWork(ReplicaFetcherThread.scala:98)
	at org.apache.kafka.server.util.ShutdownableThread.run(ShutdownableThread.java:135)
[2024-08-26 15:30:53,785] WARN [ReplicaFetcher replicaId=102, leaderId=103, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=102, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={__consumer_offsets-31=PartitionData(topicId=YjLy0o7SQV-jY9Xq9d2rFw, fetchOffset=17634, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[0], lastFetchedEpoch=Optional[0])}, isolationLevel=READ_UNCOMMITTED, removed=, replaced=, metadata=(sessionId=204427536, epoch=33322), rackId=) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to 103 was disconnected before the response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:100)
	at kafka.server.BrokerBlockingSender.sendRequest(BrokerBlockingSender.scala:113)
	at kafka.server.RemoteLeaderEndPoint.fetch(RemoteLeaderEndPoint.scala:79)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:317)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:131)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:130)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:113)
	at kafka.server.ReplicaFetcherThread.doWork(ReplicaFetcherThread.scala:98)
	at org.apache.kafka.server.util.ShutdownableThread.run(ShutdownableThread.java:135)
[2024-08-26 15:30:55,544] INFO Opening socket connection to server localhost/[0:0:0:0:0:0:0:1]:2181. (org.apache.zookeeper.ClientCnxn)
[2024-08-26 15:30:55,550] INFO Socket connection established, initiating session, client: /[0:0:0:0:0:0:0:1]:51809, server: localhost/[0:0:0:0:0:0:0:1]:2181 (org.apache.zookeeper.ClientCnxn)
[2024-08-26 15:30:55,595] WARN Unable to reconnect to ZooKeeper service, session 0x1000014c98f0001 has expired (org.apache.zookeeper.ClientCnxn)
[2024-08-26 15:30:55,605] WARN Session 0x1000014c98f0001 for server localhost/[0:0:0:0:0:0:0:1]:2181, Closing socket connection. Attempting reconnect except it is a SessionExpiredException. (org.apache.zookeeper.ClientCnxn)
org.apache.zookeeper.ClientCnxn$SessionExpiredException: Unable to reconnect to ZooKeeper service, session 0x1000014c98f0001 has expired
	at org.apache.zookeeper.ClientCnxn$SendThread.onConnected(ClientCnxn.java:1439)
	at org.apache.zookeeper.ClientCnxnSocket.readConnectResult(ClientCnxnSocket.java:154)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doIO(ClientCnxnSocketNIO.java:86)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:350)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1289)
[2024-08-26 15:30:55,624] INFO EventThread shut down for session: 0x1000014c98f0001 (org.apache.zookeeper.ClientCnxn)
[2024-08-26 15:30:55,638] INFO [ZooKeeperClient Kafka server] Session expired. (kafka.zookeeper.ZooKeeperClient)
[2024-08-26 15:30:55,921] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2024-08-26 15:30:55,921] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@7d94beb9 (org.apache.zookeeper.ZooKeeper)
[2024-08-26 15:30:55,922] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2024-08-26 15:30:55,923] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2024-08-26 15:30:55,924] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2024-08-26 15:30:55,924] INFO Socket connection established, initiating session, client: /127.0.0.1:51815, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2024-08-26 15:30:55,964] INFO Session establishment complete on server localhost/127.0.0.1:2181, session id = 0x1000014c98f0005, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2024-08-26 15:30:58,361] INFO [ReplicaFetcher replicaId=102, leaderId=103, fetcherId=0] Partition __transaction_state-11 has an older epoch (0) than the current leader. Will await the new LeaderAndIsr state before resuming fetching. (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:30:57,362] INFO [ReplicaFetcher replicaId=102, leaderId=101, fetcherId=0] Partition __transaction_state-7 has an older epoch (0) than the current leader. Will await the new LeaderAndIsr state before resuming fetching. (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:30:55,972] INFO Creating /brokers/ids/102 (is it secure? false) (kafka.zk.KafkaZkClient)
[2024-08-26 15:31:04,252] WARN [ReplicaFetcher replicaId=102, leaderId=101, fetcherId=0] Partition __transaction_state-7 marked as failed (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:31:04,253] WARN [ReplicaFetcher replicaId=102, leaderId=103, fetcherId=0] Partition __transaction_state-11 marked as failed (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:31:04,305] INFO [ReplicaFetcher replicaId=102, leaderId=103, fetcherId=0] Partition __consumer_offsets-13 has an older epoch (0) than the current leader. Will await the new LeaderAndIsr state before resuming fetching. (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:31:04,302] INFO Stat of the created znode at /brokers/ids/102 is: 620,620,1724666464253,1724666464253,1,0,0,72057683318865925,202,0,620
 (kafka.zk.KafkaZkClient)
[2024-08-26 15:31:04,306] WARN [ReplicaFetcher replicaId=102, leaderId=103, fetcherId=0] Partition __consumer_offsets-13 marked as failed (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:31:04,255] INFO [MetadataCache brokerId=102] Updated cache from existing Some(Features(version=3.7-IV4, finalizedFeatures={}, finalizedFeaturesEpoch=0)) to latest Features(version=3.7-IV4, finalizedFeatures={}, finalizedFeaturesEpoch=0). (kafka.server.metadata.ZkMetadataCache)
[2024-08-26 15:31:04,307] INFO Registered broker 102 at path /brokers/ids/102 with addresses: PLAINTEXT://localhost:9093, czxid (broker epoch): 620 (kafka.zk.KafkaZkClient)
[2024-08-26 15:31:04,253] INFO [ReplicaFetcher replicaId=102, leaderId=101, fetcherId=0] Partition __consumer_offsets-3 has an older epoch (0) than the current leader. Will await the new LeaderAndIsr state before resuming fetching. (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:31:04,306] INFO [ReplicaFetcher replicaId=102, leaderId=103, fetcherId=0] Partition __transaction_state-44 has an older epoch (0) than the current leader. Will await the new LeaderAndIsr state before resuming fetching. (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:31:04,329] WARN [ReplicaFetcher replicaId=102, leaderId=103, fetcherId=0] Partition __transaction_state-44 marked as failed (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:31:04,329] INFO [ReplicaFetcher replicaId=102, leaderId=103, fetcherId=0] Partition __consumer_offsets-46 has an older epoch (0) than the current leader. Will await the new LeaderAndIsr state before resuming fetching. (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:31:04,329] WARN [ReplicaFetcher replicaId=102, leaderId=101, fetcherId=0] Partition __consumer_offsets-3 marked as failed (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:31:04,347] INFO [ReplicaFetcher replicaId=102, leaderId=101, fetcherId=0] Partition __transaction_state-22 has an older epoch (0) than the current leader. Will await the new LeaderAndIsr state before resuming fetching. (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:31:04,330] WARN [ReplicaFetcher replicaId=102, leaderId=103, fetcherId=0] Partition __consumer_offsets-46 marked as failed (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:31:04,347] INFO [ReplicaFetcher replicaId=102, leaderId=103, fetcherId=0] Partition __transaction_state-17 has an older epoch (0) than the current leader. Will await the new LeaderAndIsr state before resuming fetching. (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:31:04,347] WARN [ReplicaFetcher replicaId=102, leaderId=101, fetcherId=0] Partition __transaction_state-22 marked as failed (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:31:04,347] WARN [ReplicaFetcher replicaId=102, leaderId=103, fetcherId=0] Partition __transaction_state-17 marked as failed (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:31:04,354] INFO [ReplicaFetcher replicaId=102, leaderId=103, fetcherId=0] Partition __transaction_state-5 has an older epoch (0) than the current leader. Will await the new LeaderAndIsr state before resuming fetching. (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:31:04,348] INFO [ReplicaFetcher replicaId=102, leaderId=101, fetcherId=0] Partition __transaction_state-37 has an older epoch (0) than the current leader. Will await the new LeaderAndIsr state before resuming fetching. (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:31:04,354] WARN [ReplicaFetcher replicaId=102, leaderId=103, fetcherId=0] Partition __transaction_state-5 marked as failed (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:31:04,354] INFO [ReplicaFetcher replicaId=102, leaderId=103, fetcherId=0] Partition __consumer_offsets-19 has an older epoch (0) than the current leader. Will await the new LeaderAndIsr state before resuming fetching. (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:31:04,355] WARN [ReplicaFetcher replicaId=102, leaderId=101, fetcherId=0] Partition __transaction_state-37 marked as failed (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:31:04,355] WARN [ReplicaFetcher replicaId=102, leaderId=103, fetcherId=0] Partition __consumer_offsets-19 marked as failed (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:31:04,363] INFO [ReplicaFetcher replicaId=102, leaderId=103, fetcherId=0] Partition __transaction_state-38 has an older epoch (0) than the current leader. Will await the new LeaderAndIsr state before resuming fetching. (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:31:04,364] INFO [ReplicaFetcher replicaId=102, leaderId=101, fetcherId=0] Partition __consumer_offsets-18 has an older epoch (0) than the current leader. Will await the new LeaderAndIsr state before resuming fetching. (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:31:04,364] WARN [ReplicaFetcher replicaId=102, leaderId=101, fetcherId=0] Partition __consumer_offsets-18 marked as failed (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:31:04,364] INFO [ReplicaFetcher replicaId=102, leaderId=101, fetcherId=0] Partition __consumer_offsets-33 has an older epoch (0) than the current leader. Will await the new LeaderAndIsr state before resuming fetching. (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:31:04,365] WARN [ReplicaFetcher replicaId=102, leaderId=101, fetcherId=0] Partition __consumer_offsets-33 marked as failed (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:31:04,364] WARN [ReplicaFetcher replicaId=102, leaderId=103, fetcherId=0] Partition __transaction_state-38 marked as failed (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:31:04,365] INFO [ReplicaFetcher replicaId=102, leaderId=103, fetcherId=0] Partition __transaction_state-26 has an older epoch (0) than the current leader. Will await the new LeaderAndIsr state before resuming fetching. (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:31:04,366] WARN [ReplicaFetcher replicaId=102, leaderId=103, fetcherId=0] Partition __transaction_state-26 marked as failed (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:31:04,366] INFO [ReplicaFetcher replicaId=102, leaderId=103, fetcherId=0] Partition __consumer_offsets-28 has an older epoch (0) than the current leader. Will await the new LeaderAndIsr state before resuming fetching. (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:31:04,367] WARN [ReplicaFetcher replicaId=102, leaderId=103, fetcherId=0] Partition __consumer_offsets-28 marked as failed (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:31:04,367] INFO [ReplicaFetcher replicaId=102, leaderId=103, fetcherId=0] Partition __transaction_state-32 has an older epoch (0) than the current leader. Will await the new LeaderAndIsr state before resuming fetching. (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:31:04,367] WARN [ReplicaFetcher replicaId=102, leaderId=103, fetcherId=0] Partition __transaction_state-32 marked as failed (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:31:04,367] INFO [ReplicaFetcher replicaId=102, leaderId=103, fetcherId=0] Partition __consumer_offsets-7 has an older epoch (0) than the current leader. Will await the new LeaderAndIsr state before resuming fetching. (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:31:04,369] WARN [ReplicaFetcher replicaId=102, leaderId=103, fetcherId=0] Partition __consumer_offsets-7 marked as failed (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:31:04,369] INFO [ReplicaFetcher replicaId=102, leaderId=103, fetcherId=0] Partition __consumer_offsets-40 has an older epoch (0) than the current leader. Will await the new LeaderAndIsr state before resuming fetching. (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:31:04,379] INFO [ReplicaFetcher replicaId=102, leaderId=101, fetcherId=0] Partition __consumer_offsets-15 has an older epoch (0) than the current leader. Will await the new LeaderAndIsr state before resuming fetching. (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:31:04,385] WARN [ReplicaFetcher replicaId=102, leaderId=101, fetcherId=0] Partition __consumer_offsets-15 marked as failed (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:31:04,385] INFO [ReplicaFetcher replicaId=102, leaderId=101, fetcherId=0] Partition __consumer_offsets-48 has an older epoch (0) than the current leader. Will await the new LeaderAndIsr state before resuming fetching. (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:31:04,385] WARN [ReplicaFetcher replicaId=102, leaderId=103, fetcherId=0] Partition __consumer_offsets-40 marked as failed (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:31:04,385] WARN [ReplicaFetcher replicaId=102, leaderId=101, fetcherId=0] Partition __consumer_offsets-48 marked as failed (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:31:04,402] INFO [ReplicaFetcher replicaId=102, leaderId=103, fetcherId=0] Partition __transaction_state-20 has an older epoch (0) than the current leader. Will await the new LeaderAndIsr state before resuming fetching. (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:31:04,402] INFO [ReplicaFetcher replicaId=102, leaderId=101, fetcherId=0] Partition __transaction_state-13 has an older epoch (0) than the current leader. Will await the new LeaderAndIsr state before resuming fetching. (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:31:04,402] WARN [ReplicaFetcher replicaId=102, leaderId=103, fetcherId=0] Partition __transaction_state-20 marked as failed (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:31:04,403] INFO [ReplicaFetcher replicaId=102, leaderId=103, fetcherId=0] Partition __consumer_offsets-1 has an older epoch (0) than the current leader. Will await the new LeaderAndIsr state before resuming fetching. (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:31:04,402] WARN [ReplicaFetcher replicaId=102, leaderId=101, fetcherId=0] Partition __transaction_state-13 marked as failed (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:31:04,403] INFO [ReplicaFetcher replicaId=102, leaderId=101, fetcherId=0] Partition __transaction_state-46 has an older epoch (0) than the current leader. Will await the new LeaderAndIsr state before resuming fetching. (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:31:04,404] WARN [ReplicaFetcher replicaId=102, leaderId=103, fetcherId=0] Partition __consumer_offsets-1 marked as failed (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:31:04,404] INFO [ReplicaFetcher replicaId=102, leaderId=103, fetcherId=0] Partition __consumer_offsets-34 has an older epoch (0) than the current leader. Will await the new LeaderAndIsr state before resuming fetching. (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:31:04,404] WARN [ReplicaFetcher replicaId=102, leaderId=101, fetcherId=0] Partition __transaction_state-46 marked as failed (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:31:04,405] INFO [ReplicaFetcher replicaId=102, leaderId=101, fetcherId=0] Partition __consumer_offsets-9 has an older epoch (0) than the current leader. Will await the new LeaderAndIsr state before resuming fetching. (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:31:04,405] WARN [ReplicaFetcher replicaId=102, leaderId=103, fetcherId=0] Partition __consumer_offsets-34 marked as failed (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:31:04,405] WARN [ReplicaFetcher replicaId=102, leaderId=101, fetcherId=0] Partition __consumer_offsets-9 marked as failed (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:31:04,405] INFO [ReplicaFetcher replicaId=102, leaderId=103, fetcherId=0] Partition __consumer_offsets-16 has an older epoch (0) than the current leader. Will await the new LeaderAndIsr state before resuming fetching. (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:31:04,405] INFO [ReplicaFetcher replicaId=102, leaderId=101, fetcherId=0] Partition __consumer_offsets-42 has an older epoch (0) than the current leader. Will await the new LeaderAndIsr state before resuming fetching. (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:31:04,409] WARN [ReplicaFetcher replicaId=102, leaderId=101, fetcherId=0] Partition __consumer_offsets-42 marked as failed (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:31:04,409] WARN [ReplicaFetcher replicaId=102, leaderId=103, fetcherId=0] Partition __consumer_offsets-16 marked as failed (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:31:04,409] INFO [ReplicaFetcher replicaId=102, leaderId=101, fetcherId=0] Partition __transaction_state-34 has an older epoch (0) than the current leader. Will await the new LeaderAndIsr state before resuming fetching. (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:31:04,409] INFO [ReplicaFetcher replicaId=102, leaderId=103, fetcherId=0] Partition __consumer_offsets-43 has an older epoch (0) than the current leader. Will await the new LeaderAndIsr state before resuming fetching. (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:31:04,409] WARN [ReplicaFetcher replicaId=102, leaderId=101, fetcherId=0] Partition __transaction_state-34 marked as failed (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:31:04,409] WARN [ReplicaFetcher replicaId=102, leaderId=103, fetcherId=0] Partition __consumer_offsets-43 marked as failed (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:31:04,409] INFO [ReplicaFetcher replicaId=102, leaderId=101, fetcherId=0] Partition __consumer_offsets-21 has an older epoch (0) than the current leader. Will await the new LeaderAndIsr state before resuming fetching. (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:31:04,410] INFO [ReplicaFetcher replicaId=102, leaderId=103, fetcherId=0] Partition __transaction_state-14 has an older epoch (0) than the current leader. Will await the new LeaderAndIsr state before resuming fetching. (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:31:04,411] WARN [ReplicaFetcher replicaId=102, leaderId=101, fetcherId=0] Partition __consumer_offsets-21 marked as failed (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:31:04,411] WARN [ReplicaFetcher replicaId=102, leaderId=103, fetcherId=0] Partition __transaction_state-14 marked as failed (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:31:04,411] INFO [ReplicaFetcher replicaId=102, leaderId=103, fetcherId=0] Partition __transaction_state-47 has an older epoch (0) than the current leader. Will await the new LeaderAndIsr state before resuming fetching. (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:31:04,411] INFO [ReplicaFetcher replicaId=102, leaderId=101, fetcherId=0] Partition __transaction_state-40 has an older epoch (0) than the current leader. Will await the new LeaderAndIsr state before resuming fetching. (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:31:04,411] WARN [ReplicaFetcher replicaId=102, leaderId=103, fetcherId=0] Partition __transaction_state-47 marked as failed (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:31:04,418] INFO [ReplicaFetcher replicaId=102, leaderId=103, fetcherId=0] Partition __consumer_offsets-10 has an older epoch (0) than the current leader. Will await the new LeaderAndIsr state before resuming fetching. (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:31:04,418] WARN [ReplicaFetcher replicaId=102, leaderId=101, fetcherId=0] Partition __transaction_state-40 marked as failed (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:31:04,418] INFO [ReplicaFetcher replicaId=102, leaderId=101, fetcherId=0] Partition __transaction_state-28 has an older epoch (0) than the current leader. Will await the new LeaderAndIsr state before resuming fetching. (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:31:04,418] WARN [ReplicaFetcher replicaId=102, leaderId=103, fetcherId=0] Partition __consumer_offsets-10 marked as failed (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:31:04,418] INFO [ReplicaFetcher replicaId=102, leaderId=103, fetcherId=0] Partition __transaction_state-2 has an older epoch (0) than the current leader. Will await the new LeaderAndIsr state before resuming fetching. (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:31:04,418] WARN [ReplicaFetcher replicaId=102, leaderId=101, fetcherId=0] Partition __transaction_state-28 marked as failed (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:31:04,418] INFO [ReplicaFetcher replicaId=102, leaderId=101, fetcherId=0] Partition __consumer_offsets-30 has an older epoch (0) than the current leader. Will await the new LeaderAndIsr state before resuming fetching. (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:31:04,418] WARN [ReplicaFetcher replicaId=102, leaderId=103, fetcherId=0] Partition __transaction_state-2 marked as failed (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:31:04,419] WARN [ReplicaFetcher replicaId=102, leaderId=101, fetcherId=0] Partition __consumer_offsets-30 marked as failed (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:31:04,419] INFO [ReplicaFetcher replicaId=102, leaderId=103, fetcherId=0] Partition __transaction_state-35 has an older epoch (0) than the current leader. Will await the new LeaderAndIsr state before resuming fetching. (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:31:04,419] INFO [ReplicaFetcher replicaId=102, leaderId=101, fetcherId=0] Partition __transaction_state-1 has an older epoch (0) than the current leader. Will await the new LeaderAndIsr state before resuming fetching. (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:31:04,420] WARN [ReplicaFetcher replicaId=102, leaderId=103, fetcherId=0] Partition __transaction_state-35 marked as failed (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:31:04,420] WARN [ReplicaFetcher replicaId=102, leaderId=101, fetcherId=0] Partition __transaction_state-1 marked as failed (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:31:04,420] INFO [ReplicaFetcher replicaId=102, leaderId=103, fetcherId=0] Partition __consumer_offsets-22 has an older epoch (0) than the current leader. Will await the new LeaderAndIsr state before resuming fetching. (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:31:04,420] INFO [ReplicaFetcher replicaId=102, leaderId=101, fetcherId=0] Partition __consumer_offsets-36 has an older epoch (0) than the current leader. Will await the new LeaderAndIsr state before resuming fetching. (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:31:04,420] WARN [ReplicaFetcher replicaId=102, leaderId=103, fetcherId=0] Partition __consumer_offsets-22 marked as failed (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:31:04,421] INFO [ReplicaFetcher replicaId=102, leaderId=103, fetcherId=0] Partition __consumer_offsets-49 has an older epoch (0) than the current leader. Will await the new LeaderAndIsr state before resuming fetching. (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:31:04,421] WARN [ReplicaFetcher replicaId=102, leaderId=101, fetcherId=0] Partition __consumer_offsets-36 marked as failed (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:31:04,421] INFO [ReplicaFetcher replicaId=102, leaderId=101, fetcherId=0] Partition __transaction_state-10 has an older epoch (0) than the current leader. Will await the new LeaderAndIsr state before resuming fetching. (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:31:04,421] WARN [ReplicaFetcher replicaId=102, leaderId=103, fetcherId=0] Partition __consumer_offsets-49 marked as failed (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:31:04,422] INFO [ReplicaFetcher replicaId=102, leaderId=103, fetcherId=0] Partition __transaction_state-8 has an older epoch (0) than the current leader. Will await the new LeaderAndIsr state before resuming fetching. (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:31:04,422] WARN [ReplicaFetcher replicaId=102, leaderId=101, fetcherId=0] Partition __transaction_state-10 marked as failed (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:31:04,422] WARN [ReplicaFetcher replicaId=102, leaderId=103, fetcherId=0] Partition __transaction_state-8 marked as failed (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:31:04,422] INFO [ReplicaFetcher replicaId=102, leaderId=101, fetcherId=0] Partition __transaction_state-43 has an older epoch (0) than the current leader. Will await the new LeaderAndIsr state before resuming fetching. (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:31:04,422] INFO [ReplicaFetcher replicaId=102, leaderId=103, fetcherId=0] Partition __transaction_state-41 has an older epoch (0) than the current leader. Will await the new LeaderAndIsr state before resuming fetching. (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:31:04,423] WARN [ReplicaFetcher replicaId=102, leaderId=103, fetcherId=0] Partition __transaction_state-41 marked as failed (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:31:04,423] INFO [ReplicaFetcher replicaId=102, leaderId=103, fetcherId=0] Partition __consumer_offsets-31 has an older epoch (0) than the current leader. Will await the new LeaderAndIsr state before resuming fetching. (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:31:04,423] WARN [ReplicaFetcher replicaId=102, leaderId=103, fetcherId=0] Partition __consumer_offsets-31 marked as failed (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:31:04,423] WARN [ReplicaFetcher replicaId=102, leaderId=101, fetcherId=0] Partition __transaction_state-43 marked as failed (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:31:04,447] INFO [ReplicaFetcher replicaId=102, leaderId=103, fetcherId=0] Partition __transaction_state-29 has an older epoch (0) than the current leader. Will await the new LeaderAndIsr state before resuming fetching. (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:31:04,447] INFO [ReplicaFetcher replicaId=102, leaderId=101, fetcherId=0] Partition __consumer_offsets-45 has an older epoch (0) than the current leader. Will await the new LeaderAndIsr state before resuming fetching. (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:31:04,448] WARN [ReplicaFetcher replicaId=102, leaderId=101, fetcherId=0] Partition __consumer_offsets-45 marked as failed (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:31:04,448] WARN [ReplicaFetcher replicaId=102, leaderId=103, fetcherId=0] Partition __transaction_state-29 marked as failed (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:31:04,448] INFO [ReplicaFetcher replicaId=102, leaderId=101, fetcherId=0] Partition __consumer_offsets-12 has an older epoch (0) than the current leader. Will await the new LeaderAndIsr state before resuming fetching. (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:31:04,448] INFO [ReplicaFetcher replicaId=102, leaderId=103, fetcherId=0] Partition __consumer_offsets-25 has an older epoch (0) than the current leader. Will await the new LeaderAndIsr state before resuming fetching. (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:31:04,449] WARN [ReplicaFetcher replicaId=102, leaderId=101, fetcherId=0] Partition __consumer_offsets-12 marked as failed (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:31:04,449] WARN [ReplicaFetcher replicaId=102, leaderId=103, fetcherId=0] Partition __consumer_offsets-25 marked as failed (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:31:04,449] INFO [ReplicaFetcher replicaId=102, leaderId=101, fetcherId=0] Partition __transaction_state-16 has an older epoch (0) than the current leader. Will await the new LeaderAndIsr state before resuming fetching. (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:31:04,449] INFO [ReplicaFetcher replicaId=102, leaderId=103, fetcherId=0] Partition __consumer_offsets-37 has an older epoch (0) than the current leader. Will await the new LeaderAndIsr state before resuming fetching. (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:31:04,449] WARN [ReplicaFetcher replicaId=102, leaderId=101, fetcherId=0] Partition __transaction_state-16 marked as failed (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:31:04,450] WARN [ReplicaFetcher replicaId=102, leaderId=103, fetcherId=0] Partition __consumer_offsets-37 marked as failed (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:31:04,450] INFO [ReplicaFetcher replicaId=102, leaderId=101, fetcherId=0] Partition __transaction_state-49 has an older epoch (0) than the current leader. Will await the new LeaderAndIsr state before resuming fetching. (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:31:04,450] INFO [ReplicaFetcher replicaId=102, leaderId=103, fetcherId=0] Partition __consumer_offsets-4 has an older epoch (0) than the current leader. Will await the new LeaderAndIsr state before resuming fetching. (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:31:04,450] WARN [ReplicaFetcher replicaId=102, leaderId=101, fetcherId=0] Partition __transaction_state-49 marked as failed (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:31:04,450] WARN [ReplicaFetcher replicaId=102, leaderId=103, fetcherId=0] Partition __consumer_offsets-4 marked as failed (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:31:04,451] INFO [ReplicaFetcher replicaId=102, leaderId=101, fetcherId=0] Partition __consumer_offsets-24 has an older epoch (0) than the current leader. Will await the new LeaderAndIsr state before resuming fetching. (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:31:04,451] INFO [ReplicaFetcher replicaId=102, leaderId=103, fetcherId=0] Partition __transaction_state-23 has an older epoch (0) than the current leader. Will await the new LeaderAndIsr state before resuming fetching. (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:31:04,451] WARN [ReplicaFetcher replicaId=102, leaderId=101, fetcherId=0] Partition __consumer_offsets-24 marked as failed (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:31:04,451] WARN [ReplicaFetcher replicaId=102, leaderId=103, fetcherId=0] Partition __transaction_state-23 marked as failed (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:31:04,451] INFO [ReplicaFetcher replicaId=102, leaderId=101, fetcherId=0] Partition __transaction_state-4 has an older epoch (0) than the current leader. Will await the new LeaderAndIsr state before resuming fetching. (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:31:04,452] WARN [ReplicaFetcher replicaId=102, leaderId=101, fetcherId=0] Partition __transaction_state-4 marked as failed (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:31:04,452] INFO [ReplicaFetcher replicaId=102, leaderId=101, fetcherId=0] Partition __consumer_offsets-0 has an older epoch (0) than the current leader. Will await the new LeaderAndIsr state before resuming fetching. (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:31:04,453] WARN [ReplicaFetcher replicaId=102, leaderId=101, fetcherId=0] Partition __consumer_offsets-0 marked as failed (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:31:04,453] INFO [ReplicaFetcher replicaId=102, leaderId=101, fetcherId=0] Partition __consumer_offsets-27 has an older epoch (0) than the current leader. Will await the new LeaderAndIsr state before resuming fetching. (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:31:04,453] WARN [ReplicaFetcher replicaId=102, leaderId=101, fetcherId=0] Partition __consumer_offsets-27 marked as failed (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:31:04,454] INFO [ReplicaFetcher replicaId=102, leaderId=101, fetcherId=0] Partition __transaction_state-31 has an older epoch (0) than the current leader. Will await the new LeaderAndIsr state before resuming fetching. (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:31:04,454] WARN [ReplicaFetcher replicaId=102, leaderId=101, fetcherId=0] Partition __transaction_state-31 marked as failed (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:31:04,454] INFO [ReplicaFetcher replicaId=102, leaderId=101, fetcherId=0] Partition __consumer_offsets-39 has an older epoch (0) than the current leader. Will await the new LeaderAndIsr state before resuming fetching. (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:31:04,454] WARN [ReplicaFetcher replicaId=102, leaderId=101, fetcherId=0] Partition __consumer_offsets-39 marked as failed (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:31:04,454] INFO [ReplicaFetcher replicaId=102, leaderId=101, fetcherId=0] Partition __transaction_state-19 has an older epoch (0) than the current leader. Will await the new LeaderAndIsr state before resuming fetching. (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:31:04,455] WARN [ReplicaFetcher replicaId=102, leaderId=101, fetcherId=0] Partition __transaction_state-19 marked as failed (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:31:04,455] INFO [ReplicaFetcher replicaId=102, leaderId=101, fetcherId=0] Partition __consumer_offsets-6 has an older epoch (0) than the current leader. Will await the new LeaderAndIsr state before resuming fetching. (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:31:04,455] WARN [ReplicaFetcher replicaId=102, leaderId=101, fetcherId=0] Partition __consumer_offsets-6 marked as failed (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:31:04,455] INFO [ReplicaFetcher replicaId=102, leaderId=101, fetcherId=0] Partition __transaction_state-25 has an older epoch (0) than the current leader. Will await the new LeaderAndIsr state before resuming fetching. (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:31:04,455] WARN [ReplicaFetcher replicaId=102, leaderId=101, fetcherId=0] Partition __transaction_state-25 marked as failed (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:31:04,456] INFO [ReplicaFetcherManager on broker 102] Removed fetcher for partitions HashSet(__transaction_state-42, __consumer_offsets-13, __consumer_offsets-46, __transaction_state-17, __transaction_state-34, __consumer_offsets-21, __transaction_state-9, __transaction_state-26, __consumer_offsets-30, __transaction_state-1, __transaction_state-18, __consumer_offsets-5, __consumer_offsets-38, __consumer_offsets-45, __consumer_offsets-12, __transaction_state-16, __transaction_state-49, __consumer_offsets-20, __transaction_state-8, __transaction_state-41, __consumer_offsets-29, __transaction_state-0, __transaction_state-33, __consumer_offsets-37, __consumer_offsets-4, __transaction_state-25, __consumer_offsets-15, __consumer_offsets-48, __transaction_state-15, __transaction_state-48, __consumer_offsets-23, __transaction_state-7, __transaction_state-40, __consumer_offsets-32, __transaction_state-32, __consumer_offsets-7, __consumer_offsets-40, __transaction_state-24, __consumer_offsets-47, __consumer_offsets-14, __transaction_state-14, __transaction_state-47, __consumer_offsets-22, __transaction_state-6, __transaction_state-39, __consumer_offsets-31, __transaction_state-31, __consumer_offsets-39, __consumer_offsets-6, __transaction_state-23, __transaction_state-13, __transaction_state-46, __consumer_offsets-9, __consumer_offsets-42, __transaction_state-5, __transaction_state-38, __consumer_offsets-17, __transaction_state-30, __consumer_offsets-26, __transaction_state-22, __consumer_offsets-1, __consumer_offsets-34, __consumer_offsets-16, __transaction_state-12, __transaction_state-45, __consumer_offsets-41, __consumer_offsets-24, __transaction_state-4, __transaction_state-37, __consumer_offsets-49, __consumer_offsets-0, __transaction_state-29, __consumer_offsets-25, __consumer_offsets-8, __transaction_state-21, __consumer_offsets-33, __transaction_state-11, __transaction_state-44, __consumer_offsets-11, __consumer_offsets-44, __transaction_state-3, __transaction_state-36, __consumer_offsets-19, __transaction_state-28, __consumer_offsets-28, __transaction_state-20, __consumer_offsets-3, __consumer_offsets-36, __transaction_state-10, __transaction_state-43, __consumer_offsets-43, __consumer_offsets-10, __transaction_state-2, __transaction_state-35, __consumer_offsets-18, __transaction_state-27, __consumer_offsets-27, __transaction_state-19, __consumer_offsets-35, __consumer_offsets-2) (kafka.server.ReplicaFetcherManager)
[2024-08-26 15:31:04,471] INFO [ReplicaFetcher replicaId=102, leaderId=101, fetcherId=0] Truncating partition __consumer_offsets-13 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:31:04,472] INFO [UnifiedLog partition=__consumer_offsets-13, dir=/tmp/kafka-logs-102] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2024-08-26 15:31:04,473] INFO [ReplicaFetcher replicaId=102, leaderId=101, fetcherId=0] Truncating partition __consumer_offsets-46 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:31:04,473] INFO [UnifiedLog partition=__consumer_offsets-46, dir=/tmp/kafka-logs-102] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2024-08-26 15:31:04,473] INFO [ReplicaFetcher replicaId=102, leaderId=101, fetcherId=0] Truncating partition __transaction_state-13 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:31:04,475] INFO [ReplicaFetcherManager on broker 102] Added fetcher to broker 101 for partitions HashMap(__transaction_state-7 -> InitialFetchState(Some(GeNTnPQnQvCfhJ6N7pXZsQ),BrokerEndPoint(id=101, host=localhost:9092),2,0), __consumer_offsets-25 -> InitialFetchState(Some(YjLy0o7SQV-jY9Xq9d2rFw),BrokerEndPoint(id=101, host=localhost:9092),3,0), __transaction_state-0 -> InitialFetchState(Some(GeNTnPQnQvCfhJ6N7pXZsQ),BrokerEndPoint(id=101, host=localhost:9092),3,0), __transaction_state-6 -> InitialFetchState(Some(GeNTnPQnQvCfhJ6N7pXZsQ),BrokerEndPoint(id=101, host=localhost:9092),3,0), __transaction_state-18 -> InitialFetchState(Some(GeNTnPQnQvCfhJ6N7pXZsQ),BrokerEndPoint(id=101, host=localhost:9092),3,0), __consumer_offsets-22 -> InitialFetchState(Some(YjLy0o7SQV-jY9Xq9d2rFw),BrokerEndPoint(id=101, host=localhost:9092),3,0), __transaction_state-42 -> InitialFetchState(Some(GeNTnPQnQvCfhJ6N7pXZsQ),BrokerEndPoint(id=101, host=localhost:9092),3,0), __consumer_offsets-30 -> InitialFetchState(Some(YjLy0o7SQV-jY9Xq9d2rFw),BrokerEndPoint(id=101, host=localhost:9092),2,0), __transaction_state-31 -> InitialFetchState(Some(GeNTnPQnQvCfhJ6N7pXZsQ),BrokerEndPoint(id=101, host=localhost:9092),2,0), __transaction_state-45 -> InitialFetchState(Some(GeNTnPQnQvCfhJ6N7pXZsQ),BrokerEndPoint(id=101, host=localhost:9092),3,0), __transaction_state-15 -> InitialFetchState(Some(GeNTnPQnQvCfhJ6N7pXZsQ),BrokerEndPoint(id=101, host=localhost:9092),3,0), __transaction_state-12 -> InitialFetchState(Some(GeNTnPQnQvCfhJ6N7pXZsQ),BrokerEndPoint(id=101, host=localhost:9092),3,0), __consumer_offsets-8 -> InitialFetchState(Some(YjLy0o7SQV-jY9Xq9d2rFw),BrokerEndPoint(id=101, host=localhost:9092),3,0), __consumer_offsets-21 -> InitialFetchState(Some(YjLy0o7SQV-jY9Xq9d2rFw),BrokerEndPoint(id=101, host=localhost:9092),2,0), __consumer_offsets-4 -> InitialFetchState(Some(YjLy0o7SQV-jY9Xq9d2rFw),BrokerEndPoint(id=101, host=localhost:9092),3,0), __transaction_state-46 -> InitialFetchState(Some(GeNTnPQnQvCfhJ6N7pXZsQ),BrokerEndPoint(id=101, host=localhost:9092),2,0), __consumer_offsets-27 -> InitialFetchState(Some(YjLy0o7SQV-jY9Xq9d2rFw),BrokerEndPoint(id=101, host=localhost:9092),2,0), __consumer_offsets-7 -> InitialFetchState(Some(YjLy0o7SQV-jY9Xq9d2rFw),BrokerEndPoint(id=101, host=localhost:9092),3,0), __transaction_state-48 -> InitialFetchState(Some(GeNTnPQnQvCfhJ6N7pXZsQ),BrokerEndPoint(id=101, host=localhost:9092),3,0), __consumer_offsets-9 -> InitialFetchState(Some(YjLy0o7SQV-jY9Xq9d2rFw),BrokerEndPoint(id=101, host=localhost:9092),2,0), __transaction_state-49 -> InitialFetchState(Some(GeNTnPQnQvCfhJ6N7pXZsQ),BrokerEndPoint(id=101, host=localhost:9092),2,0), __consumer_offsets-46 -> InitialFetchState(Some(YjLy0o7SQV-jY9Xq9d2rFw),BrokerEndPoint(id=101, host=localhost:9092),3,0), __consumer_offsets-35 -> InitialFetchState(Some(YjLy0o7SQV-jY9Xq9d2rFw),BrokerEndPoint(id=101, host=localhost:9092),3,0), __transaction_state-28 -> InitialFetchState(Some(GeNTnPQnQvCfhJ6N7pXZsQ),BrokerEndPoint(id=101, host=localhost:9092),2,0), __transaction_state-2 -> InitialFetchState(Some(GeNTnPQnQvCfhJ6N7pXZsQ),BrokerEndPoint(id=101, host=localhost:9092),3,13518), __transaction_state-20 -> InitialFetchState(Some(GeNTnPQnQvCfhJ6N7pXZsQ),BrokerEndPoint(id=101, host=localhost:9092),3,0), __transaction_state-24 -> InitialFetchState(Some(GeNTnPQnQvCfhJ6N7pXZsQ),BrokerEndPoint(id=101, host=localhost:9092),3,0), __consumer_offsets-41 -> InitialFetchState(Some(YjLy0o7SQV-jY9Xq9d2rFw),BrokerEndPoint(id=101, host=localhost:9092),3,0), __consumer_offsets-33 -> InitialFetchState(Some(YjLy0o7SQV-jY9Xq9d2rFw),BrokerEndPoint(id=101, host=localhost:9092),2,0), __consumer_offsets-23 -> InitialFetchState(Some(YjLy0o7SQV-jY9Xq9d2rFw),BrokerEndPoint(id=101, host=localhost:9092),3,0), __transaction_state-13 -> InitialFetchState(Some(GeNTnPQnQvCfhJ6N7pXZsQ),BrokerEndPoint(id=101, host=localhost:9092),2,0), __consumer_offsets-49 -> InitialFetchState(Some(YjLy0o7SQV-jY9Xq9d2rFw),BrokerEndPoint(id=101, host=localhost:9092),3,0), __consumer_offsets-47 -> InitialFetchState(Some(YjLy0o7SQV-jY9Xq9d2rFw),BrokerEndPoint(id=101, host=localhost:9092),3,0), __consumer_offsets-16 -> InitialFetchState(Some(YjLy0o7SQV-jY9Xq9d2rFw),BrokerEndPoint(id=101, host=localhost:9092),3,0), __consumer_offsets-28 -> InitialFetchState(Some(YjLy0o7SQV-jY9Xq9d2rFw),BrokerEndPoint(id=101, host=localhost:9092),3,0), __transaction_state-37 -> InitialFetchState(Some(GeNTnPQnQvCfhJ6N7pXZsQ),BrokerEndPoint(id=101, host=localhost:9092),2,0), __transaction_state-3 -> InitialFetchState(Some(GeNTnPQnQvCfhJ6N7pXZsQ),BrokerEndPoint(id=101, host=localhost:9092),3,12663), __consumer_offsets-31 -> InitialFetchState(Some(YjLy0o7SQV-jY9Xq9d2rFw),BrokerEndPoint(id=101, host=localhost:9092),3,17635), __transaction_state-21 -> InitialFetchState(Some(GeNTnPQnQvCfhJ6N7pXZsQ),BrokerEndPoint(id=101, host=localhost:9092),3,0), __consumer_offsets-36 -> InitialFetchState(Some(YjLy0o7SQV-jY9Xq9d2rFw),BrokerEndPoint(id=101, host=localhost:9092),2,0), __transaction_state-29 -> InitialFetchState(Some(GeNTnPQnQvCfhJ6N7pXZsQ),BrokerEndPoint(id=101, host=localhost:9092),3,0), __consumer_offsets-42 -> InitialFetchState(Some(YjLy0o7SQV-jY9Xq9d2rFw),BrokerEndPoint(id=101, host=localhost:9092),2,0), __consumer_offsets-3 -> InitialFetchState(Some(YjLy0o7SQV-jY9Xq9d2rFw),BrokerEndPoint(id=101, host=localhost:9092),2,0), __consumer_offsets-18 -> InitialFetchState(Some(YjLy0o7SQV-jY9Xq9d2rFw),BrokerEndPoint(id=101, host=localhost:9092),2,0), __transaction_state-39 -> InitialFetchState(Some(GeNTnPQnQvCfhJ6N7pXZsQ),BrokerEndPoint(id=101, host=localhost:9092),3,0), __consumer_offsets-37 -> InitialFetchState(Some(YjLy0o7SQV-jY9Xq9d2rFw),BrokerEndPoint(id=101, host=localhost:9092),3,0), __transaction_state-38 -> InitialFetchState(Some(GeNTnPQnQvCfhJ6N7pXZsQ),BrokerEndPoint(id=101, host=localhost:9092),3,0), __consumer_offsets-15 -> InitialFetchState(Some(YjLy0o7SQV-jY9Xq9d2rFw),BrokerEndPoint(id=101, host=localhost:9092),2,0), __consumer_offsets-24 -> InitialFetchState(Some(YjLy0o7SQV-jY9Xq9d2rFw),BrokerEndPoint(id=101, host=localhost:9092),2,0), __transaction_state-14 -> InitialFetchState(Some(GeNTnPQnQvCfhJ6N7pXZsQ),BrokerEndPoint(id=101, host=localhost:9092),3,0), __transaction_state-10 -> InitialFetchState(Some(GeNTnPQnQvCfhJ6N7pXZsQ),BrokerEndPoint(id=101, host=localhost:9092),2,0), __transaction_state-44 -> InitialFetchState(Some(GeNTnPQnQvCfhJ6N7pXZsQ),BrokerEndPoint(id=101, host=localhost:9092),3,0), __transaction_state-9 -> InitialFetchState(Some(GeNTnPQnQvCfhJ6N7pXZsQ),BrokerEndPoint(id=101, host=localhost:9092),3,0), __transaction_state-22 -> InitialFetchState(Some(GeNTnPQnQvCfhJ6N7pXZsQ),BrokerEndPoint(id=101, host=localhost:9092),2,0), __transaction_state-43 -> InitialFetchState(Some(GeNTnPQnQvCfhJ6N7pXZsQ),BrokerEndPoint(id=101, host=localhost:9092),2,0), __transaction_state-4 -> InitialFetchState(Some(GeNTnPQnQvCfhJ6N7pXZsQ),BrokerEndPoint(id=101, host=localhost:9092),2,0), __transaction_state-30 -> InitialFetchState(Some(GeNTnPQnQvCfhJ6N7pXZsQ),BrokerEndPoint(id=101, host=localhost:9092),3,0), __transaction_state-33 -> InitialFetchState(Some(GeNTnPQnQvCfhJ6N7pXZsQ),BrokerEndPoint(id=101, host=localhost:9092),3,0), __consumer_offsets-38 -> InitialFetchState(Some(YjLy0o7SQV-jY9Xq9d2rFw),BrokerEndPoint(id=101, host=localhost:9092),3,0), __consumer_offsets-48 -> InitialFetchState(Some(YjLy0o7SQV-jY9Xq9d2rFw),BrokerEndPoint(id=101, host=localhost:9092),2,0), __consumer_offsets-17 -> InitialFetchState(Some(YjLy0o7SQV-jY9Xq9d2rFw),BrokerEndPoint(id=101, host=localhost:9092),3,0), __transaction_state-32 -> InitialFetchState(Some(GeNTnPQnQvCfhJ6N7pXZsQ),BrokerEndPoint(id=101, host=localhost:9092),3,0), __transaction_state-25 -> InitialFetchState(Some(GeNTnPQnQvCfhJ6N7pXZsQ),BrokerEndPoint(id=101, host=localhost:9092),2,0), __transaction_state-17 -> InitialFetchState(Some(GeNTnPQnQvCfhJ6N7pXZsQ),BrokerEndPoint(id=101, host=localhost:9092),3,0), __consumer_offsets-19 -> InitialFetchState(Some(YjLy0o7SQV-jY9Xq9d2rFw),BrokerEndPoint(id=101, host=localhost:9092),3,0), __consumer_offsets-11 -> InitialFetchState(Some(YjLy0o7SQV-jY9Xq9d2rFw),BrokerEndPoint(id=101, host=localhost:9092),3,0), __transaction_state-23 -> InitialFetchState(Some(GeNTnPQnQvCfhJ6N7pXZsQ),BrokerEndPoint(id=101, host=localhost:9092),3,0), __transaction_state-47 -> InitialFetchState(Some(GeNTnPQnQvCfhJ6N7pXZsQ),BrokerEndPoint(id=101, host=localhost:9092),3,0), __consumer_offsets-13 -> InitialFetchState(Some(YjLy0o7SQV-jY9Xq9d2rFw),BrokerEndPoint(id=101, host=localhost:9092),3,0), __consumer_offsets-2 -> InitialFetchState(Some(YjLy0o7SQV-jY9Xq9d2rFw),BrokerEndPoint(id=101, host=localhost:9092),3,0), __consumer_offsets-43 -> InitialFetchState(Some(YjLy0o7SQV-jY9Xq9d2rFw),BrokerEndPoint(id=101, host=localhost:9092),3,0), __consumer_offsets-6 -> InitialFetchState(Some(YjLy0o7SQV-jY9Xq9d2rFw),BrokerEndPoint(id=101, host=localhost:9092),2,0), __consumer_offsets-14 -> InitialFetchState(Some(YjLy0o7SQV-jY9Xq9d2rFw),BrokerEndPoint(id=101, host=localhost:9092),3,0), __transaction_state-26 -> InitialFetchState(Some(GeNTnPQnQvCfhJ6N7pXZsQ),BrokerEndPoint(id=101, host=localhost:9092),3,0), __transaction_state-36 -> InitialFetchState(Some(GeNTnPQnQvCfhJ6N7pXZsQ),BrokerEndPoint(id=101, host=localhost:9092),3,0), __transaction_state-5 -> InitialFetchState(Some(GeNTnPQnQvCfhJ6N7pXZsQ),BrokerEndPoint(id=101, host=localhost:9092),3,0), __transaction_state-8 -> InitialFetchState(Some(GeNTnPQnQvCfhJ6N7pXZsQ),BrokerEndPoint(id=101, host=localhost:9092),3,0), __consumer_offsets-0 -> InitialFetchState(Some(YjLy0o7SQV-jY9Xq9d2rFw),BrokerEndPoint(id=101, host=localhost:9092),2,0), __consumer_offsets-44 -> InitialFetchState(Some(YjLy0o7SQV-jY9Xq9d2rFw),BrokerEndPoint(id=101, host=localhost:9092),3,0), __transaction_state-11 -> InitialFetchState(Some(GeNTnPQnQvCfhJ6N7pXZsQ),BrokerEndPoint(id=101, host=localhost:9092),3,0), __consumer_offsets-20 -> InitialFetchState(Some(YjLy0o7SQV-jY9Xq9d2rFw),BrokerEndPoint(id=101, host=localhost:9092),3,0), __transaction_state-16 -> InitialFetchState(Some(GeNTnPQnQvCfhJ6N7pXZsQ),BrokerEndPoint(id=101, host=localhost:9092),2,0), __consumer_offsets-39 -> InitialFetchState(Some(YjLy0o7SQV-jY9Xq9d2rFw),BrokerEndPoint(id=101, host=localhost:9092),2,0), __consumer_offsets-12 -> InitialFetchState(Some(YjLy0o7SQV-jY9Xq9d2rFw),BrokerEndPoint(id=101, host=localhost:9092),2,0), __transaction_state-40 -> InitialFetchState(Some(GeNTnPQnQvCfhJ6N7pXZsQ),BrokerEndPoint(id=101, host=localhost:9092),2,0), __consumer_offsets-45 -> InitialFetchState(Some(YjLy0o7SQV-jY9Xq9d2rFw),BrokerEndPoint(id=101, host=localhost:9092),2,0), __consumer_offsets-1 -> InitialFetchState(Some(YjLy0o7SQV-jY9Xq9d2rFw),BrokerEndPoint(id=101, host=localhost:9092),3,0), __consumer_offsets-5 -> InitialFetchState(Some(YjLy0o7SQV-jY9Xq9d2rFw),BrokerEndPoint(id=101, host=localhost:9092),3,0), __consumer_offsets-26 -> InitialFetchState(Some(YjLy0o7SQV-jY9Xq9d2rFw),BrokerEndPoint(id=101, host=localhost:9092),3,0), __transaction_state-19 -> InitialFetchState(Some(GeNTnPQnQvCfhJ6N7pXZsQ),BrokerEndPoint(id=101, host=localhost:9092),2,0), __transaction_state-27 -> InitialFetchState(Some(GeNTnPQnQvCfhJ6N7pXZsQ),BrokerEndPoint(id=101, host=localhost:9092),3,0), __consumer_offsets-34 -> InitialFetchState(Some(YjLy0o7SQV-jY9Xq9d2rFw),BrokerEndPoint(id=101, host=localhost:9092),3,0), __consumer_offsets-29 -> InitialFetchState(Some(YjLy0o7SQV-jY9Xq9d2rFw),BrokerEndPoint(id=101, host=localhost:9092),3,0), __transaction_state-41 -> InitialFetchState(Some(GeNTnPQnQvCfhJ6N7pXZsQ),BrokerEndPoint(id=101, host=localhost:9092),3,0), __transaction_state-1 -> InitialFetchState(Some(GeNTnPQnQvCfhJ6N7pXZsQ),BrokerEndPoint(id=101, host=localhost:9092),2,12998), __consumer_offsets-10 -> InitialFetchState(Some(YjLy0o7SQV-jY9Xq9d2rFw),BrokerEndPoint(id=101, host=localhost:9092),3,0), __consumer_offsets-32 -> InitialFetchState(Some(YjLy0o7SQV-jY9Xq9d2rFw),BrokerEndPoint(id=101, host=localhost:9092),3,0), __transaction_state-34 -> InitialFetchState(Some(GeNTnPQnQvCfhJ6N7pXZsQ),BrokerEndPoint(id=101, host=localhost:9092),2,0), __transaction_state-35 -> InitialFetchState(Some(GeNTnPQnQvCfhJ6N7pXZsQ),BrokerEndPoint(id=101, host=localhost:9092),3,0), __consumer_offsets-40 -> InitialFetchState(Some(YjLy0o7SQV-jY9Xq9d2rFw),BrokerEndPoint(id=101, host=localhost:9092),3,0)) (kafka.server.ReplicaFetcherManager)
[2024-08-26 15:31:04,497] INFO [UnifiedLog partition=__transaction_state-13, dir=/tmp/kafka-logs-102] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2024-08-26 15:31:04,505] INFO [ReplicaFetcher replicaId=102, leaderId=101, fetcherId=0] Truncating partition __transaction_state-46 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:31:04,505] INFO [UnifiedLog partition=__transaction_state-46, dir=/tmp/kafka-logs-102] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2024-08-26 15:31:04,505] INFO [ReplicaFetcher replicaId=102, leaderId=101, fetcherId=0] Truncating partition __consumer_offsets-9 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:31:04,506] INFO [UnifiedLog partition=__consumer_offsets-9, dir=/tmp/kafka-logs-102] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2024-08-26 15:31:04,506] INFO [ReplicaFetcher replicaId=102, leaderId=101, fetcherId=0] Truncating partition __consumer_offsets-42 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:31:04,506] INFO [UnifiedLog partition=__consumer_offsets-42, dir=/tmp/kafka-logs-102] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2024-08-26 15:31:04,506] INFO [ReplicaFetcher replicaId=102, leaderId=101, fetcherId=0] Truncating partition __transaction_state-17 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:31:04,506] INFO [UnifiedLog partition=__transaction_state-17, dir=/tmp/kafka-logs-102] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2024-08-26 15:31:04,506] INFO [ReplicaFetcher replicaId=102, leaderId=101, fetcherId=0] Truncating partition __transaction_state-34 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:31:04,506] INFO [UnifiedLog partition=__transaction_state-34, dir=/tmp/kafka-logs-102] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2024-08-26 15:31:04,506] INFO [ReplicaFetcher replicaId=102, leaderId=101, fetcherId=0] Truncating partition __consumer_offsets-21 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:31:04,506] INFO [UnifiedLog partition=__consumer_offsets-21, dir=/tmp/kafka-logs-102] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2024-08-26 15:31:04,506] INFO [ReplicaFetcher replicaId=102, leaderId=101, fetcherId=0] Truncating partition __transaction_state-5 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:31:04,507] INFO [UnifiedLog partition=__transaction_state-5, dir=/tmp/kafka-logs-102] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2024-08-26 15:31:04,507] INFO [ReplicaFetcher replicaId=102, leaderId=101, fetcherId=0] Truncating partition __transaction_state-38 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:31:04,507] INFO [UnifiedLog partition=__transaction_state-38, dir=/tmp/kafka-logs-102] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2024-08-26 15:31:04,508] INFO [ReplicaFetcher replicaId=102, leaderId=101, fetcherId=0] Truncating partition __transaction_state-26 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:31:04,508] INFO [UnifiedLog partition=__transaction_state-26, dir=/tmp/kafka-logs-102] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2024-08-26 15:31:04,508] INFO [ReplicaFetcher replicaId=102, leaderId=101, fetcherId=0] Truncating partition __consumer_offsets-30 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:31:04,508] INFO [UnifiedLog partition=__consumer_offsets-30, dir=/tmp/kafka-logs-102] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2024-08-26 15:31:04,508] INFO [ReplicaFetcherThread-0-103]: Shutting down (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:31:04,508] INFO [ReplicaFetcher replicaId=102, leaderId=101, fetcherId=0] Truncating partition __transaction_state-22 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:31:04,508] INFO [UnifiedLog partition=__transaction_state-22, dir=/tmp/kafka-logs-102] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2024-08-26 15:31:04,509] INFO [ReplicaFetcher replicaId=102, leaderId=101, fetcherId=0] Truncating partition __consumer_offsets-1 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:31:04,509] INFO [UnifiedLog partition=__consumer_offsets-1, dir=/tmp/kafka-logs-102] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2024-08-26 15:31:04,509] INFO [ReplicaFetcher replicaId=102, leaderId=101, fetcherId=0] Truncating partition __consumer_offsets-34 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:31:04,509] INFO [UnifiedLog partition=__consumer_offsets-34, dir=/tmp/kafka-logs-102] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2024-08-26 15:31:04,509] INFO [ReplicaFetcher replicaId=102, leaderId=101, fetcherId=0] Truncating partition __consumer_offsets-16 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:31:04,509] INFO [UnifiedLog partition=__consumer_offsets-16, dir=/tmp/kafka-logs-102] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2024-08-26 15:31:04,509] INFO [ReplicaFetcherThread-0-103]: Shutdown completed (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:31:04,509] INFO [ReplicaFetcher replicaId=102, leaderId=101, fetcherId=0] Truncating partition __consumer_offsets-45 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:31:04,509] INFO [ReplicaFetcherThread-0-103]: Stopped (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:31:04,514] INFO [UnifiedLog partition=__consumer_offsets-45, dir=/tmp/kafka-logs-102] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2024-08-26 15:31:04,514] INFO [ReplicaFetcher replicaId=102, leaderId=101, fetcherId=0] Truncating partition __consumer_offsets-12 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:31:04,514] INFO [UnifiedLog partition=__consumer_offsets-12, dir=/tmp/kafka-logs-102] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2024-08-26 15:31:04,514] INFO [ReplicaFetcher replicaId=102, leaderId=101, fetcherId=0] Truncating partition __transaction_state-16 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:31:04,515] INFO [UnifiedLog partition=__transaction_state-16, dir=/tmp/kafka-logs-102] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2024-08-26 15:31:04,515] INFO [ReplicaFetcher replicaId=102, leaderId=101, fetcherId=0] Truncating partition __transaction_state-49 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:31:04,515] INFO [UnifiedLog partition=__transaction_state-49, dir=/tmp/kafka-logs-102] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2024-08-26 15:31:04,515] INFO [ReplicaFetcher replicaId=102, leaderId=101, fetcherId=0] Truncating partition __consumer_offsets-24 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:31:04,516] INFO [UnifiedLog partition=__consumer_offsets-24, dir=/tmp/kafka-logs-102] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2024-08-26 15:31:04,516] INFO [ReplicaFetcher replicaId=102, leaderId=101, fetcherId=0] Truncating partition __transaction_state-4 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:31:04,516] INFO [UnifiedLog partition=__transaction_state-4, dir=/tmp/kafka-logs-102] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2024-08-26 15:31:04,516] INFO [ReplicaFetcher replicaId=102, leaderId=101, fetcherId=0] Truncating partition __transaction_state-37 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:31:04,516] INFO [UnifiedLog partition=__transaction_state-37, dir=/tmp/kafka-logs-102] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2024-08-26 15:31:04,517] INFO [ReplicaFetcher replicaId=102, leaderId=101, fetcherId=0] Truncating partition __consumer_offsets-49 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:31:04,518] INFO [UnifiedLog partition=__consumer_offsets-49, dir=/tmp/kafka-logs-102] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2024-08-26 15:31:04,518] INFO [ReplicaFetcher replicaId=102, leaderId=101, fetcherId=0] Truncating partition __transaction_state-8 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:31:04,518] INFO [UnifiedLog partition=__transaction_state-8, dir=/tmp/kafka-logs-102] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2024-08-26 15:31:04,518] INFO [ReplicaFetcher replicaId=102, leaderId=101, fetcherId=0] Truncating partition __transaction_state-41 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:31:04,518] INFO [UnifiedLog partition=__transaction_state-41, dir=/tmp/kafka-logs-102] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2024-08-26 15:31:04,518] INFO [ReplicaFetcher replicaId=102, leaderId=101, fetcherId=0] Truncating partition __consumer_offsets-0 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:31:04,518] INFO [UnifiedLog partition=__consumer_offsets-0, dir=/tmp/kafka-logs-102] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2024-08-26 15:31:04,518] INFO [ReplicaFetcher replicaId=102, leaderId=101, fetcherId=0] Truncating partition __transaction_state-29 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:31:04,518] INFO [UnifiedLog partition=__transaction_state-29, dir=/tmp/kafka-logs-102] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2024-08-26 15:31:04,518] INFO [ReplicaFetcher replicaId=102, leaderId=101, fetcherId=0] Truncating partition __consumer_offsets-25 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:31:04,518] INFO [UnifiedLog partition=__consumer_offsets-25, dir=/tmp/kafka-logs-102] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2024-08-26 15:31:04,519] INFO [ReplicaFetcher replicaId=102, leaderId=101, fetcherId=0] Truncating partition __consumer_offsets-37 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:31:04,519] INFO [UnifiedLog partition=__consumer_offsets-37, dir=/tmp/kafka-logs-102] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2024-08-26 15:31:04,519] INFO [ReplicaFetcher replicaId=102, leaderId=101, fetcherId=0] Truncating partition __consumer_offsets-4 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:31:04,519] INFO [UnifiedLog partition=__consumer_offsets-4, dir=/tmp/kafka-logs-102] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2024-08-26 15:31:04,519] INFO [ReplicaFetcher replicaId=102, leaderId=101, fetcherId=0] Truncating partition __consumer_offsets-33 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:31:04,519] INFO [UnifiedLog partition=__consumer_offsets-33, dir=/tmp/kafka-logs-102] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2024-08-26 15:31:04,519] INFO [ReplicaFetcher replicaId=102, leaderId=101, fetcherId=0] Truncating partition __transaction_state-25 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:31:04,519] INFO [UnifiedLog partition=__transaction_state-25, dir=/tmp/kafka-logs-102] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2024-08-26 15:31:04,519] INFO [ReplicaFetcher replicaId=102, leaderId=101, fetcherId=0] Truncating partition __consumer_offsets-15 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:31:04,519] INFO [UnifiedLog partition=__consumer_offsets-15, dir=/tmp/kafka-logs-102] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2024-08-26 15:31:04,519] INFO [ReplicaFetcher replicaId=102, leaderId=101, fetcherId=0] Truncating partition __consumer_offsets-48 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:31:04,519] INFO [UnifiedLog partition=__consumer_offsets-48, dir=/tmp/kafka-logs-102] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2024-08-26 15:31:04,519] INFO [ReplicaFetcher replicaId=102, leaderId=101, fetcherId=0] Truncating partition __transaction_state-11 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:31:04,520] INFO [UnifiedLog partition=__transaction_state-11, dir=/tmp/kafka-logs-102] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2024-08-26 15:31:04,520] INFO [ReplicaFetcher replicaId=102, leaderId=101, fetcherId=0] Truncating partition __transaction_state-44 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:31:04,520] INFO [UnifiedLog partition=__transaction_state-44, dir=/tmp/kafka-logs-102] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2024-08-26 15:31:04,520] INFO [ReplicaFetcher replicaId=102, leaderId=101, fetcherId=0] Truncating partition __consumer_offsets-19 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:31:04,520] INFO [UnifiedLog partition=__consumer_offsets-19, dir=/tmp/kafka-logs-102] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2024-08-26 15:31:04,520] INFO [ReplicaFetcher replicaId=102, leaderId=101, fetcherId=0] Truncating partition __transaction_state-7 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:31:04,520] INFO [UnifiedLog partition=__transaction_state-7, dir=/tmp/kafka-logs-102] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2024-08-26 15:31:04,520] INFO [ReplicaFetcher replicaId=102, leaderId=101, fetcherId=0] Truncating partition __transaction_state-40 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:31:04,520] INFO [UnifiedLog partition=__transaction_state-40, dir=/tmp/kafka-logs-102] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2024-08-26 15:31:04,520] INFO [ReplicaFetcher replicaId=102, leaderId=101, fetcherId=0] Truncating partition __transaction_state-28 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:31:04,520] INFO [UnifiedLog partition=__transaction_state-28, dir=/tmp/kafka-logs-102] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2024-08-26 15:31:04,521] INFO [ReplicaFetcher replicaId=102, leaderId=101, fetcherId=0] Truncating partition __consumer_offsets-28 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:31:04,521] INFO [UnifiedLog partition=__consumer_offsets-28, dir=/tmp/kafka-logs-102] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2024-08-26 15:31:04,521] INFO [ReplicaFetcher replicaId=102, leaderId=101, fetcherId=0] Truncating partition __transaction_state-32 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:31:04,521] INFO [UnifiedLog partition=__transaction_state-32, dir=/tmp/kafka-logs-102] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2024-08-26 15:31:04,521] INFO [ReplicaFetcher replicaId=102, leaderId=101, fetcherId=0] Truncating partition __consumer_offsets-7 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:31:04,521] INFO [UnifiedLog partition=__consumer_offsets-7, dir=/tmp/kafka-logs-102] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2024-08-26 15:31:04,521] INFO [ReplicaFetcher replicaId=102, leaderId=101, fetcherId=0] Truncating partition __consumer_offsets-40 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:31:04,521] INFO [UnifiedLog partition=__consumer_offsets-40, dir=/tmp/kafka-logs-102] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2024-08-26 15:31:04,521] INFO [ReplicaFetcher replicaId=102, leaderId=101, fetcherId=0] Truncating partition __transaction_state-20 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:31:04,521] INFO [UnifiedLog partition=__transaction_state-20, dir=/tmp/kafka-logs-102] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2024-08-26 15:31:04,522] INFO [ReplicaFetcher replicaId=102, leaderId=101, fetcherId=0] Truncating partition __consumer_offsets-3 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:31:04,522] INFO [UnifiedLog partition=__consumer_offsets-3, dir=/tmp/kafka-logs-102] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2024-08-26 15:31:04,522] INFO [ReplicaFetcher replicaId=102, leaderId=101, fetcherId=0] Truncating partition __consumer_offsets-36 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:31:04,522] INFO [UnifiedLog partition=__consumer_offsets-36, dir=/tmp/kafka-logs-102] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2024-08-26 15:31:04,522] INFO [ReplicaFetcher replicaId=102, leaderId=101, fetcherId=0] Truncating partition __transaction_state-10 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:31:04,522] INFO [UnifiedLog partition=__transaction_state-10, dir=/tmp/kafka-logs-102] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2024-08-26 15:31:04,531] INFO [ReplicaFetcher replicaId=102, leaderId=101, fetcherId=0] Truncating partition __transaction_state-43 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:31:04,531] INFO [UnifiedLog partition=__transaction_state-43, dir=/tmp/kafka-logs-102] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2024-08-26 15:31:04,531] INFO [ReplicaFetcher replicaId=102, leaderId=101, fetcherId=0] Truncating partition __consumer_offsets-43 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:31:04,531] INFO [UnifiedLog partition=__consumer_offsets-43, dir=/tmp/kafka-logs-102] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2024-08-26 15:31:04,531] INFO [ReplicaFetcher replicaId=102, leaderId=101, fetcherId=0] Truncating partition __transaction_state-14 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:31:04,546] INFO [UnifiedLog partition=__transaction_state-14, dir=/tmp/kafka-logs-102] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2024-08-26 15:31:04,546] INFO [ReplicaFetcher replicaId=102, leaderId=101, fetcherId=0] Truncating partition __transaction_state-47 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:31:04,547] INFO [UnifiedLog partition=__transaction_state-47, dir=/tmp/kafka-logs-102] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2024-08-26 15:31:04,547] INFO [ReplicaFetcher replicaId=102, leaderId=101, fetcherId=0] Truncating partition __consumer_offsets-10 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:31:04,547] INFO [UnifiedLog partition=__consumer_offsets-10, dir=/tmp/kafka-logs-102] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2024-08-26 15:31:04,547] INFO [ReplicaFetcher replicaId=102, leaderId=101, fetcherId=0] Truncating partition __transaction_state-35 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:31:04,547] INFO [UnifiedLog partition=__transaction_state-35, dir=/tmp/kafka-logs-102] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2024-08-26 15:31:04,547] INFO [ReplicaFetcher replicaId=102, leaderId=101, fetcherId=0] Truncating partition __consumer_offsets-22 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:31:04,547] INFO [UnifiedLog partition=__consumer_offsets-22, dir=/tmp/kafka-logs-102] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2024-08-26 15:31:04,547] INFO [ReplicaFetcher replicaId=102, leaderId=101, fetcherId=0] Truncating partition __consumer_offsets-18 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:31:04,547] INFO [UnifiedLog partition=__consumer_offsets-18, dir=/tmp/kafka-logs-102] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2024-08-26 15:31:04,547] INFO [ReplicaFetcher replicaId=102, leaderId=101, fetcherId=0] Truncating partition __consumer_offsets-27 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:31:04,547] INFO [UnifiedLog partition=__consumer_offsets-27, dir=/tmp/kafka-logs-102] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2024-08-26 15:31:04,547] INFO [ReplicaFetcher replicaId=102, leaderId=101, fetcherId=0] Truncating partition __transaction_state-31 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:31:04,548] INFO [UnifiedLog partition=__transaction_state-31, dir=/tmp/kafka-logs-102] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2024-08-26 15:31:04,548] INFO [ReplicaFetcher replicaId=102, leaderId=101, fetcherId=0] Truncating partition __consumer_offsets-39 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:31:04,548] INFO [UnifiedLog partition=__consumer_offsets-39, dir=/tmp/kafka-logs-102] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2024-08-26 15:31:04,548] INFO [ReplicaFetcher replicaId=102, leaderId=101, fetcherId=0] Truncating partition __transaction_state-19 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:31:06,852] INFO [UnifiedLog partition=__transaction_state-19, dir=/tmp/kafka-logs-102] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2024-08-26 15:31:06,852] INFO [ReplicaFetcher replicaId=102, leaderId=101, fetcherId=0] Truncating partition __consumer_offsets-6 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:31:06,852] INFO [UnifiedLog partition=__consumer_offsets-6, dir=/tmp/kafka-logs-102] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2024-08-26 15:31:06,852] INFO [ReplicaFetcher replicaId=102, leaderId=101, fetcherId=0] Truncating partition __transaction_state-23 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:31:06,852] INFO [UnifiedLog partition=__transaction_state-23, dir=/tmp/kafka-logs-102] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2024-08-26 15:31:06,854] INFO [GroupCoordinator 102]: Resigned as the group coordinator for partition 3 in epoch OptionalInt[2] (kafka.coordinator.group.GroupCoordinator)
[2024-08-26 15:31:06,854] INFO [GroupMetadataManager brokerId=102] Scheduling unloading of offsets and group metadata from __consumer_offsets-3 (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 15:31:06,854] INFO [GroupCoordinator 102]: Resigned as the group coordinator for partition 18 in epoch OptionalInt[2] (kafka.coordinator.group.GroupCoordinator)
[2024-08-26 15:31:06,854] INFO [GroupMetadataManager brokerId=102] Scheduling unloading of offsets and group metadata from __consumer_offsets-18 (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 15:31:06,855] INFO [TransactionCoordinator id=102] Resigned as the txn coordinator for partition 11 at epoch Some(3) (kafka.coordinator.transaction.TransactionCoordinator)
[2024-08-26 15:31:06,855] INFO [GroupMetadataManager brokerId=102] Finished unloading __consumer_offsets-3 for coordinator epoch OptionalInt[2]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 15:31:06,856] INFO [Transaction State Manager 102]: No cached transaction metadata found for __transaction_state-11 during become-follower transition (kafka.coordinator.transaction.TransactionStateManager)
[2024-08-26 15:31:06,903] INFO [GroupMetadataManager brokerId=102] Finished unloading __consumer_offsets-18 for coordinator epoch OptionalInt[2]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 15:31:06,905] INFO [GroupCoordinator 102]: Resigned as the group coordinator for partition 33 in epoch OptionalInt[2] (kafka.coordinator.group.GroupCoordinator)
[2024-08-26 15:31:06,905] INFO [GroupMetadataManager brokerId=102] Scheduling unloading of offsets and group metadata from __consumer_offsets-33 (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 15:31:06,906] INFO [TransactionCoordinator id=102] Resigned as the txn coordinator for partition 26 at epoch Some(3) (kafka.coordinator.transaction.TransactionCoordinator)
[2024-08-26 15:31:06,906] INFO [GroupMetadataManager brokerId=102] Finished unloading __consumer_offsets-33 for coordinator epoch OptionalInt[2]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 15:31:06,907] INFO [Transaction State Manager 102]: No cached transaction metadata found for __transaction_state-26 during become-follower transition (kafka.coordinator.transaction.TransactionStateManager)
[2024-08-26 15:31:06,907] INFO [GroupCoordinator 102]: Resigned as the group coordinator for partition 48 in epoch OptionalInt[2] (kafka.coordinator.group.GroupCoordinator)
[2024-08-26 15:31:06,907] INFO [GroupMetadataManager brokerId=102] Scheduling unloading of offsets and group metadata from __consumer_offsets-48 (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 15:31:06,907] INFO [TransactionCoordinator id=102] Resigned as the txn coordinator for partition 41 at epoch Some(3) (kafka.coordinator.transaction.TransactionCoordinator)
[2024-08-26 15:31:06,908] INFO [GroupMetadataManager brokerId=102] Finished unloading __consumer_offsets-48 for coordinator epoch OptionalInt[2]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 15:31:06,908] INFO [Transaction State Manager 102]: No cached transaction metadata found for __transaction_state-41 during become-follower transition (kafka.coordinator.transaction.TransactionStateManager)
[2024-08-26 15:31:06,909] INFO [GroupCoordinator 102]: Resigned as the group coordinator for partition 19 in epoch OptionalInt[3] (kafka.coordinator.group.GroupCoordinator)
[2024-08-26 15:31:06,909] INFO [GroupMetadataManager brokerId=102] Scheduling unloading of offsets and group metadata from __consumer_offsets-19 (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 15:31:06,909] INFO [GroupCoordinator 102]: Resigned as the group coordinator for partition 34 in epoch OptionalInt[3] (kafka.coordinator.group.GroupCoordinator)
[2024-08-26 15:31:06,915] INFO [GroupMetadataManager brokerId=102] Scheduling unloading of offsets and group metadata from __consumer_offsets-34 (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 15:31:06,909] INFO [GroupMetadataManager brokerId=102] Finished unloading __consumer_offsets-19 for coordinator epoch OptionalInt[3]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 15:31:06,918] INFO [GroupCoordinator 102]: Resigned as the group coordinator for partition 4 in epoch OptionalInt[3] (kafka.coordinator.group.GroupCoordinator)
[2024-08-26 15:31:06,919] INFO [GroupMetadataManager brokerId=102] Scheduling unloading of offsets and group metadata from __consumer_offsets-4 (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 15:31:06,919] INFO [TransactionCoordinator id=102] Resigned as the txn coordinator for partition 12 at epoch Some(3) (kafka.coordinator.transaction.TransactionCoordinator)
[2024-08-26 15:31:06,918] INFO [GroupMetadataManager brokerId=102] Finished unloading __consumer_offsets-34 for coordinator epoch OptionalInt[3]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 15:31:06,920] INFO [GroupMetadataManager brokerId=102] Finished unloading __consumer_offsets-4 for coordinator epoch OptionalInt[3]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 15:31:06,920] INFO [Transaction State Manager 102]: Unloaded transaction metadata TxnMetadataCacheEntry(coordinatorEpoch=0, numTransactionalEntries=0) for __transaction_state-12 on become-follower transition (kafka.coordinator.transaction.TransactionStateManager)
[2024-08-26 15:31:06,921] INFO [TransactionCoordinator id=102] Resigned as the txn coordinator for partition 27 at epoch Some(3) (kafka.coordinator.transaction.TransactionCoordinator)
[2024-08-26 15:31:06,921] INFO [Transaction State Manager 102]: Unloaded transaction metadata TxnMetadataCacheEntry(coordinatorEpoch=0, numTransactionalEntries=0) for __transaction_state-27 on become-follower transition (kafka.coordinator.transaction.TransactionStateManager)
[2024-08-26 15:31:06,921] INFO [GroupCoordinator 102]: Resigned as the group coordinator for partition 49 in epoch OptionalInt[3] (kafka.coordinator.group.GroupCoordinator)
[2024-08-26 15:31:06,953] INFO [GroupMetadataManager brokerId=102] Scheduling unloading of offsets and group metadata from __consumer_offsets-49 (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 15:31:06,954] INFO [TransactionCoordinator id=102] Resigned as the txn coordinator for partition 42 at epoch Some(3) (kafka.coordinator.transaction.TransactionCoordinator)
[2024-08-26 15:31:06,954] INFO [Transaction State Manager 102]: Unloaded transaction metadata TxnMetadataCacheEntry(coordinatorEpoch=0, numTransactionalEntries=0) for __transaction_state-42 on become-follower transition (kafka.coordinator.transaction.TransactionStateManager)
[2024-08-26 15:31:06,954] INFO [GroupMetadataManager brokerId=102] Finished unloading __consumer_offsets-49 for coordinator epoch OptionalInt[3]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 15:31:06,954] INFO [TransactionCoordinator id=102] Resigned as the txn coordinator for partition 24 at epoch Some(3) (kafka.coordinator.transaction.TransactionCoordinator)
[2024-08-26 15:31:06,954] INFO [Transaction State Manager 102]: Unloaded transaction metadata TxnMetadataCacheEntry(coordinatorEpoch=0, numTransactionalEntries=0) for __transaction_state-24 on become-follower transition (kafka.coordinator.transaction.TransactionStateManager)
[2024-08-26 15:31:06,954] INFO [TransactionCoordinator id=102] Resigned as the txn coordinator for partition 39 at epoch Some(3) (kafka.coordinator.transaction.TransactionCoordinator)
[2024-08-26 15:31:06,954] INFO [Transaction State Manager 102]: Unloaded transaction metadata TxnMetadataCacheEntry(coordinatorEpoch=0, numTransactionalEntries=0) for __transaction_state-39 on become-follower transition (kafka.coordinator.transaction.TransactionStateManager)
[2024-08-26 15:31:06,955] INFO [GroupCoordinator 102]: Resigned as the group coordinator for partition 31 in epoch OptionalInt[3] (kafka.coordinator.group.GroupCoordinator)
[2024-08-26 15:31:06,955] INFO [GroupMetadataManager brokerId=102] Scheduling unloading of offsets and group metadata from __consumer_offsets-31 (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 15:31:06,955] INFO [GroupCoordinator 102]: Resigned as the group coordinator for partition 46 in epoch OptionalInt[3] (kafka.coordinator.group.GroupCoordinator)
[2024-08-26 15:31:06,955] INFO [GroupMetadataManager brokerId=102] Finished unloading __consumer_offsets-31 for coordinator epoch OptionalInt[3]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 15:31:06,955] INFO [GroupMetadataManager brokerId=102] Scheduling unloading of offsets and group metadata from __consumer_offsets-46 (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 15:31:06,964] INFO [GroupCoordinator 102]: Resigned as the group coordinator for partition 1 in epoch OptionalInt[3] (kafka.coordinator.group.GroupCoordinator)
[2024-08-26 15:31:06,964] INFO [GroupMetadataManager brokerId=102] Scheduling unloading of offsets and group metadata from __consumer_offsets-1 (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 15:31:06,964] INFO [GroupMetadataManager brokerId=102] Finished unloading __consumer_offsets-46 for coordinator epoch OptionalInt[3]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 15:31:06,964] INFO [GroupCoordinator 102]: Resigned as the group coordinator for partition 16 in epoch OptionalInt[3] (kafka.coordinator.group.GroupCoordinator)
[2024-08-26 15:31:06,964] INFO [GroupMetadataManager brokerId=102] Finished unloading __consumer_offsets-1 for coordinator epoch OptionalInt[3]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 15:31:06,964] INFO [GroupMetadataManager brokerId=102] Scheduling unloading of offsets and group metadata from __consumer_offsets-16 (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 15:31:06,965] INFO [TransactionCoordinator id=102] Resigned as the txn coordinator for partition 9 at epoch Some(3) (kafka.coordinator.transaction.TransactionCoordinator)
[2024-08-26 15:31:06,965] INFO [GroupMetadataManager brokerId=102] Finished unloading __consumer_offsets-16 for coordinator epoch OptionalInt[3]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 15:31:06,965] INFO [Transaction State Manager 102]: Unloaded transaction metadata TxnMetadataCacheEntry(coordinatorEpoch=0, numTransactionalEntries=0) for __transaction_state-9 on become-follower transition (kafka.coordinator.transaction.TransactionStateManager)
[2024-08-26 15:31:06,965] INFO [TransactionCoordinator id=102] Resigned as the txn coordinator for partition 40 at epoch Some(2) (kafka.coordinator.transaction.TransactionCoordinator)
[2024-08-26 15:31:07,002] INFO [Transaction State Manager 102]: No cached transaction metadata found for __transaction_state-40 during become-follower transition (kafka.coordinator.transaction.TransactionStateManager)
[2024-08-26 15:31:07,003] INFO [GroupCoordinator 102]: Resigned as the group coordinator for partition 2 in epoch OptionalInt[3] (kafka.coordinator.group.GroupCoordinator)
[2024-08-26 15:31:07,004] INFO [GroupMetadataManager brokerId=102] Scheduling unloading of offsets and group metadata from __consumer_offsets-2 (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 15:31:07,004] INFO [GroupCoordinator 102]: Resigned as the group coordinator for partition 47 in epoch OptionalInt[3] (kafka.coordinator.group.GroupCoordinator)
[2024-08-26 15:31:07,004] INFO [GroupMetadataManager brokerId=102] Scheduling unloading of offsets and group metadata from __consumer_offsets-47 (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 15:31:07,004] INFO [GroupMetadataManager brokerId=102] Finished unloading __consumer_offsets-2 for coordinator epoch OptionalInt[3]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 15:31:07,004] INFO [GroupCoordinator 102]: Resigned as the group coordinator for partition 17 in epoch OptionalInt[3] (kafka.coordinator.group.GroupCoordinator)
[2024-08-26 15:31:07,005] INFO [GroupMetadataManager brokerId=102] Scheduling unloading of offsets and group metadata from __consumer_offsets-17 (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 15:31:07,005] INFO [TransactionCoordinator id=102] Resigned as the txn coordinator for partition 10 at epoch Some(2) (kafka.coordinator.transaction.TransactionCoordinator)
[2024-08-26 15:31:07,005] INFO [GroupMetadataManager brokerId=102] Finished unloading __consumer_offsets-47 for coordinator epoch OptionalInt[3]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 15:31:07,005] INFO [Transaction State Manager 102]: No cached transaction metadata found for __transaction_state-10 during become-follower transition (kafka.coordinator.transaction.TransactionStateManager)
[2024-08-26 15:31:07,006] INFO [GroupMetadataManager brokerId=102] Finished unloading __consumer_offsets-17 for coordinator epoch OptionalInt[3]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 15:31:07,006] INFO [GroupCoordinator 102]: Resigned as the group coordinator for partition 32 in epoch OptionalInt[3] (kafka.coordinator.group.GroupCoordinator)
[2024-08-26 15:31:07,012] INFO [GroupMetadataManager brokerId=102] Scheduling unloading of offsets and group metadata from __consumer_offsets-32 (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 15:31:07,012] INFO [TransactionCoordinator id=102] Resigned as the txn coordinator for partition 25 at epoch Some(2) (kafka.coordinator.transaction.TransactionCoordinator)
[2024-08-26 15:31:07,012] INFO [GroupMetadataManager brokerId=102] Finished unloading __consumer_offsets-32 for coordinator epoch OptionalInt[3]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 15:31:07,012] INFO [Transaction State Manager 102]: No cached transaction metadata found for __transaction_state-25 during become-follower transition (kafka.coordinator.transaction.TransactionStateManager)
[2024-08-26 15:31:07,013] INFO [TransactionCoordinator id=102] Resigned as the txn coordinator for partition 7 at epoch Some(2) (kafka.coordinator.transaction.TransactionCoordinator)
[2024-08-26 15:31:07,015] INFO [Transaction State Manager 102]: No cached transaction metadata found for __transaction_state-7 during become-follower transition (kafka.coordinator.transaction.TransactionStateManager)
[2024-08-26 15:31:07,015] INFO [GroupCoordinator 102]: Resigned as the group coordinator for partition 37 in epoch OptionalInt[3] (kafka.coordinator.group.GroupCoordinator)
[2024-08-26 15:31:07,015] INFO [GroupMetadataManager brokerId=102] Scheduling unloading of offsets and group metadata from __consumer_offsets-37 (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 15:31:07,015] INFO [TransactionCoordinator id=102] Resigned as the txn coordinator for partition 22 at epoch Some(2) (kafka.coordinator.transaction.TransactionCoordinator)
[2024-08-26 15:31:07,016] INFO [Transaction State Manager 102]: No cached transaction metadata found for __transaction_state-22 during become-follower transition (kafka.coordinator.transaction.TransactionStateManager)
[2024-08-26 15:31:07,016] INFO [GroupMetadataManager brokerId=102] Finished unloading __consumer_offsets-37 for coordinator epoch OptionalInt[3]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 15:31:07,017] INFO [TransactionCoordinator id=102] Resigned as the txn coordinator for partition 37 at epoch Some(2) (kafka.coordinator.transaction.TransactionCoordinator)
[2024-08-26 15:31:07,017] INFO [Transaction State Manager 102]: No cached transaction metadata found for __transaction_state-37 during become-follower transition (kafka.coordinator.transaction.TransactionStateManager)
[2024-08-26 15:31:07,017] INFO [GroupCoordinator 102]: Resigned as the group coordinator for partition 7 in epoch OptionalInt[3] (kafka.coordinator.group.GroupCoordinator)
[2024-08-26 15:31:07,017] INFO [GroupMetadataManager brokerId=102] Scheduling unloading of offsets and group metadata from __consumer_offsets-7 (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 15:31:07,018] INFO [GroupCoordinator 102]: Resigned as the group coordinator for partition 22 in epoch OptionalInt[3] (kafka.coordinator.group.GroupCoordinator)
[2024-08-26 15:31:07,019] INFO [GroupMetadataManager brokerId=102] Scheduling unloading of offsets and group metadata from __consumer_offsets-22 (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 15:31:07,019] INFO [TransactionCoordinator id=102] Resigned as the txn coordinator for partition 8 at epoch Some(3) (kafka.coordinator.transaction.TransactionCoordinator)
[2024-08-26 15:31:07,019] INFO [GroupMetadataManager brokerId=102] Finished unloading __consumer_offsets-7 for coordinator epoch OptionalInt[3]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 15:31:07,019] INFO [Transaction State Manager 102]: No cached transaction metadata found for __transaction_state-8 during become-follower transition (kafka.coordinator.transaction.TransactionStateManager)
[2024-08-26 15:31:07,019] INFO [GroupMetadataManager brokerId=102] Finished unloading __consumer_offsets-22 for coordinator epoch OptionalInt[3]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 15:31:07,022] INFO [TransactionCoordinator id=102] Resigned as the txn coordinator for partition 23 at epoch Some(3) (kafka.coordinator.transaction.TransactionCoordinator)
[2024-08-26 15:31:07,022] INFO [Transaction State Manager 102]: No cached transaction metadata found for __transaction_state-23 during become-follower transition (kafka.coordinator.transaction.TransactionStateManager)
[2024-08-26 15:31:07,022] INFO [TransactionCoordinator id=102] Resigned as the txn coordinator for partition 38 at epoch Some(3) (kafka.coordinator.transaction.TransactionCoordinator)
[2024-08-26 15:31:07,022] INFO [Transaction State Manager 102]: No cached transaction metadata found for __transaction_state-38 during become-follower transition (kafka.coordinator.transaction.TransactionStateManager)
[2024-08-26 15:31:07,022] INFO [GroupCoordinator 102]: Resigned as the group coordinator for partition 23 in epoch OptionalInt[3] (kafka.coordinator.group.GroupCoordinator)
[2024-08-26 15:31:07,022] INFO [GroupMetadataManager brokerId=102] Scheduling unloading of offsets and group metadata from __consumer_offsets-23 (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 15:31:07,022] INFO [GroupCoordinator 102]: Resigned as the group coordinator for partition 38 in epoch OptionalInt[3] (kafka.coordinator.group.GroupCoordinator)
[2024-08-26 15:31:07,022] INFO [GroupMetadataManager brokerId=102] Finished unloading __consumer_offsets-23 for coordinator epoch OptionalInt[3]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 15:31:07,022] INFO [GroupMetadataManager brokerId=102] Scheduling unloading of offsets and group metadata from __consumer_offsets-38 (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 15:31:07,023] INFO [GroupCoordinator 102]: Resigned as the group coordinator for partition 8 in epoch OptionalInt[3] (kafka.coordinator.group.GroupCoordinator)
[2024-08-26 15:31:07,023] INFO [GroupMetadataManager brokerId=102] Scheduling unloading of offsets and group metadata from __consumer_offsets-8 (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 15:31:07,023] INFO [GroupMetadataManager brokerId=102] Finished unloading __consumer_offsets-38 for coordinator epoch OptionalInt[3]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 15:31:07,023] INFO [GroupCoordinator 102]: Resigned as the group coordinator for partition 35 in epoch OptionalInt[3] (kafka.coordinator.group.GroupCoordinator)
[2024-08-26 15:31:07,023] INFO [GroupMetadataManager brokerId=102] Finished unloading __consumer_offsets-8 for coordinator epoch OptionalInt[3]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 15:31:07,023] INFO [GroupMetadataManager brokerId=102] Scheduling unloading of offsets and group metadata from __consumer_offsets-35 (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 15:31:07,053] INFO [GroupCoordinator 102]: Resigned as the group coordinator for partition 5 in epoch OptionalInt[3] (kafka.coordinator.group.GroupCoordinator)
[2024-08-26 15:31:07,053] INFO [GroupMetadataManager brokerId=102] Scheduling unloading of offsets and group metadata from __consumer_offsets-5 (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 15:31:07,053] INFO [GroupMetadataManager brokerId=102] Finished unloading __consumer_offsets-35 for coordinator epoch OptionalInt[3]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 15:31:07,054] INFO [GroupCoordinator 102]: Resigned as the group coordinator for partition 20 in epoch OptionalInt[3] (kafka.coordinator.group.GroupCoordinator)
[2024-08-26 15:31:07,054] INFO [GroupMetadataManager brokerId=102] Finished unloading __consumer_offsets-5 for coordinator epoch OptionalInt[3]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 15:31:07,054] INFO [GroupMetadataManager brokerId=102] Scheduling unloading of offsets and group metadata from __consumer_offsets-20 (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 15:31:07,054] INFO [TransactionCoordinator id=102] Resigned as the txn coordinator for partition 5 at epoch Some(3) (kafka.coordinator.transaction.TransactionCoordinator)
[2024-08-26 15:31:07,054] INFO [GroupMetadataManager brokerId=102] Finished unloading __consumer_offsets-20 for coordinator epoch OptionalInt[3]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 15:31:07,054] INFO [Transaction State Manager 102]: No cached transaction metadata found for __transaction_state-5 during become-follower transition (kafka.coordinator.transaction.TransactionStateManager)
[2024-08-26 15:31:07,054] INFO [TransactionCoordinator id=102] Resigned as the txn coordinator for partition 20 at epoch Some(3) (kafka.coordinator.transaction.TransactionCoordinator)
[2024-08-26 15:31:07,054] INFO [Transaction State Manager 102]: No cached transaction metadata found for __transaction_state-20 during become-follower transition (kafka.coordinator.transaction.TransactionStateManager)
[2024-08-26 15:31:07,054] INFO [TransactionCoordinator id=102] Resigned as the txn coordinator for partition 35 at epoch Some(3) (kafka.coordinator.transaction.TransactionCoordinator)
[2024-08-26 15:31:07,054] INFO [Transaction State Manager 102]: No cached transaction metadata found for __transaction_state-35 during become-follower transition (kafka.coordinator.transaction.TransactionStateManager)
[2024-08-26 15:31:07,054] INFO [GroupCoordinator 102]: Resigned as the group coordinator for partition 21 in epoch OptionalInt[2] (kafka.coordinator.group.GroupCoordinator)
[2024-08-26 15:31:07,055] INFO [GroupMetadataManager brokerId=102] Scheduling unloading of offsets and group metadata from __consumer_offsets-21 (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 15:31:07,055] INFO [TransactionCoordinator id=102] Resigned as the txn coordinator for partition 6 at epoch Some(3) (kafka.coordinator.transaction.TransactionCoordinator)
[2024-08-26 15:31:07,055] INFO [GroupMetadataManager brokerId=102] Finished unloading __consumer_offsets-21 for coordinator epoch OptionalInt[2]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 15:31:07,055] INFO [Transaction State Manager 102]: Unloaded transaction metadata TxnMetadataCacheEntry(coordinatorEpoch=0, numTransactionalEntries=0) for __transaction_state-6 on become-follower transition (kafka.coordinator.transaction.TransactionStateManager)
[2024-08-26 15:31:07,055] INFO [GroupCoordinator 102]: Resigned as the group coordinator for partition 36 in epoch OptionalInt[2] (kafka.coordinator.group.GroupCoordinator)
[2024-08-26 15:31:07,055] INFO [GroupMetadataManager brokerId=102] Scheduling unloading of offsets and group metadata from __consumer_offsets-36 (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 15:31:07,056] INFO [TransactionCoordinator id=102] Resigned as the txn coordinator for partition 21 at epoch Some(3) (kafka.coordinator.transaction.TransactionCoordinator)
[2024-08-26 15:31:07,056] INFO [Transaction State Manager 102]: Unloaded transaction metadata TxnMetadataCacheEntry(coordinatorEpoch=0, numTransactionalEntries=0) for __transaction_state-21 on become-follower transition (kafka.coordinator.transaction.TransactionStateManager)
[2024-08-26 15:31:07,056] INFO [GroupMetadataManager brokerId=102] Finished unloading __consumer_offsets-36 for coordinator epoch OptionalInt[2]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 15:31:07,056] INFO [TransactionCoordinator id=102] Resigned as the txn coordinator for partition 36 at epoch Some(3) (kafka.coordinator.transaction.TransactionCoordinator)
[2024-08-26 15:31:07,056] INFO [Transaction State Manager 102]: Unloaded transaction metadata TxnMetadataCacheEntry(coordinatorEpoch=0, numTransactionalEntries=0) for __transaction_state-36 on become-follower transition (kafka.coordinator.transaction.TransactionStateManager)
[2024-08-26 15:31:07,056] INFO [GroupCoordinator 102]: Resigned as the group coordinator for partition 6 in epoch OptionalInt[2] (kafka.coordinator.group.GroupCoordinator)
[2024-08-26 15:31:07,057] INFO [GroupMetadataManager brokerId=102] Scheduling unloading of offsets and group metadata from __consumer_offsets-6 (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 15:31:07,057] INFO [TransactionCoordinator id=102] Resigned as the txn coordinator for partition 3 at epoch Some(3) (kafka.coordinator.transaction.TransactionCoordinator)
[2024-08-26 15:31:07,057] INFO [GroupMetadataManager brokerId=102] Finished unloading __consumer_offsets-6 for coordinator epoch OptionalInt[2]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 15:31:07,057] INFO [Transaction State Manager 102]: Unloaded transaction metadata TxnMetadataCacheEntry(coordinatorEpoch=0, numTransactionalEntries=1) for __transaction_state-3 on become-follower transition (kafka.coordinator.transaction.TransactionStateManager)
[2024-08-26 15:31:07,067] INFO [GroupCoordinator 102]: Resigned as the group coordinator for partition 41 in epoch OptionalInt[3] (kafka.coordinator.group.GroupCoordinator)
[2024-08-26 15:31:07,067] INFO [GroupMetadataManager brokerId=102] Scheduling unloading of offsets and group metadata from __consumer_offsets-41 (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 15:31:07,067] INFO [TransactionCoordinator id=102] Resigned as the txn coordinator for partition 18 at epoch Some(3) (kafka.coordinator.transaction.TransactionCoordinator)
[2024-08-26 15:31:07,067] INFO [GroupMetadataManager brokerId=102] Finished unloading __consumer_offsets-41 for coordinator epoch OptionalInt[3]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 15:31:07,067] INFO [Transaction State Manager 102]: Unloaded transaction metadata TxnMetadataCacheEntry(coordinatorEpoch=0, numTransactionalEntries=0) for __transaction_state-18 on become-follower transition (kafka.coordinator.transaction.TransactionStateManager)
[2024-08-26 15:31:07,067] INFO [TransactionCoordinator id=102] Resigned as the txn coordinator for partition 33 at epoch Some(3) (kafka.coordinator.transaction.TransactionCoordinator)
[2024-08-26 15:31:07,067] INFO [Transaction State Manager 102]: Unloaded transaction metadata TxnMetadataCacheEntry(coordinatorEpoch=0, numTransactionalEntries=0) for __transaction_state-33 on become-follower transition (kafka.coordinator.transaction.TransactionStateManager)
[2024-08-26 15:31:07,070] INFO [GroupCoordinator 102]: Resigned as the group coordinator for partition 10 in epoch OptionalInt[3] (kafka.coordinator.group.GroupCoordinator)
[2024-08-26 15:31:07,070] INFO [GroupMetadataManager brokerId=102] Scheduling unloading of offsets and group metadata from __consumer_offsets-10 (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 15:31:07,070] INFO [TransactionCoordinator id=102] Resigned as the txn coordinator for partition 4 at epoch Some(2) (kafka.coordinator.transaction.TransactionCoordinator)
[2024-08-26 15:31:07,070] INFO [GroupMetadataManager brokerId=102] Finished unloading __consumer_offsets-10 for coordinator epoch OptionalInt[3]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 15:31:07,070] INFO [Transaction State Manager 102]: No cached transaction metadata found for __transaction_state-4 during become-follower transition (kafka.coordinator.transaction.TransactionStateManager)
[2024-08-26 15:31:07,070] INFO [TransactionCoordinator id=102] Resigned as the txn coordinator for partition 19 at epoch Some(2) (kafka.coordinator.transaction.TransactionCoordinator)
[2024-08-26 15:31:07,070] INFO [Transaction State Manager 102]: No cached transaction metadata found for __transaction_state-19 during become-follower transition (kafka.coordinator.transaction.TransactionStateManager)
[2024-08-26 15:31:07,070] INFO [TransactionCoordinator id=102] Resigned as the txn coordinator for partition 34 at epoch Some(2) (kafka.coordinator.transaction.TransactionCoordinator)
[2024-08-26 15:31:07,070] INFO [Transaction State Manager 102]: No cached transaction metadata found for __transaction_state-34 during become-follower transition (kafka.coordinator.transaction.TransactionStateManager)
[2024-08-26 15:31:07,112] INFO [TransactionCoordinator id=102] Resigned as the txn coordinator for partition 49 at epoch Some(2) (kafka.coordinator.transaction.TransactionCoordinator)
[2024-08-26 15:31:07,112] INFO [Transaction State Manager 102]: No cached transaction metadata found for __transaction_state-49 during become-follower transition (kafka.coordinator.transaction.TransactionStateManager)
[2024-08-26 15:31:07,112] INFO [GroupCoordinator 102]: Resigned as the group coordinator for partition 11 in epoch OptionalInt[3] (kafka.coordinator.group.GroupCoordinator)
[2024-08-26 15:31:07,112] INFO [GroupMetadataManager brokerId=102] Scheduling unloading of offsets and group metadata from __consumer_offsets-11 (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 15:31:07,112] INFO [GroupCoordinator 102]: Resigned as the group coordinator for partition 26 in epoch OptionalInt[3] (kafka.coordinator.group.GroupCoordinator)
[2024-08-26 15:31:07,112] INFO [GroupMetadataManager brokerId=102] Scheduling unloading of offsets and group metadata from __consumer_offsets-26 (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 15:31:07,112] INFO [GroupMetadataManager brokerId=102] Finished unloading __consumer_offsets-11 for coordinator epoch OptionalInt[3]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 15:31:07,121] INFO [GroupCoordinator 102]: Resigned as the group coordinator for partition 39 in epoch OptionalInt[2] (kafka.coordinator.group.GroupCoordinator)
[2024-08-26 15:31:07,121] INFO [GroupMetadataManager brokerId=102] Scheduling unloading of offsets and group metadata from __consumer_offsets-39 (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 15:31:07,121] INFO [GroupMetadataManager brokerId=102] Finished unloading __consumer_offsets-26 for coordinator epoch OptionalInt[3]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 15:31:07,121] INFO [GroupCoordinator 102]: Resigned as the group coordinator for partition 9 in epoch OptionalInt[2] (kafka.coordinator.group.GroupCoordinator)
[2024-08-26 15:31:07,121] INFO [GroupMetadataManager brokerId=102] Finished unloading __consumer_offsets-39 for coordinator epoch OptionalInt[2]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 15:31:07,122] INFO [GroupMetadataManager brokerId=102] Scheduling unloading of offsets and group metadata from __consumer_offsets-9 (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 15:31:07,122] INFO [GroupCoordinator 102]: Resigned as the group coordinator for partition 24 in epoch OptionalInt[2] (kafka.coordinator.group.GroupCoordinator)
[2024-08-26 15:31:07,122] INFO [GroupMetadataManager brokerId=102] Finished unloading __consumer_offsets-9 for coordinator epoch OptionalInt[2]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 15:31:07,122] INFO [GroupMetadataManager brokerId=102] Scheduling unloading of offsets and group metadata from __consumer_offsets-24 (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 15:31:07,151] INFO [TransactionCoordinator id=102] Resigned as the txn coordinator for partition 1 at epoch Some(2) (kafka.coordinator.transaction.TransactionCoordinator)
[2024-08-26 15:31:07,151] INFO [GroupMetadataManager brokerId=102] Finished unloading __consumer_offsets-24 for coordinator epoch OptionalInt[2]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 15:31:07,151] INFO [Transaction State Manager 102]: No cached transaction metadata found for __transaction_state-1 during become-follower transition (kafka.coordinator.transaction.TransactionStateManager)
[2024-08-26 15:31:07,152] INFO [TransactionCoordinator id=102] Resigned as the txn coordinator for partition 32 at epoch Some(3) (kafka.coordinator.transaction.TransactionCoordinator)
[2024-08-26 15:31:07,152] INFO [Transaction State Manager 102]: No cached transaction metadata found for __transaction_state-32 during become-follower transition (kafka.coordinator.transaction.TransactionStateManager)
[2024-08-26 15:31:07,152] INFO [TransactionCoordinator id=102] Resigned as the txn coordinator for partition 47 at epoch Some(3) (kafka.coordinator.transaction.TransactionCoordinator)
[2024-08-26 15:31:07,154] INFO [Transaction State Manager 102]: No cached transaction metadata found for __transaction_state-47 during become-follower transition (kafka.coordinator.transaction.TransactionStateManager)
[2024-08-26 15:31:07,154] INFO [GroupCoordinator 102]: Resigned as the group coordinator for partition 25 in epoch OptionalInt[3] (kafka.coordinator.group.GroupCoordinator)
[2024-08-26 15:31:07,154] INFO [GroupMetadataManager brokerId=102] Scheduling unloading of offsets and group metadata from __consumer_offsets-25 (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 15:31:07,154] INFO [TransactionCoordinator id=102] Resigned as the txn coordinator for partition 2 at epoch Some(3) (kafka.coordinator.transaction.TransactionCoordinator)
[2024-08-26 15:31:07,154] INFO [Transaction State Manager 102]: No cached transaction metadata found for __transaction_state-2 during become-follower transition (kafka.coordinator.transaction.TransactionStateManager)
[2024-08-26 15:31:07,154] INFO [GroupMetadataManager brokerId=102] Finished unloading __consumer_offsets-25 for coordinator epoch OptionalInt[3]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 15:31:07,154] INFO [GroupCoordinator 102]: Resigned as the group coordinator for partition 40 in epoch OptionalInt[3] (kafka.coordinator.group.GroupCoordinator)
[2024-08-26 15:31:07,154] INFO [GroupMetadataManager brokerId=102] Scheduling unloading of offsets and group metadata from __consumer_offsets-40 (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 15:31:07,154] INFO [TransactionCoordinator id=102] Resigned as the txn coordinator for partition 17 at epoch Some(3) (kafka.coordinator.transaction.TransactionCoordinator)
[2024-08-26 15:31:07,154] INFO [GroupMetadataManager brokerId=102] Finished unloading __consumer_offsets-40 for coordinator epoch OptionalInt[3]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 15:31:07,154] INFO [Transaction State Manager 102]: No cached transaction metadata found for __transaction_state-17 during become-follower transition (kafka.coordinator.transaction.TransactionStateManager)
[2024-08-26 15:31:07,155] INFO [TransactionCoordinator id=102] Resigned as the txn coordinator for partition 48 at epoch Some(3) (kafka.coordinator.transaction.TransactionCoordinator)
[2024-08-26 15:31:09,352] INFO [Transaction State Manager 102]: Unloaded transaction metadata TxnMetadataCacheEntry(coordinatorEpoch=0, numTransactionalEntries=0) for __transaction_state-48 on become-follower transition (kafka.coordinator.transaction.TransactionStateManager)
[2024-08-26 15:31:09,352] INFO [TransactionCoordinator id=102] Resigned as the txn coordinator for partition 0 at epoch Some(3) (kafka.coordinator.transaction.TransactionCoordinator)
[2024-08-26 15:31:09,352] INFO [Transaction State Manager 102]: Unloaded transaction metadata TxnMetadataCacheEntry(coordinatorEpoch=0, numTransactionalEntries=0) for __transaction_state-0 on become-follower transition (kafka.coordinator.transaction.TransactionStateManager)
[2024-08-26 15:31:09,352] INFO [TransactionCoordinator id=102] Resigned as the txn coordinator for partition 15 at epoch Some(3) (kafka.coordinator.transaction.TransactionCoordinator)
[2024-08-26 15:31:09,352] INFO [Transaction State Manager 102]: Unloaded transaction metadata TxnMetadataCacheEntry(coordinatorEpoch=0, numTransactionalEntries=0) for __transaction_state-15 on become-follower transition (kafka.coordinator.transaction.TransactionStateManager)
[2024-08-26 15:31:09,353] INFO [GroupCoordinator 102]: Resigned as the group coordinator for partition 29 in epoch OptionalInt[3] (kafka.coordinator.group.GroupCoordinator)
[2024-08-26 15:31:09,353] INFO [GroupMetadataManager brokerId=102] Scheduling unloading of offsets and group metadata from __consumer_offsets-29 (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 15:31:09,354] INFO [TransactionCoordinator id=102] Resigned as the txn coordinator for partition 30 at epoch Some(3) (kafka.coordinator.transaction.TransactionCoordinator)
[2024-08-26 15:31:09,354] INFO [Transaction State Manager 102]: Unloaded transaction metadata TxnMetadataCacheEntry(coordinatorEpoch=0, numTransactionalEntries=0) for __transaction_state-30 on become-follower transition (kafka.coordinator.transaction.TransactionStateManager)
[2024-08-26 15:31:09,354] INFO [GroupMetadataManager brokerId=102] Finished unloading __consumer_offsets-29 for coordinator epoch OptionalInt[3]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 15:31:09,354] INFO [GroupCoordinator 102]: Resigned as the group coordinator for partition 44 in epoch OptionalInt[3] (kafka.coordinator.group.GroupCoordinator)
[2024-08-26 15:31:09,354] INFO [GroupMetadataManager brokerId=102] Scheduling unloading of offsets and group metadata from __consumer_offsets-44 (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 15:31:09,354] INFO [TransactionCoordinator id=102] Resigned as the txn coordinator for partition 45 at epoch Some(3) (kafka.coordinator.transaction.TransactionCoordinator)
[2024-08-26 15:31:09,354] INFO [GroupMetadataManager brokerId=102] Finished unloading __consumer_offsets-44 for coordinator epoch OptionalInt[3]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 15:31:09,354] INFO [Transaction State Manager 102]: Unloaded transaction metadata TxnMetadataCacheEntry(coordinatorEpoch=0, numTransactionalEntries=0) for __transaction_state-45 on become-follower transition (kafka.coordinator.transaction.TransactionStateManager)
[2024-08-26 15:31:09,361] INFO [GroupCoordinator 102]: Resigned as the group coordinator for partition 14 in epoch OptionalInt[3] (kafka.coordinator.group.GroupCoordinator)
[2024-08-26 15:31:09,362] INFO [GroupMetadataManager brokerId=102] Scheduling unloading of offsets and group metadata from __consumer_offsets-14 (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 15:31:09,362] INFO [TransactionCoordinator id=102] Resigned as the txn coordinator for partition 16 at epoch Some(2) (kafka.coordinator.transaction.TransactionCoordinator)
[2024-08-26 15:31:09,362] INFO [GroupMetadataManager brokerId=102] Finished unloading __consumer_offsets-14 for coordinator epoch OptionalInt[3]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 15:31:09,362] INFO [Transaction State Manager 102]: No cached transaction metadata found for __transaction_state-16 during become-follower transition (kafka.coordinator.transaction.TransactionStateManager)
[2024-08-26 15:31:09,362] INFO [TransactionCoordinator id=102] Resigned as the txn coordinator for partition 31 at epoch Some(2) (kafka.coordinator.transaction.TransactionCoordinator)
[2024-08-26 15:31:09,365] INFO [Transaction State Manager 102]: No cached transaction metadata found for __transaction_state-31 during become-follower transition (kafka.coordinator.transaction.TransactionStateManager)
[2024-08-26 15:31:09,365] INFO [GroupCoordinator 102]: Resigned as the group coordinator for partition 45 in epoch OptionalInt[2] (kafka.coordinator.group.GroupCoordinator)
[2024-08-26 15:31:09,365] INFO [GroupMetadataManager brokerId=102] Scheduling unloading of offsets and group metadata from __consumer_offsets-45 (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 15:31:09,365] INFO [TransactionCoordinator id=102] Resigned as the txn coordinator for partition 46 at epoch Some(2) (kafka.coordinator.transaction.TransactionCoordinator)
[2024-08-26 15:31:09,365] INFO [Transaction State Manager 102]: No cached transaction metadata found for __transaction_state-46 during become-follower transition (kafka.coordinator.transaction.TransactionStateManager)
[2024-08-26 15:31:09,366] INFO [GroupMetadataManager brokerId=102] Finished unloading __consumer_offsets-45 for coordinator epoch OptionalInt[2]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 15:31:09,366] INFO [GroupCoordinator 102]: Resigned as the group coordinator for partition 15 in epoch OptionalInt[2] (kafka.coordinator.group.GroupCoordinator)
[2024-08-26 15:31:09,366] INFO [GroupMetadataManager brokerId=102] Scheduling unloading of offsets and group metadata from __consumer_offsets-15 (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 15:31:09,366] INFO [GroupCoordinator 102]: Resigned as the group coordinator for partition 30 in epoch OptionalInt[2] (kafka.coordinator.group.GroupCoordinator)
[2024-08-26 15:31:09,366] INFO [GroupMetadataManager brokerId=102] Finished unloading __consumer_offsets-15 for coordinator epoch OptionalInt[2]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 15:31:09,366] INFO [GroupMetadataManager brokerId=102] Scheduling unloading of offsets and group metadata from __consumer_offsets-30 (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 15:31:09,367] INFO [GroupCoordinator 102]: Resigned as the group coordinator for partition 0 in epoch OptionalInt[2] (kafka.coordinator.group.GroupCoordinator)
[2024-08-26 15:31:09,367] INFO [GroupMetadataManager brokerId=102] Scheduling unloading of offsets and group metadata from __consumer_offsets-0 (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 15:31:09,367] INFO [GroupCoordinator 102]: Resigned as the group coordinator for partition 27 in epoch OptionalInt[2] (kafka.coordinator.group.GroupCoordinator)
[2024-08-26 15:31:09,367] INFO [GroupMetadataManager brokerId=102] Finished unloading __consumer_offsets-30 for coordinator epoch OptionalInt[2]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 15:31:09,367] INFO [GroupMetadataManager brokerId=102] Scheduling unloading of offsets and group metadata from __consumer_offsets-27 (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 15:31:09,402] INFO [GroupCoordinator 102]: Resigned as the group coordinator for partition 42 in epoch OptionalInt[2] (kafka.coordinator.group.GroupCoordinator)
[2024-08-26 15:31:09,402] INFO [GroupMetadataManager brokerId=102] Finished unloading __consumer_offsets-0 for coordinator epoch OptionalInt[2]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 15:31:09,402] INFO [GroupMetadataManager brokerId=102] Scheduling unloading of offsets and group metadata from __consumer_offsets-42 (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 15:31:09,403] INFO [GroupCoordinator 102]: Resigned as the group coordinator for partition 12 in epoch OptionalInt[2] (kafka.coordinator.group.GroupCoordinator)
[2024-08-26 15:31:09,403] INFO [GroupMetadataManager brokerId=102] Finished unloading __consumer_offsets-27 for coordinator epoch OptionalInt[2]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 15:31:09,404] INFO [GroupMetadataManager brokerId=102] Scheduling unloading of offsets and group metadata from __consumer_offsets-12 (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 15:31:09,404] INFO [GroupMetadataManager brokerId=102] Finished unloading __consumer_offsets-42 for coordinator epoch OptionalInt[2]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 15:31:09,404] INFO [GroupMetadataManager brokerId=102] Finished unloading __consumer_offsets-12 for coordinator epoch OptionalInt[2]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 15:31:09,404] INFO [TransactionCoordinator id=102] Resigned as the txn coordinator for partition 13 at epoch Some(2) (kafka.coordinator.transaction.TransactionCoordinator)
[2024-08-26 15:31:10,352] INFO [Transaction State Manager 102]: No cached transaction metadata found for __transaction_state-13 during become-follower transition (kafka.coordinator.transaction.TransactionStateManager)
[2024-08-26 15:31:10,352] INFO [TransactionCoordinator id=102] Resigned as the txn coordinator for partition 28 at epoch Some(2) (kafka.coordinator.transaction.TransactionCoordinator)
[2024-08-26 15:31:10,352] INFO [Transaction State Manager 102]: No cached transaction metadata found for __transaction_state-28 during become-follower transition (kafka.coordinator.transaction.TransactionStateManager)
[2024-08-26 15:31:10,352] INFO [TransactionCoordinator id=102] Resigned as the txn coordinator for partition 43 at epoch Some(2) (kafka.coordinator.transaction.TransactionCoordinator)
[2024-08-26 15:31:10,353] INFO [Transaction State Manager 102]: No cached transaction metadata found for __transaction_state-43 during become-follower transition (kafka.coordinator.transaction.TransactionStateManager)
[2024-08-26 15:31:10,368] INFO [GroupCoordinator 102]: Resigned as the group coordinator for partition 43 in epoch OptionalInt[3] (kafka.coordinator.group.GroupCoordinator)
[2024-08-26 15:31:10,368] INFO [GroupMetadataManager brokerId=102] Scheduling unloading of offsets and group metadata from __consumer_offsets-43 (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 15:31:10,369] INFO [GroupCoordinator 102]: Resigned as the group coordinator for partition 13 in epoch OptionalInt[3] (kafka.coordinator.group.GroupCoordinator)
[2024-08-26 15:31:10,369] INFO [GroupMetadataManager brokerId=102] Scheduling unloading of offsets and group metadata from __consumer_offsets-13 (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 15:31:10,369] INFO [GroupMetadataManager brokerId=102] Finished unloading __consumer_offsets-43 for coordinator epoch OptionalInt[3]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 15:31:10,369] INFO [TransactionCoordinator id=102] Resigned as the txn coordinator for partition 14 at epoch Some(3) (kafka.coordinator.transaction.TransactionCoordinator)
[2024-08-26 15:31:10,404] INFO [Transaction State Manager 102]: No cached transaction metadata found for __transaction_state-14 during become-follower transition (kafka.coordinator.transaction.TransactionStateManager)
[2024-08-26 15:31:10,404] INFO [GroupMetadataManager brokerId=102] Finished unloading __consumer_offsets-13 for coordinator epoch OptionalInt[3]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 15:31:10,404] INFO [GroupCoordinator 102]: Resigned as the group coordinator for partition 28 in epoch OptionalInt[3] (kafka.coordinator.group.GroupCoordinator)
[2024-08-26 15:31:10,405] INFO [GroupMetadataManager brokerId=102] Scheduling unloading of offsets and group metadata from __consumer_offsets-28 (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 15:31:10,405] INFO [TransactionCoordinator id=102] Resigned as the txn coordinator for partition 29 at epoch Some(3) (kafka.coordinator.transaction.TransactionCoordinator)
[2024-08-26 15:31:10,405] INFO [GroupMetadataManager brokerId=102] Finished unloading __consumer_offsets-28 for coordinator epoch OptionalInt[3]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 15:31:10,405] INFO [Transaction State Manager 102]: No cached transaction metadata found for __transaction_state-29 during become-follower transition (kafka.coordinator.transaction.TransactionStateManager)
[2024-08-26 15:31:10,406] INFO [TransactionCoordinator id=102] Resigned as the txn coordinator for partition 44 at epoch Some(3) (kafka.coordinator.transaction.TransactionCoordinator)
[2024-08-26 15:31:10,406] INFO [Transaction State Manager 102]: No cached transaction metadata found for __transaction_state-44 during become-follower transition (kafka.coordinator.transaction.TransactionStateManager)
[2024-08-26 15:31:10,423] INFO [ReplicaFetcherManager on broker 102] Removed fetcher for partitions HashSet(odd-numbers-0, numbers-2, merged-numbers-1, even-numbers-0, doubled-numbers-2) (kafka.server.ReplicaFetcherManager)
[2024-08-26 15:36:02,958] INFO [ReplicaFetcherManager on broker 102] Removed fetcher for partitions HashSet(__transaction_state-42, __transaction_state-45, __transaction_state-48, __transaction_state-0, __consumer_offsets-47, __transaction_state-39, __transaction_state-6, __transaction_state-9, __consumer_offsets-17, __consumer_offsets-11, __transaction_state-18, __transaction_state-36, __consumer_offsets-32, __transaction_state-15, __transaction_state-12, __consumer_offsets-8, __consumer_offsets-35, __transaction_state-24, __consumer_offsets-41, __consumer_offsets-23, __transaction_state-3, __transaction_state-21, __transaction_state-30, __transaction_state-33, __consumer_offsets-38, __consumer_offsets-2, __consumer_offsets-14, __consumer_offsets-20, __consumer_offsets-44, __consumer_offsets-5, __consumer_offsets-26, __transaction_state-27, __consumer_offsets-29) (kafka.server.ReplicaFetcherManager)
[2024-08-26 15:36:03,135] INFO [ReplicaFetcher replicaId=102, leaderId=101, fetcherId=0] Partition __transaction_state-17 has an older epoch (3) than the current leader. Will await the new LeaderAndIsr state before resuming fetching. (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:36:03,136] WARN [ReplicaFetcher replicaId=102, leaderId=101, fetcherId=0] Partition __transaction_state-17 marked as failed (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:36:03,136] INFO [ReplicaFetcher replicaId=102, leaderId=101, fetcherId=0] Partition __transaction_state-26 has an older epoch (3) than the current leader. Will await the new LeaderAndIsr state before resuming fetching. (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:36:03,147] WARN [ReplicaFetcher replicaId=102, leaderId=101, fetcherId=0] Partition __transaction_state-26 marked as failed (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:36:03,147] INFO [ReplicaFetcher replicaId=102, leaderId=101, fetcherId=0] Partition __transaction_state-8 has an older epoch (3) than the current leader. Will await the new LeaderAndIsr state before resuming fetching. (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:36:03,147] WARN [ReplicaFetcher replicaId=102, leaderId=101, fetcherId=0] Partition __transaction_state-8 marked as failed (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:36:03,147] INFO [ReplicaFetcher replicaId=102, leaderId=101, fetcherId=0] Partition __transaction_state-41 has an older epoch (3) than the current leader. Will await the new LeaderAndIsr state before resuming fetching. (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:36:03,147] WARN [ReplicaFetcher replicaId=102, leaderId=101, fetcherId=0] Partition __transaction_state-41 marked as failed (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:36:03,148] INFO [ReplicaFetcher replicaId=102, leaderId=101, fetcherId=0] Partition __transaction_state-32 has an older epoch (3) than the current leader. Will await the new LeaderAndIsr state before resuming fetching. (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:36:03,148] WARN [ReplicaFetcher replicaId=102, leaderId=101, fetcherId=0] Partition __transaction_state-32 marked as failed (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:36:03,148] INFO [ReplicaFetcher replicaId=102, leaderId=101, fetcherId=0] Partition __transaction_state-14 has an older epoch (3) than the current leader. Will await the new LeaderAndIsr state before resuming fetching. (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:36:03,148] WARN [ReplicaFetcher replicaId=102, leaderId=101, fetcherId=0] Partition __transaction_state-14 marked as failed (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:36:03,148] INFO [ReplicaFetcher replicaId=102, leaderId=101, fetcherId=0] Partition __transaction_state-47 has an older epoch (3) than the current leader. Will await the new LeaderAndIsr state before resuming fetching. (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:36:03,148] WARN [ReplicaFetcher replicaId=102, leaderId=101, fetcherId=0] Partition __transaction_state-47 marked as failed (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:36:03,148] INFO [ReplicaFetcher replicaId=102, leaderId=101, fetcherId=0] Partition __transaction_state-23 has an older epoch (3) than the current leader. Will await the new LeaderAndIsr state before resuming fetching. (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:36:03,148] WARN [ReplicaFetcher replicaId=102, leaderId=101, fetcherId=0] Partition __transaction_state-23 marked as failed (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:36:03,148] INFO [ReplicaFetcher replicaId=102, leaderId=101, fetcherId=0] Partition __transaction_state-5 has an older epoch (3) than the current leader. Will await the new LeaderAndIsr state before resuming fetching. (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:36:03,149] WARN [ReplicaFetcher replicaId=102, leaderId=101, fetcherId=0] Partition __transaction_state-5 marked as failed (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:36:03,149] INFO [ReplicaFetcher replicaId=102, leaderId=101, fetcherId=0] Partition __transaction_state-38 has an older epoch (3) than the current leader. Will await the new LeaderAndIsr state before resuming fetching. (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:36:03,149] WARN [ReplicaFetcher replicaId=102, leaderId=101, fetcherId=0] Partition __transaction_state-38 marked as failed (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:36:03,149] INFO [ReplicaFetcher replicaId=102, leaderId=101, fetcherId=0] Partition __transaction_state-29 has an older epoch (3) than the current leader. Will await the new LeaderAndIsr state before resuming fetching. (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:36:03,149] WARN [ReplicaFetcher replicaId=102, leaderId=101, fetcherId=0] Partition __transaction_state-29 marked as failed (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:36:03,149] INFO [ReplicaFetcher replicaId=102, leaderId=101, fetcherId=0] Partition __transaction_state-11 has an older epoch (3) than the current leader. Will await the new LeaderAndIsr state before resuming fetching. (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:36:03,149] WARN [ReplicaFetcher replicaId=102, leaderId=101, fetcherId=0] Partition __transaction_state-11 marked as failed (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:36:03,149] INFO [ReplicaFetcher replicaId=102, leaderId=101, fetcherId=0] Partition __transaction_state-44 has an older epoch (3) than the current leader. Will await the new LeaderAndIsr state before resuming fetching. (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:36:03,149] WARN [ReplicaFetcher replicaId=102, leaderId=101, fetcherId=0] Partition __transaction_state-44 marked as failed (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:36:03,150] INFO [ReplicaFetcher replicaId=102, leaderId=101, fetcherId=0] Partition __transaction_state-20 has an older epoch (3) than the current leader. Will await the new LeaderAndIsr state before resuming fetching. (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:36:03,150] WARN [ReplicaFetcher replicaId=102, leaderId=101, fetcherId=0] Partition __transaction_state-20 marked as failed (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:36:03,150] INFO [ReplicaFetcher replicaId=102, leaderId=101, fetcherId=0] Partition __transaction_state-35 has an older epoch (3) than the current leader. Will await the new LeaderAndIsr state before resuming fetching. (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:36:03,150] WARN [ReplicaFetcher replicaId=102, leaderId=101, fetcherId=0] Partition __transaction_state-35 marked as failed (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:36:03,150] INFO [ReplicaFetcher replicaId=102, leaderId=101, fetcherId=0] Partition __consumer_offsets-13 has an older epoch (3) than the current leader. Will await the new LeaderAndIsr state before resuming fetching. (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:36:03,150] WARN [ReplicaFetcher replicaId=102, leaderId=101, fetcherId=0] Partition __consumer_offsets-13 marked as failed (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:36:03,150] INFO [ReplicaFetcher replicaId=102, leaderId=101, fetcherId=0] Partition __consumer_offsets-46 has an older epoch (3) than the current leader. Will await the new LeaderAndIsr state before resuming fetching. (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:36:03,150] WARN [ReplicaFetcher replicaId=102, leaderId=101, fetcherId=0] Partition __consumer_offsets-46 marked as failed (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:36:03,150] INFO [ReplicaFetcher replicaId=102, leaderId=101, fetcherId=0] Partition __consumer_offsets-37 has an older epoch (3) than the current leader. Will await the new LeaderAndIsr state before resuming fetching. (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:36:03,150] WARN [ReplicaFetcher replicaId=102, leaderId=101, fetcherId=0] Partition __consumer_offsets-37 marked as failed (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:36:03,151] INFO [ReplicaFetcher replicaId=102, leaderId=101, fetcherId=0] Partition __consumer_offsets-4 has an older epoch (3) than the current leader. Will await the new LeaderAndIsr state before resuming fetching. (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:36:03,151] WARN [ReplicaFetcher replicaId=102, leaderId=101, fetcherId=0] Partition __consumer_offsets-4 marked as failed (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:36:03,151] INFO [ReplicaFetcher replicaId=102, leaderId=101, fetcherId=0] Partition __consumer_offsets-7 has an older epoch (3) than the current leader. Will await the new LeaderAndIsr state before resuming fetching. (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:36:03,151] WARN [ReplicaFetcher replicaId=102, leaderId=101, fetcherId=0] Partition __consumer_offsets-7 marked as failed (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:36:03,151] INFO [ReplicaFetcher replicaId=102, leaderId=101, fetcherId=0] Partition __consumer_offsets-40 has an older epoch (3) than the current leader. Will await the new LeaderAndIsr state before resuming fetching. (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:36:03,151] WARN [ReplicaFetcher replicaId=102, leaderId=101, fetcherId=0] Partition __consumer_offsets-40 marked as failed (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:36:03,151] INFO [ReplicaFetcher replicaId=102, leaderId=101, fetcherId=0] Partition __consumer_offsets-22 has an older epoch (3) than the current leader. Will await the new LeaderAndIsr state before resuming fetching. (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:36:03,151] WARN [ReplicaFetcher replicaId=102, leaderId=101, fetcherId=0] Partition __consumer_offsets-22 marked as failed (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:36:03,152] INFO [ReplicaFetcher replicaId=102, leaderId=101, fetcherId=0] Partition __consumer_offsets-1 has an older epoch (3) than the current leader. Will await the new LeaderAndIsr state before resuming fetching. (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:36:03,152] WARN [ReplicaFetcher replicaId=102, leaderId=101, fetcherId=0] Partition __consumer_offsets-1 marked as failed (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:36:03,152] INFO [ReplicaFetcher replicaId=102, leaderId=101, fetcherId=0] Partition __consumer_offsets-34 has an older epoch (3) than the current leader. Will await the new LeaderAndIsr state before resuming fetching. (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:36:03,152] WARN [ReplicaFetcher replicaId=102, leaderId=101, fetcherId=0] Partition __consumer_offsets-34 marked as failed (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:36:03,152] INFO [ReplicaFetcher replicaId=102, leaderId=101, fetcherId=0] Partition __consumer_offsets-16 has an older epoch (3) than the current leader. Will await the new LeaderAndIsr state before resuming fetching. (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:36:03,152] WARN [ReplicaFetcher replicaId=102, leaderId=101, fetcherId=0] Partition __consumer_offsets-16 marked as failed (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:36:03,152] INFO [ReplicaFetcher replicaId=102, leaderId=101, fetcherId=0] Partition __consumer_offsets-49 has an older epoch (3) than the current leader. Will await the new LeaderAndIsr state before resuming fetching. (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:36:03,152] WARN [ReplicaFetcher replicaId=102, leaderId=101, fetcherId=0] Partition __consumer_offsets-49 marked as failed (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:36:03,152] INFO [ReplicaFetcher replicaId=102, leaderId=101, fetcherId=0] Partition __consumer_offsets-25 has an older epoch (3) than the current leader. Will await the new LeaderAndIsr state before resuming fetching. (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:36:03,153] WARN [ReplicaFetcher replicaId=102, leaderId=101, fetcherId=0] Partition __consumer_offsets-25 marked as failed (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:36:03,153] INFO [ReplicaFetcher replicaId=102, leaderId=101, fetcherId=0] Partition __consumer_offsets-19 has an older epoch (3) than the current leader. Will await the new LeaderAndIsr state before resuming fetching. (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:36:03,157] WARN [ReplicaFetcher replicaId=102, leaderId=101, fetcherId=0] Partition __consumer_offsets-19 marked as failed (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:36:03,157] INFO [ReplicaFetcher replicaId=102, leaderId=101, fetcherId=0] Partition __consumer_offsets-28 has an older epoch (3) than the current leader. Will await the new LeaderAndIsr state before resuming fetching. (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:36:03,158] WARN [ReplicaFetcher replicaId=102, leaderId=101, fetcherId=0] Partition __consumer_offsets-28 marked as failed (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:36:03,158] INFO [ReplicaFetcher replicaId=102, leaderId=101, fetcherId=0] Partition __consumer_offsets-43 has an older epoch (3) than the current leader. Will await the new LeaderAndIsr state before resuming fetching. (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:36:03,159] WARN [ReplicaFetcher replicaId=102, leaderId=101, fetcherId=0] Partition __consumer_offsets-43 marked as failed (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:36:03,159] INFO [ReplicaFetcher replicaId=102, leaderId=101, fetcherId=0] Partition __consumer_offsets-10 has an older epoch (3) than the current leader. Will await the new LeaderAndIsr state before resuming fetching. (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:36:03,159] WARN [ReplicaFetcher replicaId=102, leaderId=101, fetcherId=0] Partition __consumer_offsets-10 marked as failed (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:36:03,159] INFO [ReplicaFetcher replicaId=102, leaderId=101, fetcherId=0] Partition __transaction_state-2 has an older epoch (3) than the current leader. Will await the new LeaderAndIsr state before resuming fetching. (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:36:03,159] WARN [ReplicaFetcher replicaId=102, leaderId=101, fetcherId=0] Partition __transaction_state-2 marked as failed (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:36:03,159] INFO [ReplicaFetcher replicaId=102, leaderId=101, fetcherId=0] Partition __consumer_offsets-31 has an older epoch (3) than the current leader. Will await the new LeaderAndIsr state before resuming fetching. (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:36:03,159] WARN [ReplicaFetcher replicaId=102, leaderId=101, fetcherId=0] Partition __consumer_offsets-31 marked as failed (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:36:03,702] INFO [TransactionCoordinator id=102] Elected as the txn coordinator for partition 3 at epoch 4 (kafka.coordinator.transaction.TransactionCoordinator)
[2024-08-26 15:36:03,704] INFO [GroupCoordinator 102]: Elected as the group coordinator for partition 41 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2024-08-26 15:36:03,704] INFO [Transaction State Manager 102]: Loading transaction metadata from __transaction_state-3 at epoch 4 (kafka.coordinator.transaction.TransactionStateManager)
[2024-08-26 15:36:03,704] INFO [GroupMetadataManager brokerId=102] Scheduling loading of offsets and group metadata from __consumer_offsets-41 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 15:36:03,705] INFO [TransactionCoordinator id=102] Elected as the txn coordinator for partition 18 at epoch 4 (kafka.coordinator.transaction.TransactionCoordinator)
[2024-08-26 15:36:03,705] INFO [TransactionCoordinator id=102] Elected as the txn coordinator for partition 33 at epoch 4 (kafka.coordinator.transaction.TransactionCoordinator)
[2024-08-26 15:36:03,705] INFO [TransactionCoordinator id=102] Elected as the txn coordinator for partition 0 at epoch 4 (kafka.coordinator.transaction.TransactionCoordinator)
[2024-08-26 15:36:03,705] INFO [TransactionCoordinator id=102] Elected as the txn coordinator for partition 15 at epoch 4 (kafka.coordinator.transaction.TransactionCoordinator)
[2024-08-26 15:36:03,705] INFO [GroupCoordinator 102]: Elected as the group coordinator for partition 29 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2024-08-26 15:36:03,705] INFO [GroupMetadataManager brokerId=102] Scheduling loading of offsets and group metadata from __consumer_offsets-29 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 15:36:03,705] INFO [GroupMetadataManager brokerId=102] Finished loading offsets and group metadata from __consumer_offsets-41 in 1 milliseconds for epoch 4, of which 1 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 15:36:03,705] INFO [TransactionCoordinator id=102] Elected as the txn coordinator for partition 30 at epoch 4 (kafka.coordinator.transaction.TransactionCoordinator)
[2024-08-26 15:36:03,705] INFO [GroupCoordinator 102]: Elected as the group coordinator for partition 44 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2024-08-26 15:36:03,705] INFO [GroupMetadataManager brokerId=102] Scheduling loading of offsets and group metadata from __consumer_offsets-44 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 15:36:03,705] INFO [GroupMetadataManager brokerId=102] Finished loading offsets and group metadata from __consumer_offsets-29 in 0 milliseconds for epoch 4, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 15:36:03,705] INFO [TransactionCoordinator id=102] Elected as the txn coordinator for partition 45 at epoch 4 (kafka.coordinator.transaction.TransactionCoordinator)
[2024-08-26 15:36:03,706] INFO [GroupMetadataManager brokerId=102] Finished loading offsets and group metadata from __consumer_offsets-44 in 1 milliseconds for epoch 4, of which 1 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 15:36:03,706] INFO [GroupCoordinator 102]: Elected as the group coordinator for partition 14 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2024-08-26 15:36:03,706] INFO [GroupMetadataManager brokerId=102] Scheduling loading of offsets and group metadata from __consumer_offsets-14 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 15:36:03,706] INFO [GroupCoordinator 102]: Elected as the group coordinator for partition 23 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2024-08-26 15:36:03,706] INFO [GroupMetadataManager brokerId=102] Scheduling loading of offsets and group metadata from __consumer_offsets-23 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 15:36:03,706] INFO [GroupCoordinator 102]: Elected as the group coordinator for partition 38 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2024-08-26 15:36:03,706] INFO [GroupMetadataManager brokerId=102] Scheduling loading of offsets and group metadata from __consumer_offsets-38 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 15:36:03,706] INFO [GroupMetadataManager brokerId=102] Finished loading offsets and group metadata from __consumer_offsets-14 in 0 milliseconds for epoch 4, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 15:36:03,706] INFO [GroupCoordinator 102]: Elected as the group coordinator for partition 8 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2024-08-26 15:36:03,706] INFO [GroupMetadataManager brokerId=102] Scheduling loading of offsets and group metadata from __consumer_offsets-8 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 15:36:03,706] INFO [GroupCoordinator 102]: Elected as the group coordinator for partition 11 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2024-08-26 15:36:03,706] INFO [GroupMetadataManager brokerId=102] Scheduling loading of offsets and group metadata from __consumer_offsets-11 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 15:36:03,706] INFO [GroupMetadataManager brokerId=102] Finished loading offsets and group metadata from __consumer_offsets-23 in 0 milliseconds for epoch 4, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 15:36:03,706] INFO [GroupCoordinator 102]: Elected as the group coordinator for partition 26 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2024-08-26 15:36:03,707] INFO [GroupMetadataManager brokerId=102] Finished loading offsets and group metadata from __consumer_offsets-38 in 1 milliseconds for epoch 4, of which 1 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 15:36:03,707] INFO [GroupMetadataManager brokerId=102] Scheduling loading of offsets and group metadata from __consumer_offsets-26 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 15:36:03,707] INFO [TransactionCoordinator id=102] Elected as the txn coordinator for partition 12 at epoch 4 (kafka.coordinator.transaction.TransactionCoordinator)
[2024-08-26 15:36:03,707] INFO [GroupMetadataManager brokerId=102] Finished loading offsets and group metadata from __consumer_offsets-8 in 1 milliseconds for epoch 4, of which 1 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 15:36:03,707] INFO [GroupMetadataManager brokerId=102] Finished loading offsets and group metadata from __consumer_offsets-11 in 1 milliseconds for epoch 4, of which 1 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 15:36:03,707] INFO [GroupMetadataManager brokerId=102] Finished loading offsets and group metadata from __consumer_offsets-26 in 0 milliseconds for epoch 4, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 15:36:03,707] INFO [TransactionCoordinator id=102] Elected as the txn coordinator for partition 27 at epoch 4 (kafka.coordinator.transaction.TransactionCoordinator)
[2024-08-26 15:36:03,707] INFO [TransactionCoordinator id=102] Elected as the txn coordinator for partition 42 at epoch 4 (kafka.coordinator.transaction.TransactionCoordinator)
[2024-08-26 15:36:03,707] INFO [GroupCoordinator 102]: Elected as the group coordinator for partition 35 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2024-08-26 15:36:03,707] INFO [GroupMetadataManager brokerId=102] Scheduling loading of offsets and group metadata from __consumer_offsets-35 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 15:36:03,707] INFO [TransactionCoordinator id=102] Elected as the txn coordinator for partition 24 at epoch 4 (kafka.coordinator.transaction.TransactionCoordinator)
[2024-08-26 15:36:03,708] INFO [TransactionCoordinator id=102] Elected as the txn coordinator for partition 39 at epoch 4 (kafka.coordinator.transaction.TransactionCoordinator)
[2024-08-26 15:36:03,708] INFO [GroupMetadataManager brokerId=102] Finished loading offsets and group metadata from __consumer_offsets-35 in 1 milliseconds for epoch 4, of which 1 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 15:36:03,708] INFO [GroupCoordinator 102]: Elected as the group coordinator for partition 5 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2024-08-26 15:36:03,708] INFO [GroupMetadataManager brokerId=102] Scheduling loading of offsets and group metadata from __consumer_offsets-5 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 15:36:03,708] INFO [GroupCoordinator 102]: Elected as the group coordinator for partition 20 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2024-08-26 15:36:03,708] INFO [GroupMetadataManager brokerId=102] Scheduling loading of offsets and group metadata from __consumer_offsets-20 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 15:36:03,708] INFO [TransactionCoordinator id=102] Elected as the txn coordinator for partition 9 at epoch 4 (kafka.coordinator.transaction.TransactionCoordinator)
[2024-08-26 15:36:03,708] INFO [GroupMetadataManager brokerId=102] Finished loading offsets and group metadata from __consumer_offsets-5 in 0 milliseconds for epoch 4, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 15:36:03,708] INFO [GroupCoordinator 102]: Elected as the group coordinator for partition 2 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2024-08-26 15:36:03,708] INFO [GroupMetadataManager brokerId=102] Scheduling loading of offsets and group metadata from __consumer_offsets-2 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 15:36:03,708] INFO [GroupMetadataManager brokerId=102] Finished loading offsets and group metadata from __consumer_offsets-20 in 0 milliseconds for epoch 4, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 15:36:03,708] INFO [TransactionCoordinator id=102] Elected as the txn coordinator for partition 6 at epoch 4 (kafka.coordinator.transaction.TransactionCoordinator)
[2024-08-26 15:36:03,708] INFO [GroupMetadataManager brokerId=102] Finished loading offsets and group metadata from __consumer_offsets-2 in 0 milliseconds for epoch 4, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 15:36:03,708] INFO [TransactionCoordinator id=102] Elected as the txn coordinator for partition 21 at epoch 4 (kafka.coordinator.transaction.TransactionCoordinator)
[2024-08-26 15:36:03,708] INFO [TransactionCoordinator id=102] Elected as the txn coordinator for partition 36 at epoch 4 (kafka.coordinator.transaction.TransactionCoordinator)
[2024-08-26 15:36:03,708] INFO [TransactionCoordinator id=102] Elected as the txn coordinator for partition 48 at epoch 4 (kafka.coordinator.transaction.TransactionCoordinator)
[2024-08-26 15:36:03,708] INFO [GroupCoordinator 102]: Elected as the group coordinator for partition 47 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2024-08-26 15:36:03,708] INFO [GroupMetadataManager brokerId=102] Scheduling loading of offsets and group metadata from __consumer_offsets-47 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 15:36:03,708] INFO [GroupCoordinator 102]: Elected as the group coordinator for partition 17 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2024-08-26 15:36:03,708] INFO [GroupMetadataManager brokerId=102] Scheduling loading of offsets and group metadata from __consumer_offsets-17 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 15:36:03,708] INFO [GroupCoordinator 102]: Elected as the group coordinator for partition 32 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2024-08-26 15:36:03,708] INFO [GroupMetadataManager brokerId=102] Finished loading offsets and group metadata from __consumer_offsets-47 in 0 milliseconds for epoch 4, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 15:36:03,709] INFO [GroupMetadataManager brokerId=102] Scheduling loading of offsets and group metadata from __consumer_offsets-32 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 15:36:03,709] INFO [GroupMetadataManager brokerId=102] Finished loading offsets and group metadata from __consumer_offsets-17 in 1 milliseconds for epoch 4, of which 1 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 15:36:03,709] INFO [GroupMetadataManager brokerId=102] Finished loading offsets and group metadata from __consumer_offsets-32 in 0 milliseconds for epoch 4, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 15:36:03,718] INFO [ReplicaFetcherManager on broker 102] Removed fetcher for partitions HashSet(__transaction_state-11, __consumer_offsets-13, __transaction_state-44, __consumer_offsets-46, __transaction_state-17, __transaction_state-5, __consumer_offsets-19, __transaction_state-38, __transaction_state-26, __consumer_offsets-28, __transaction_state-32, __consumer_offsets-7, __consumer_offsets-40, __transaction_state-20, __consumer_offsets-1, __consumer_offsets-34, __consumer_offsets-16, __consumer_offsets-43, __transaction_state-14, __transaction_state-47, __consumer_offsets-10, __transaction_state-2, __transaction_state-35, __consumer_offsets-22, __consumer_offsets-49, __transaction_state-8, __transaction_state-41, __consumer_offsets-31, __transaction_state-29, __consumer_offsets-25, __consumer_offsets-37, __consumer_offsets-4, __transaction_state-23) (kafka.server.ReplicaFetcherManager)
[2024-08-26 15:36:03,721] INFO [ReplicaFetcherThread-0-103]: Starting (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:36:03,721] INFO [ReplicaFetcherManager on broker 102] Added fetcher to broker 103 for partitions HashMap(__consumer_offsets-22 -> InitialFetchState(Some(YjLy0o7SQV-jY9Xq9d2rFw),BrokerEndPoint(id=103, host=localhost:9094),4,0), __consumer_offsets-4 -> InitialFetchState(Some(YjLy0o7SQV-jY9Xq9d2rFw),BrokerEndPoint(id=103, host=localhost:9094),4,0), __consumer_offsets-25 -> InitialFetchState(Some(YjLy0o7SQV-jY9Xq9d2rFw),BrokerEndPoint(id=103, host=localhost:9094),4,0), __consumer_offsets-49 -> InitialFetchState(Some(YjLy0o7SQV-jY9Xq9d2rFw),BrokerEndPoint(id=103, host=localhost:9094),4,0), __transaction_state-32 -> InitialFetchState(Some(GeNTnPQnQvCfhJ6N7pXZsQ),BrokerEndPoint(id=103, host=localhost:9094),4,0), __transaction_state-17 -> InitialFetchState(Some(GeNTnPQnQvCfhJ6N7pXZsQ),BrokerEndPoint(id=103, host=localhost:9094),4,0), __consumer_offsets-19 -> InitialFetchState(Some(YjLy0o7SQV-jY9Xq9d2rFw),BrokerEndPoint(id=103, host=localhost:9094),4,0), __consumer_offsets-43 -> InitialFetchState(Some(YjLy0o7SQV-jY9Xq9d2rFw),BrokerEndPoint(id=103, host=localhost:9094),4,0), __transaction_state-11 -> InitialFetchState(Some(GeNTnPQnQvCfhJ6N7pXZsQ),BrokerEndPoint(id=103, host=localhost:9094),4,0), __consumer_offsets-1 -> InitialFetchState(Some(YjLy0o7SQV-jY9Xq9d2rFw),BrokerEndPoint(id=103, host=localhost:9094),4,0), __consumer_offsets-7 -> InitialFetchState(Some(YjLy0o7SQV-jY9Xq9d2rFw),BrokerEndPoint(id=103, host=localhost:9094),4,0), __consumer_offsets-46 -> InitialFetchState(Some(YjLy0o7SQV-jY9Xq9d2rFw),BrokerEndPoint(id=103, host=localhost:9094),4,0), __transaction_state-2 -> InitialFetchState(Some(GeNTnPQnQvCfhJ6N7pXZsQ),BrokerEndPoint(id=103, host=localhost:9094),4,13548), __transaction_state-20 -> InitialFetchState(Some(GeNTnPQnQvCfhJ6N7pXZsQ),BrokerEndPoint(id=103, host=localhost:9094),4,0), __consumer_offsets-16 -> InitialFetchState(Some(YjLy0o7SQV-jY9Xq9d2rFw),BrokerEndPoint(id=103, host=localhost:9094),4,0), __consumer_offsets-28 -> InitialFetchState(Some(YjLy0o7SQV-jY9Xq9d2rFw),BrokerEndPoint(id=103, host=localhost:9094),4,0), __consumer_offsets-31 -> InitialFetchState(Some(YjLy0o7SQV-jY9Xq9d2rFw),BrokerEndPoint(id=103, host=localhost:9094),4,17666), __transaction_state-29 -> InitialFetchState(Some(GeNTnPQnQvCfhJ6N7pXZsQ),BrokerEndPoint(id=103, host=localhost:9094),4,0), __consumer_offsets-37 -> InitialFetchState(Some(YjLy0o7SQV-jY9Xq9d2rFw),BrokerEndPoint(id=103, host=localhost:9094),4,0), __transaction_state-38 -> InitialFetchState(Some(GeNTnPQnQvCfhJ6N7pXZsQ),BrokerEndPoint(id=103, host=localhost:9094),4,0), __transaction_state-14 -> InitialFetchState(Some(GeNTnPQnQvCfhJ6N7pXZsQ),BrokerEndPoint(id=103, host=localhost:9094),4,0), __transaction_state-44 -> InitialFetchState(Some(GeNTnPQnQvCfhJ6N7pXZsQ),BrokerEndPoint(id=103, host=localhost:9094),4,0), __transaction_state-23 -> InitialFetchState(Some(GeNTnPQnQvCfhJ6N7pXZsQ),BrokerEndPoint(id=103, host=localhost:9094),4,0), __transaction_state-47 -> InitialFetchState(Some(GeNTnPQnQvCfhJ6N7pXZsQ),BrokerEndPoint(id=103, host=localhost:9094),4,0), __consumer_offsets-13 -> InitialFetchState(Some(YjLy0o7SQV-jY9Xq9d2rFw),BrokerEndPoint(id=103, host=localhost:9094),4,0), __transaction_state-26 -> InitialFetchState(Some(GeNTnPQnQvCfhJ6N7pXZsQ),BrokerEndPoint(id=103, host=localhost:9094),4,0), __transaction_state-5 -> InitialFetchState(Some(GeNTnPQnQvCfhJ6N7pXZsQ),BrokerEndPoint(id=103, host=localhost:9094),4,0), __transaction_state-8 -> InitialFetchState(Some(GeNTnPQnQvCfhJ6N7pXZsQ),BrokerEndPoint(id=103, host=localhost:9094),4,0), __transaction_state-41 -> InitialFetchState(Some(GeNTnPQnQvCfhJ6N7pXZsQ),BrokerEndPoint(id=103, host=localhost:9094),4,0), __consumer_offsets-34 -> InitialFetchState(Some(YjLy0o7SQV-jY9Xq9d2rFw),BrokerEndPoint(id=103, host=localhost:9094),4,0), __consumer_offsets-10 -> InitialFetchState(Some(YjLy0o7SQV-jY9Xq9d2rFw),BrokerEndPoint(id=103, host=localhost:9094),4,0), __transaction_state-35 -> InitialFetchState(Some(GeNTnPQnQvCfhJ6N7pXZsQ),BrokerEndPoint(id=103, host=localhost:9094),4,0), __consumer_offsets-40 -> InitialFetchState(Some(YjLy0o7SQV-jY9Xq9d2rFw),BrokerEndPoint(id=103, host=localhost:9094),4,0)) (kafka.server.ReplicaFetcherManager)
[2024-08-26 15:36:03,721] INFO [ReplicaFetcher replicaId=102, leaderId=103, fetcherId=0] Truncating partition __transaction_state-11 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:36:03,735] INFO [UnifiedLog partition=__transaction_state-11, dir=/tmp/kafka-logs-102] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2024-08-26 15:36:03,735] INFO [ReplicaFetcher replicaId=102, leaderId=103, fetcherId=0] Truncating partition __consumer_offsets-13 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:36:03,735] INFO [UnifiedLog partition=__consumer_offsets-13, dir=/tmp/kafka-logs-102] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2024-08-26 15:36:03,735] INFO [ReplicaFetcher replicaId=102, leaderId=103, fetcherId=0] Truncating partition __transaction_state-44 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:36:03,735] INFO [UnifiedLog partition=__transaction_state-44, dir=/tmp/kafka-logs-102] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2024-08-26 15:36:03,735] INFO [ReplicaFetcher replicaId=102, leaderId=103, fetcherId=0] Truncating partition __consumer_offsets-46 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:36:03,736] INFO [UnifiedLog partition=__consumer_offsets-46, dir=/tmp/kafka-logs-102] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2024-08-26 15:36:03,736] INFO [ReplicaFetcher replicaId=102, leaderId=103, fetcherId=0] Truncating partition __transaction_state-17 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:36:03,736] INFO [UnifiedLog partition=__transaction_state-17, dir=/tmp/kafka-logs-102] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2024-08-26 15:36:03,736] INFO [ReplicaFetcher replicaId=102, leaderId=103, fetcherId=0] Truncating partition __transaction_state-5 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:36:03,736] INFO [UnifiedLog partition=__transaction_state-5, dir=/tmp/kafka-logs-102] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2024-08-26 15:36:03,736] INFO [ReplicaFetcher replicaId=102, leaderId=103, fetcherId=0] Truncating partition __consumer_offsets-19 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:36:03,736] INFO [UnifiedLog partition=__consumer_offsets-19, dir=/tmp/kafka-logs-102] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2024-08-26 15:36:03,736] INFO [ReplicaFetcher replicaId=102, leaderId=103, fetcherId=0] Truncating partition __transaction_state-38 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:36:03,736] INFO [UnifiedLog partition=__transaction_state-38, dir=/tmp/kafka-logs-102] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2024-08-26 15:36:03,736] INFO [ReplicaFetcher replicaId=102, leaderId=103, fetcherId=0] Truncating partition __transaction_state-26 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:36:03,736] INFO [UnifiedLog partition=__transaction_state-26, dir=/tmp/kafka-logs-102] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2024-08-26 15:36:03,736] INFO [ReplicaFetcher replicaId=102, leaderId=103, fetcherId=0] Truncating partition __consumer_offsets-28 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:36:03,736] INFO [UnifiedLog partition=__consumer_offsets-28, dir=/tmp/kafka-logs-102] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2024-08-26 15:36:03,736] INFO [ReplicaFetcher replicaId=102, leaderId=103, fetcherId=0] Truncating partition __transaction_state-32 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:36:03,736] INFO [UnifiedLog partition=__transaction_state-32, dir=/tmp/kafka-logs-102] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2024-08-26 15:36:03,736] INFO [ReplicaFetcher replicaId=102, leaderId=103, fetcherId=0] Truncating partition __consumer_offsets-7 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:36:03,736] INFO [UnifiedLog partition=__consumer_offsets-7, dir=/tmp/kafka-logs-102] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2024-08-26 15:36:03,736] INFO [ReplicaFetcher replicaId=102, leaderId=103, fetcherId=0] Truncating partition __consumer_offsets-40 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:36:03,736] INFO [UnifiedLog partition=__consumer_offsets-40, dir=/tmp/kafka-logs-102] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2024-08-26 15:36:03,736] INFO [ReplicaFetcher replicaId=102, leaderId=103, fetcherId=0] Truncating partition __transaction_state-20 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:36:03,736] INFO [UnifiedLog partition=__transaction_state-20, dir=/tmp/kafka-logs-102] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2024-08-26 15:36:03,736] INFO [ReplicaFetcher replicaId=102, leaderId=103, fetcherId=0] Truncating partition __consumer_offsets-1 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:36:03,736] INFO [UnifiedLog partition=__consumer_offsets-1, dir=/tmp/kafka-logs-102] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2024-08-26 15:36:03,736] INFO [ReplicaFetcher replicaId=102, leaderId=103, fetcherId=0] Truncating partition __consumer_offsets-34 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:36:03,736] INFO [UnifiedLog partition=__consumer_offsets-34, dir=/tmp/kafka-logs-102] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2024-08-26 15:36:03,736] INFO [ReplicaFetcher replicaId=102, leaderId=103, fetcherId=0] Truncating partition __consumer_offsets-16 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:36:03,736] INFO [UnifiedLog partition=__consumer_offsets-16, dir=/tmp/kafka-logs-102] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2024-08-26 15:36:03,736] INFO [ReplicaFetcher replicaId=102, leaderId=103, fetcherId=0] Truncating partition __consumer_offsets-43 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:36:03,736] INFO [UnifiedLog partition=__consumer_offsets-43, dir=/tmp/kafka-logs-102] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2024-08-26 15:36:03,736] INFO [ReplicaFetcher replicaId=102, leaderId=103, fetcherId=0] Truncating partition __transaction_state-14 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:36:03,737] INFO [UnifiedLog partition=__transaction_state-14, dir=/tmp/kafka-logs-102] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2024-08-26 15:36:03,737] INFO [ReplicaFetcher replicaId=102, leaderId=103, fetcherId=0] Truncating partition __transaction_state-47 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:36:03,737] INFO [UnifiedLog partition=__transaction_state-47, dir=/tmp/kafka-logs-102] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2024-08-26 15:36:03,737] INFO [ReplicaFetcher replicaId=102, leaderId=103, fetcherId=0] Truncating partition __consumer_offsets-10 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:36:03,737] INFO [UnifiedLog partition=__consumer_offsets-10, dir=/tmp/kafka-logs-102] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2024-08-26 15:36:03,737] INFO [ReplicaFetcher replicaId=102, leaderId=103, fetcherId=0] Truncating partition __transaction_state-35 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:36:03,737] INFO [UnifiedLog partition=__transaction_state-35, dir=/tmp/kafka-logs-102] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2024-08-26 15:36:03,737] INFO [ReplicaFetcher replicaId=102, leaderId=103, fetcherId=0] Truncating partition __consumer_offsets-22 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:36:03,737] INFO [UnifiedLog partition=__consumer_offsets-22, dir=/tmp/kafka-logs-102] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2024-08-26 15:36:03,737] INFO [ReplicaFetcher replicaId=102, leaderId=103, fetcherId=0] Truncating partition __consumer_offsets-49 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:36:03,737] INFO [UnifiedLog partition=__consumer_offsets-49, dir=/tmp/kafka-logs-102] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2024-08-26 15:36:03,737] INFO [ReplicaFetcher replicaId=102, leaderId=103, fetcherId=0] Truncating partition __transaction_state-8 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:36:03,737] INFO [UnifiedLog partition=__transaction_state-8, dir=/tmp/kafka-logs-102] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2024-08-26 15:36:03,737] INFO [ReplicaFetcher replicaId=102, leaderId=103, fetcherId=0] Truncating partition __transaction_state-41 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:36:03,737] INFO [UnifiedLog partition=__transaction_state-41, dir=/tmp/kafka-logs-102] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2024-08-26 15:36:03,737] INFO [ReplicaFetcher replicaId=102, leaderId=103, fetcherId=0] Truncating partition __transaction_state-29 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:36:03,737] INFO [UnifiedLog partition=__transaction_state-29, dir=/tmp/kafka-logs-102] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2024-08-26 15:36:03,737] INFO [ReplicaFetcher replicaId=102, leaderId=103, fetcherId=0] Truncating partition __consumer_offsets-25 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:36:03,737] INFO [UnifiedLog partition=__consumer_offsets-25, dir=/tmp/kafka-logs-102] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2024-08-26 15:36:03,737] INFO [ReplicaFetcher replicaId=102, leaderId=103, fetcherId=0] Truncating partition __consumer_offsets-37 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:36:03,737] INFO [UnifiedLog partition=__consumer_offsets-37, dir=/tmp/kafka-logs-102] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2024-08-26 15:36:03,737] INFO [ReplicaFetcher replicaId=102, leaderId=103, fetcherId=0] Truncating partition __consumer_offsets-4 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:36:03,737] INFO [UnifiedLog partition=__consumer_offsets-4, dir=/tmp/kafka-logs-102] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2024-08-26 15:36:03,737] INFO [ReplicaFetcher replicaId=102, leaderId=103, fetcherId=0] Truncating partition __transaction_state-23 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-08-26 15:36:03,737] INFO [UnifiedLog partition=__transaction_state-23, dir=/tmp/kafka-logs-102] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2024-08-26 15:36:03,738] INFO [GroupCoordinator 102]: Resigned as the group coordinator for partition 37 in epoch OptionalInt[4] (kafka.coordinator.group.GroupCoordinator)
[2024-08-26 15:36:03,738] INFO [GroupMetadataManager brokerId=102] Scheduling unloading of offsets and group metadata from __consumer_offsets-37 (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 15:36:03,738] INFO [GroupCoordinator 102]: Resigned as the group coordinator for partition 7 in epoch OptionalInt[4] (kafka.coordinator.group.GroupCoordinator)
[2024-08-26 15:36:03,738] INFO [GroupMetadataManager brokerId=102] Scheduling unloading of offsets and group metadata from __consumer_offsets-7 (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 15:36:03,738] INFO [GroupMetadataManager brokerId=102] Finished unloading __consumer_offsets-37 for coordinator epoch OptionalInt[4]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 15:36:03,738] INFO [GroupCoordinator 102]: Resigned as the group coordinator for partition 22 in epoch OptionalInt[4] (kafka.coordinator.group.GroupCoordinator)
[2024-08-26 15:36:03,738] INFO [GroupMetadataManager brokerId=102] Finished unloading __consumer_offsets-7 for coordinator epoch OptionalInt[4]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 15:36:03,738] INFO [GroupMetadataManager brokerId=102] Scheduling unloading of offsets and group metadata from __consumer_offsets-22 (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 15:36:03,738] INFO [GroupCoordinator 102]: Resigned as the group coordinator for partition 10 in epoch OptionalInt[4] (kafka.coordinator.group.GroupCoordinator)
[2024-08-26 15:36:03,738] INFO [GroupMetadataManager brokerId=102] Finished unloading __consumer_offsets-22 for coordinator epoch OptionalInt[4]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 15:36:03,738] INFO [GroupMetadataManager brokerId=102] Scheduling unloading of offsets and group metadata from __consumer_offsets-10 (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 15:36:03,738] INFO [TransactionCoordinator id=102] Resigned as the txn coordinator for partition 11 at epoch Some(4) (kafka.coordinator.transaction.TransactionCoordinator)
[2024-08-26 15:36:03,738] INFO [GroupMetadataManager brokerId=102] Finished unloading __consumer_offsets-10 for coordinator epoch OptionalInt[4]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 15:36:03,738] INFO [Transaction State Manager 102]: No cached transaction metadata found for __transaction_state-11 during become-follower transition (kafka.coordinator.transaction.TransactionStateManager)
[2024-08-26 15:36:03,738] INFO [TransactionCoordinator id=102] Resigned as the txn coordinator for partition 26 at epoch Some(4) (kafka.coordinator.transaction.TransactionCoordinator)
[2024-08-26 15:36:03,738] INFO [Transaction State Manager 102]: No cached transaction metadata found for __transaction_state-26 during become-follower transition (kafka.coordinator.transaction.TransactionStateManager)
[2024-08-26 15:36:03,739] INFO [TransactionCoordinator id=102] Resigned as the txn coordinator for partition 41 at epoch Some(4) (kafka.coordinator.transaction.TransactionCoordinator)
[2024-08-26 15:36:03,739] INFO [Transaction State Manager 102]: No cached transaction metadata found for __transaction_state-41 during become-follower transition (kafka.coordinator.transaction.TransactionStateManager)
[2024-08-26 15:36:03,739] INFO [GroupCoordinator 102]: Resigned as the group coordinator for partition 19 in epoch OptionalInt[4] (kafka.coordinator.group.GroupCoordinator)
[2024-08-26 15:36:03,739] INFO [GroupMetadataManager brokerId=102] Scheduling unloading of offsets and group metadata from __consumer_offsets-19 (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 15:36:03,739] INFO [TransactionCoordinator id=102] Resigned as the txn coordinator for partition 8 at epoch Some(4) (kafka.coordinator.transaction.TransactionCoordinator)
[2024-08-26 15:36:03,739] INFO [Transaction State Manager 102]: No cached transaction metadata found for __transaction_state-8 during become-follower transition (kafka.coordinator.transaction.TransactionStateManager)
[2024-08-26 15:36:03,739] INFO [GroupMetadataManager brokerId=102] Finished unloading __consumer_offsets-19 for coordinator epoch OptionalInt[4]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 15:36:03,739] INFO [GroupCoordinator 102]: Resigned as the group coordinator for partition 34 in epoch OptionalInt[4] (kafka.coordinator.group.GroupCoordinator)
[2024-08-26 15:36:03,739] INFO [GroupMetadataManager brokerId=102] Scheduling unloading of offsets and group metadata from __consumer_offsets-34 (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 15:36:03,739] INFO [TransactionCoordinator id=102] Resigned as the txn coordinator for partition 23 at epoch Some(4) (kafka.coordinator.transaction.TransactionCoordinator)
[2024-08-26 15:36:03,739] INFO [GroupMetadataManager brokerId=102] Finished unloading __consumer_offsets-34 for coordinator epoch OptionalInt[4]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 15:36:03,739] INFO [Transaction State Manager 102]: No cached transaction metadata found for __transaction_state-23 during become-follower transition (kafka.coordinator.transaction.TransactionStateManager)
[2024-08-26 15:36:03,739] INFO [TransactionCoordinator id=102] Resigned as the txn coordinator for partition 38 at epoch Some(4) (kafka.coordinator.transaction.TransactionCoordinator)
[2024-08-26 15:36:03,739] INFO [Transaction State Manager 102]: No cached transaction metadata found for __transaction_state-38 during become-follower transition (kafka.coordinator.transaction.TransactionStateManager)
[2024-08-26 15:36:03,739] INFO [GroupCoordinator 102]: Resigned as the group coordinator for partition 4 in epoch OptionalInt[4] (kafka.coordinator.group.GroupCoordinator)
[2024-08-26 15:36:03,739] INFO [GroupMetadataManager brokerId=102] Scheduling unloading of offsets and group metadata from __consumer_offsets-4 (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 15:36:03,739] INFO [GroupCoordinator 102]: Resigned as the group coordinator for partition 49 in epoch OptionalInt[4] (kafka.coordinator.group.GroupCoordinator)
[2024-08-26 15:36:03,739] INFO [GroupMetadataManager brokerId=102] Scheduling unloading of offsets and group metadata from __consumer_offsets-49 (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 15:36:03,739] INFO [GroupMetadataManager brokerId=102] Finished unloading __consumer_offsets-4 for coordinator epoch OptionalInt[4]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 15:36:03,739] INFO [TransactionCoordinator id=102] Resigned as the txn coordinator for partition 5 at epoch Some(4) (kafka.coordinator.transaction.TransactionCoordinator)
[2024-08-26 15:36:03,739] INFO [GroupMetadataManager brokerId=102] Finished unloading __consumer_offsets-49 for coordinator epoch OptionalInt[4]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 15:36:03,739] INFO [Transaction State Manager 102]: No cached transaction metadata found for __transaction_state-5 during become-follower transition (kafka.coordinator.transaction.TransactionStateManager)
[2024-08-26 15:36:03,739] INFO [TransactionCoordinator id=102] Resigned as the txn coordinator for partition 20 at epoch Some(4) (kafka.coordinator.transaction.TransactionCoordinator)
[2024-08-26 15:36:03,740] INFO [Transaction State Manager 102]: No cached transaction metadata found for __transaction_state-20 during become-follower transition (kafka.coordinator.transaction.TransactionStateManager)
[2024-08-26 15:36:03,740] INFO [TransactionCoordinator id=102] Resigned as the txn coordinator for partition 35 at epoch Some(4) (kafka.coordinator.transaction.TransactionCoordinator)
[2024-08-26 15:36:03,740] INFO [Transaction State Manager 102]: No cached transaction metadata found for __transaction_state-35 during become-follower transition (kafka.coordinator.transaction.TransactionStateManager)
[2024-08-26 15:36:03,740] INFO [TransactionCoordinator id=102] Resigned as the txn coordinator for partition 32 at epoch Some(4) (kafka.coordinator.transaction.TransactionCoordinator)
[2024-08-26 15:36:03,740] INFO [Transaction State Manager 102]: No cached transaction metadata found for __transaction_state-32 during become-follower transition (kafka.coordinator.transaction.TransactionStateManager)
[2024-08-26 15:36:03,740] INFO [TransactionCoordinator id=102] Resigned as the txn coordinator for partition 47 at epoch Some(4) (kafka.coordinator.transaction.TransactionCoordinator)
[2024-08-26 15:36:03,740] INFO [Transaction State Manager 102]: No cached transaction metadata found for __transaction_state-47 during become-follower transition (kafka.coordinator.transaction.TransactionStateManager)
[2024-08-26 15:36:03,740] INFO [GroupCoordinator 102]: Resigned as the group coordinator for partition 31 in epoch OptionalInt[4] (kafka.coordinator.group.GroupCoordinator)
[2024-08-26 15:36:03,743] INFO [GroupMetadataManager brokerId=102] Scheduling unloading of offsets and group metadata from __consumer_offsets-31 (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 15:36:03,744] INFO [GroupCoordinator 102]: Resigned as the group coordinator for partition 46 in epoch OptionalInt[4] (kafka.coordinator.group.GroupCoordinator)
[2024-08-26 15:36:03,744] INFO [GroupMetadataManager brokerId=102] Finished unloading __consumer_offsets-31 for coordinator epoch OptionalInt[4]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 15:36:03,744] INFO [GroupMetadataManager brokerId=102] Scheduling unloading of offsets and group metadata from __consumer_offsets-46 (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 15:36:03,744] INFO [GroupCoordinator 102]: Resigned as the group coordinator for partition 1 in epoch OptionalInt[4] (kafka.coordinator.group.GroupCoordinator)
[2024-08-26 15:36:03,744] INFO [GroupMetadataManager brokerId=102] Scheduling unloading of offsets and group metadata from __consumer_offsets-1 (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 15:36:03,744] INFO [GroupMetadataManager brokerId=102] Finished unloading __consumer_offsets-46 for coordinator epoch OptionalInt[4]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 15:36:03,744] INFO [GroupCoordinator 102]: Resigned as the group coordinator for partition 16 in epoch OptionalInt[4] (kafka.coordinator.group.GroupCoordinator)
[2024-08-26 15:36:03,744] INFO [GroupMetadataManager brokerId=102] Finished unloading __consumer_offsets-1 for coordinator epoch OptionalInt[4]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 15:36:03,744] INFO [GroupMetadataManager brokerId=102] Scheduling unloading of offsets and group metadata from __consumer_offsets-16 (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 15:36:03,744] INFO [GroupCoordinator 102]: Resigned as the group coordinator for partition 25 in epoch OptionalInt[4] (kafka.coordinator.group.GroupCoordinator)
[2024-08-26 15:36:03,744] INFO [GroupMetadataManager brokerId=102] Finished unloading __consumer_offsets-16 for coordinator epoch OptionalInt[4]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 15:36:03,744] INFO [GroupMetadataManager brokerId=102] Scheduling unloading of offsets and group metadata from __consumer_offsets-25 (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 15:36:03,744] INFO [GroupMetadataManager brokerId=102] Finished unloading __consumer_offsets-25 for coordinator epoch OptionalInt[4]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 15:36:03,745] INFO [TransactionCoordinator id=102] Resigned as the txn coordinator for partition 2 at epoch Some(4) (kafka.coordinator.transaction.TransactionCoordinator)
[2024-08-26 15:36:03,745] INFO [Transaction State Manager 102]: No cached transaction metadata found for __transaction_state-2 during become-follower transition (kafka.coordinator.transaction.TransactionStateManager)
[2024-08-26 15:36:03,745] INFO [GroupCoordinator 102]: Resigned as the group coordinator for partition 40 in epoch OptionalInt[4] (kafka.coordinator.group.GroupCoordinator)
[2024-08-26 15:36:03,745] INFO [GroupMetadataManager brokerId=102] Scheduling unloading of offsets and group metadata from __consumer_offsets-40 (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 15:36:03,745] INFO [TransactionCoordinator id=102] Resigned as the txn coordinator for partition 17 at epoch Some(4) (kafka.coordinator.transaction.TransactionCoordinator)
[2024-08-26 15:36:03,745] INFO [Transaction State Manager 102]: No cached transaction metadata found for __transaction_state-17 during become-follower transition (kafka.coordinator.transaction.TransactionStateManager)
[2024-08-26 15:36:03,745] INFO [GroupMetadataManager brokerId=102] Finished unloading __consumer_offsets-40 for coordinator epoch OptionalInt[4]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 15:36:03,745] INFO [GroupCoordinator 102]: Resigned as the group coordinator for partition 43 in epoch OptionalInt[4] (kafka.coordinator.group.GroupCoordinator)
[2024-08-26 15:36:03,745] INFO [GroupMetadataManager brokerId=102] Scheduling unloading of offsets and group metadata from __consumer_offsets-43 (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 15:36:03,746] INFO [GroupCoordinator 102]: Resigned as the group coordinator for partition 13 in epoch OptionalInt[4] (kafka.coordinator.group.GroupCoordinator)
[2024-08-26 15:36:03,746] INFO [GroupMetadataManager brokerId=102] Scheduling unloading of offsets and group metadata from __consumer_offsets-13 (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 15:36:03,746] INFO [GroupMetadataManager brokerId=102] Finished unloading __consumer_offsets-43 for coordinator epoch OptionalInt[4]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 15:36:03,746] INFO [TransactionCoordinator id=102] Resigned as the txn coordinator for partition 14 at epoch Some(4) (kafka.coordinator.transaction.TransactionCoordinator)
[2024-08-26 15:36:03,746] INFO [GroupMetadataManager brokerId=102] Finished unloading __consumer_offsets-13 for coordinator epoch OptionalInt[4]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 15:36:03,746] INFO [Transaction State Manager 102]: No cached transaction metadata found for __transaction_state-14 during become-follower transition (kafka.coordinator.transaction.TransactionStateManager)
[2024-08-26 15:36:03,746] INFO [GroupCoordinator 102]: Resigned as the group coordinator for partition 28 in epoch OptionalInt[4] (kafka.coordinator.group.GroupCoordinator)
[2024-08-26 15:36:03,746] INFO [GroupMetadataManager brokerId=102] Scheduling unloading of offsets and group metadata from __consumer_offsets-28 (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 15:36:03,746] INFO [TransactionCoordinator id=102] Resigned as the txn coordinator for partition 29 at epoch Some(4) (kafka.coordinator.transaction.TransactionCoordinator)
[2024-08-26 15:36:03,746] INFO [GroupMetadataManager brokerId=102] Finished unloading __consumer_offsets-28 for coordinator epoch OptionalInt[4]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 15:36:03,747] INFO [Transaction State Manager 102]: No cached transaction metadata found for __transaction_state-29 during become-follower transition (kafka.coordinator.transaction.TransactionStateManager)
[2024-08-26 15:36:03,747] INFO [TransactionCoordinator id=102] Resigned as the txn coordinator for partition 44 at epoch Some(4) (kafka.coordinator.transaction.TransactionCoordinator)
[2024-08-26 15:36:03,747] INFO [Transaction State Manager 102]: No cached transaction metadata found for __transaction_state-44 during become-follower transition (kafka.coordinator.transaction.TransactionStateManager)
[2024-08-26 15:36:03,811] INFO [Transaction State Manager 102]: Finished loading 1 transaction metadata from __transaction_state-3 in 108 milliseconds, of which 1 milliseconds was spent in the scheduler. (kafka.coordinator.transaction.TransactionStateManager)
[2024-08-26 15:36:03,814] INFO [Transaction State Manager 102]: Completed loading transaction metadata from __transaction_state-3 for coordinator epoch 4 (kafka.coordinator.transaction.TransactionStateManager)
[2024-08-26 15:36:03,814] INFO [Transaction State Manager 102]: Loading transaction metadata from __transaction_state-18 at epoch 4 (kafka.coordinator.transaction.TransactionStateManager)
[2024-08-26 15:36:03,816] INFO [Transaction State Manager 102]: Finished loading 0 transaction metadata from __transaction_state-18 in 111 milliseconds, of which 109 milliseconds was spent in the scheduler. (kafka.coordinator.transaction.TransactionStateManager)
[2024-08-26 15:36:03,816] INFO [Transaction State Manager 102]: Completed loading transaction metadata from __transaction_state-18 for coordinator epoch 4 (kafka.coordinator.transaction.TransactionStateManager)
[2024-08-26 15:36:03,816] INFO [Transaction State Manager 102]: Loading transaction metadata from __transaction_state-33 at epoch 4 (kafka.coordinator.transaction.TransactionStateManager)
[2024-08-26 15:36:03,817] INFO [Transaction State Manager 102]: Finished loading 0 transaction metadata from __transaction_state-33 in 112 milliseconds, of which 111 milliseconds was spent in the scheduler. (kafka.coordinator.transaction.TransactionStateManager)
[2024-08-26 15:36:03,817] INFO [Transaction State Manager 102]: Completed loading transaction metadata from __transaction_state-33 for coordinator epoch 4 (kafka.coordinator.transaction.TransactionStateManager)
[2024-08-26 15:36:03,817] INFO [Transaction State Manager 102]: Loading transaction metadata from __transaction_state-0 at epoch 4 (kafka.coordinator.transaction.TransactionStateManager)
[2024-08-26 15:36:03,818] INFO [Transaction State Manager 102]: Finished loading 0 transaction metadata from __transaction_state-0 in 113 milliseconds, of which 112 milliseconds was spent in the scheduler. (kafka.coordinator.transaction.TransactionStateManager)
[2024-08-26 15:36:03,818] INFO [Transaction State Manager 102]: Completed loading transaction metadata from __transaction_state-0 for coordinator epoch 4 (kafka.coordinator.transaction.TransactionStateManager)
[2024-08-26 15:36:03,818] INFO [Transaction State Manager 102]: Loading transaction metadata from __transaction_state-15 at epoch 4 (kafka.coordinator.transaction.TransactionStateManager)
[2024-08-26 15:36:03,819] INFO [Transaction State Manager 102]: Finished loading 0 transaction metadata from __transaction_state-15 in 114 milliseconds, of which 113 milliseconds was spent in the scheduler. (kafka.coordinator.transaction.TransactionStateManager)
[2024-08-26 15:36:03,819] INFO [Transaction State Manager 102]: Completed loading transaction metadata from __transaction_state-15 for coordinator epoch 4 (kafka.coordinator.transaction.TransactionStateManager)
[2024-08-26 15:36:03,819] INFO [Transaction State Manager 102]: Loading transaction metadata from __transaction_state-30 at epoch 4 (kafka.coordinator.transaction.TransactionStateManager)
[2024-08-26 15:36:03,820] INFO [Transaction State Manager 102]: Finished loading 0 transaction metadata from __transaction_state-30 in 115 milliseconds, of which 114 milliseconds was spent in the scheduler. (kafka.coordinator.transaction.TransactionStateManager)
[2024-08-26 15:36:03,820] INFO [Transaction State Manager 102]: Completed loading transaction metadata from __transaction_state-30 for coordinator epoch 4 (kafka.coordinator.transaction.TransactionStateManager)
[2024-08-26 15:36:03,835] INFO [Transaction State Manager 102]: Loading transaction metadata from __transaction_state-45 at epoch 4 (kafka.coordinator.transaction.TransactionStateManager)
[2024-08-26 15:36:03,836] INFO [Transaction State Manager 102]: Finished loading 0 transaction metadata from __transaction_state-45 in 130 milliseconds, of which 129 milliseconds was spent in the scheduler. (kafka.coordinator.transaction.TransactionStateManager)
[2024-08-26 15:36:03,836] INFO [Transaction State Manager 102]: Completed loading transaction metadata from __transaction_state-45 for coordinator epoch 4 (kafka.coordinator.transaction.TransactionStateManager)
[2024-08-26 15:36:03,836] INFO [Transaction State Manager 102]: Loading transaction metadata from __transaction_state-12 at epoch 4 (kafka.coordinator.transaction.TransactionStateManager)
[2024-08-26 15:36:03,837] INFO [Transaction State Manager 102]: Finished loading 0 transaction metadata from __transaction_state-12 in 130 milliseconds, of which 129 milliseconds was spent in the scheduler. (kafka.coordinator.transaction.TransactionStateManager)
[2024-08-26 15:36:03,837] INFO [Transaction State Manager 102]: Completed loading transaction metadata from __transaction_state-12 for coordinator epoch 4 (kafka.coordinator.transaction.TransactionStateManager)
[2024-08-26 15:36:03,837] INFO [Transaction State Manager 102]: Loading transaction metadata from __transaction_state-27 at epoch 4 (kafka.coordinator.transaction.TransactionStateManager)
[2024-08-26 15:36:03,838] INFO [Transaction State Manager 102]: Finished loading 0 transaction metadata from __transaction_state-27 in 131 milliseconds, of which 130 milliseconds was spent in the scheduler. (kafka.coordinator.transaction.TransactionStateManager)
[2024-08-26 15:36:03,838] INFO [Transaction State Manager 102]: Completed loading transaction metadata from __transaction_state-27 for coordinator epoch 4 (kafka.coordinator.transaction.TransactionStateManager)
[2024-08-26 15:36:03,838] INFO [Transaction State Manager 102]: Loading transaction metadata from __transaction_state-42 at epoch 4 (kafka.coordinator.transaction.TransactionStateManager)
[2024-08-26 15:36:03,839] INFO [Transaction State Manager 102]: Finished loading 0 transaction metadata from __transaction_state-42 in 132 milliseconds, of which 131 milliseconds was spent in the scheduler. (kafka.coordinator.transaction.TransactionStateManager)
[2024-08-26 15:36:03,839] INFO [Transaction State Manager 102]: Completed loading transaction metadata from __transaction_state-42 for coordinator epoch 4 (kafka.coordinator.transaction.TransactionStateManager)
[2024-08-26 15:36:03,840] INFO [Transaction State Manager 102]: Loading transaction metadata from __transaction_state-24 at epoch 4 (kafka.coordinator.transaction.TransactionStateManager)
[2024-08-26 15:36:03,841] INFO [Transaction State Manager 102]: Finished loading 0 transaction metadata from __transaction_state-24 in 133 milliseconds, of which 131 milliseconds was spent in the scheduler. (kafka.coordinator.transaction.TransactionStateManager)
[2024-08-26 15:36:03,841] INFO [Transaction State Manager 102]: Completed loading transaction metadata from __transaction_state-24 for coordinator epoch 4 (kafka.coordinator.transaction.TransactionStateManager)
[2024-08-26 15:36:03,841] INFO [Transaction State Manager 102]: Loading transaction metadata from __transaction_state-39 at epoch 4 (kafka.coordinator.transaction.TransactionStateManager)
[2024-08-26 15:36:03,842] INFO [Transaction State Manager 102]: Finished loading 0 transaction metadata from __transaction_state-39 in 134 milliseconds, of which 133 milliseconds was spent in the scheduler. (kafka.coordinator.transaction.TransactionStateManager)
[2024-08-26 15:36:03,842] INFO [Transaction State Manager 102]: Completed loading transaction metadata from __transaction_state-39 for coordinator epoch 4 (kafka.coordinator.transaction.TransactionStateManager)
[2024-08-26 15:36:03,842] INFO [Transaction State Manager 102]: Loading transaction metadata from __transaction_state-9 at epoch 4 (kafka.coordinator.transaction.TransactionStateManager)
[2024-08-26 15:36:03,844] INFO [Transaction State Manager 102]: Finished loading 0 transaction metadata from __transaction_state-9 in 136 milliseconds, of which 134 milliseconds was spent in the scheduler. (kafka.coordinator.transaction.TransactionStateManager)
[2024-08-26 15:36:03,844] INFO [Transaction State Manager 102]: Completed loading transaction metadata from __transaction_state-9 for coordinator epoch 4 (kafka.coordinator.transaction.TransactionStateManager)
[2024-08-26 15:36:03,844] INFO [Transaction State Manager 102]: Loading transaction metadata from __transaction_state-6 at epoch 4 (kafka.coordinator.transaction.TransactionStateManager)
[2024-08-26 15:36:03,845] INFO [Transaction State Manager 102]: Finished loading 0 transaction metadata from __transaction_state-6 in 137 milliseconds, of which 136 milliseconds was spent in the scheduler. (kafka.coordinator.transaction.TransactionStateManager)
[2024-08-26 15:36:03,846] INFO [Transaction State Manager 102]: Completed loading transaction metadata from __transaction_state-6 for coordinator epoch 4 (kafka.coordinator.transaction.TransactionStateManager)
[2024-08-26 15:36:03,846] INFO [Transaction State Manager 102]: Loading transaction metadata from __transaction_state-21 at epoch 4 (kafka.coordinator.transaction.TransactionStateManager)
[2024-08-26 15:36:03,847] INFO [Transaction State Manager 102]: Finished loading 0 transaction metadata from __transaction_state-21 in 139 milliseconds, of which 138 milliseconds was spent in the scheduler. (kafka.coordinator.transaction.TransactionStateManager)
[2024-08-26 15:36:03,847] INFO [Transaction State Manager 102]: Completed loading transaction metadata from __transaction_state-21 for coordinator epoch 4 (kafka.coordinator.transaction.TransactionStateManager)
[2024-08-26 15:36:03,848] INFO [Transaction State Manager 102]: Loading transaction metadata from __transaction_state-36 at epoch 4 (kafka.coordinator.transaction.TransactionStateManager)
[2024-08-26 15:36:03,849] INFO [Transaction State Manager 102]: Finished loading 0 transaction metadata from __transaction_state-36 in 141 milliseconds, of which 140 milliseconds was spent in the scheduler. (kafka.coordinator.transaction.TransactionStateManager)
[2024-08-26 15:36:03,850] INFO [Transaction State Manager 102]: Completed loading transaction metadata from __transaction_state-36 for coordinator epoch 4 (kafka.coordinator.transaction.TransactionStateManager)
[2024-08-26 15:36:03,850] INFO [Transaction State Manager 102]: Loading transaction metadata from __transaction_state-48 at epoch 4 (kafka.coordinator.transaction.TransactionStateManager)
[2024-08-26 15:36:03,851] INFO [Transaction State Manager 102]: Finished loading 0 transaction metadata from __transaction_state-48 in 143 milliseconds, of which 142 milliseconds was spent in the scheduler. (kafka.coordinator.transaction.TransactionStateManager)
[2024-08-26 15:36:03,851] INFO [Transaction State Manager 102]: Completed loading transaction metadata from __transaction_state-48 for coordinator epoch 4 (kafka.coordinator.transaction.TransactionStateManager)
[2024-08-26 15:39:42,116] INFO [AddPartitionsToTxnManager broker=102]Node 102 disconnected. (org.apache.kafka.clients.NetworkClient)
[2024-08-26 15:39:42,116] INFO [TransactionCoordinator id=102] Node 102 disconnected. (org.apache.kafka.clients.NetworkClient)
[2024-08-26 15:39:53,185] INFO [TransactionCoordinator id=102] Node 101 disconnected. (org.apache.kafka.clients.NetworkClient)
[2024-08-26 15:39:55,737] INFO [AddPartitionsToTxnManager broker=102]Node 103 disconnected. (org.apache.kafka.clients.NetworkClient)
[2024-08-26 15:40:00,131] INFO [TransactionCoordinator id=102] Node 103 disconnected. (org.apache.kafka.clients.NetworkClient)
[2024-08-26 15:41:15,648] INFO [AddPartitionsToTxnManager broker=102]Node 101 disconnected. (org.apache.kafka.clients.NetworkClient)
[2024-08-26 15:58:32,554] INFO [GroupCoordinator 102]: Removed 0 offsets associated with deleted partitions: even-numbers-0. (kafka.coordinator.group.GroupCoordinator)
[2024-08-26 15:58:32,580] INFO [ReplicaFetcherManager on broker 102] Removed fetcher for partitions Set(even-numbers-0) (kafka.server.ReplicaFetcherManager)
[2024-08-26 15:58:32,580] INFO [ReplicaAlterLogDirsManager on broker 102] Removed fetcher for partitions Set(even-numbers-0) (kafka.server.ReplicaAlterLogDirsManager)
[2024-08-26 15:58:32,589] INFO [ReplicaFetcherManager on broker 102] Removed fetcher for partitions Set(even-numbers-0) (kafka.server.ReplicaFetcherManager)
[2024-08-26 15:58:32,589] INFO [ReplicaAlterLogDirsManager on broker 102] Removed fetcher for partitions Set(even-numbers-0) (kafka.server.ReplicaAlterLogDirsManager)
[2024-08-26 15:58:32,622] INFO Log for partition even-numbers-0 is renamed to /tmp/kafka-logs-102/even-numbers-0.5ed1f12a3a5a4d0fa8ebd65e928a4892-delete and is scheduled for deletion (kafka.log.LogManager)
[2024-08-26 15:58:32,719] INFO [GroupCoordinator 102]: Removed 0 offsets associated with deleted partitions: doubled-numbers-1, doubled-numbers-2, doubled-numbers-0. (kafka.coordinator.group.GroupCoordinator)
[2024-08-26 15:58:32,743] INFO [ReplicaFetcherManager on broker 102] Removed fetcher for partitions Set(doubled-numbers-2) (kafka.server.ReplicaFetcherManager)
[2024-08-26 15:58:32,743] INFO [ReplicaAlterLogDirsManager on broker 102] Removed fetcher for partitions Set(doubled-numbers-2) (kafka.server.ReplicaAlterLogDirsManager)
[2024-08-26 15:58:32,755] INFO [ReplicaFetcherManager on broker 102] Removed fetcher for partitions Set(doubled-numbers-2) (kafka.server.ReplicaFetcherManager)
[2024-08-26 15:58:32,755] INFO [ReplicaAlterLogDirsManager on broker 102] Removed fetcher for partitions Set(doubled-numbers-2) (kafka.server.ReplicaAlterLogDirsManager)
[2024-08-26 15:58:32,782] INFO Log for partition doubled-numbers-2 is renamed to /tmp/kafka-logs-102/doubled-numbers-2.746c5be866644fe19e719ed137460d03-delete and is scheduled for deletion (kafka.log.LogManager)
[2024-08-26 15:58:32,920] INFO [GroupCoordinator 102]: Removed 0 offsets associated with deleted partitions: merged-numbers-0, merged-numbers-1, merged-numbers-2. (kafka.coordinator.group.GroupCoordinator)
[2024-08-26 15:58:32,922] INFO [ReplicaFetcherManager on broker 102] Removed fetcher for partitions Set(merged-numbers-1) (kafka.server.ReplicaFetcherManager)
[2024-08-26 15:58:32,923] INFO [ReplicaAlterLogDirsManager on broker 102] Removed fetcher for partitions Set(merged-numbers-1) (kafka.server.ReplicaAlterLogDirsManager)
[2024-08-26 15:58:32,926] INFO [ReplicaFetcherManager on broker 102] Removed fetcher for partitions Set(merged-numbers-1) (kafka.server.ReplicaFetcherManager)
[2024-08-26 15:58:32,926] INFO [ReplicaAlterLogDirsManager on broker 102] Removed fetcher for partitions Set(merged-numbers-1) (kafka.server.ReplicaAlterLogDirsManager)
[2024-08-26 15:58:32,956] INFO Log for partition merged-numbers-1 is renamed to /tmp/kafka-logs-102/merged-numbers-1.f5f13aab3b3b462f9950b01d294e7ee3-delete and is scheduled for deletion (kafka.log.LogManager)
[2024-08-26 15:58:33,115] INFO [GroupCoordinator 102]: Removed 0 offsets associated with deleted partitions: odd-numbers-0. (kafka.coordinator.group.GroupCoordinator)
[2024-08-26 15:58:33,116] INFO [ReplicaFetcherManager on broker 102] Removed fetcher for partitions Set(odd-numbers-0) (kafka.server.ReplicaFetcherManager)
[2024-08-26 15:58:33,116] INFO [ReplicaAlterLogDirsManager on broker 102] Removed fetcher for partitions Set(odd-numbers-0) (kafka.server.ReplicaAlterLogDirsManager)
[2024-08-26 15:58:33,117] INFO [ReplicaFetcherManager on broker 102] Removed fetcher for partitions Set(odd-numbers-0) (kafka.server.ReplicaFetcherManager)
[2024-08-26 15:58:33,117] INFO [ReplicaAlterLogDirsManager on broker 102] Removed fetcher for partitions Set(odd-numbers-0) (kafka.server.ReplicaAlterLogDirsManager)
[2024-08-26 15:58:33,136] INFO Log for partition odd-numbers-0 is renamed to /tmp/kafka-logs-102/odd-numbers-0.31967729a88e41f9a4bfcd48a45b5630-delete and is scheduled for deletion (kafka.log.LogManager)
[2024-08-26 15:58:33,360] INFO [GroupCoordinator 102]: Removed 0 offsets associated with deleted partitions: numbers-2, numbers-0, numbers-1. (kafka.coordinator.group.GroupCoordinator)
[2024-08-26 15:58:33,396] INFO [ReplicaFetcherManager on broker 102] Removed fetcher for partitions Set(numbers-2) (kafka.server.ReplicaFetcherManager)
[2024-08-26 15:58:33,396] INFO [ReplicaAlterLogDirsManager on broker 102] Removed fetcher for partitions Set(numbers-2) (kafka.server.ReplicaAlterLogDirsManager)
[2024-08-26 15:58:33,399] INFO [ReplicaFetcherManager on broker 102] Removed fetcher for partitions Set(numbers-2) (kafka.server.ReplicaFetcherManager)
[2024-08-26 15:58:33,399] INFO [ReplicaAlterLogDirsManager on broker 102] Removed fetcher for partitions Set(numbers-2) (kafka.server.ReplicaAlterLogDirsManager)
[2024-08-26 15:58:33,425] INFO Log for partition numbers-2 is renamed to /tmp/kafka-logs-102/numbers-2.8a790f2661b84008ae56d7c414271d87-delete and is scheduled for deletion (kafka.log.LogManager)
[2024-08-26 15:58:53,564] INFO [ReplicaFetcherManager on broker 102] Removed fetcher for partitions Set(numbers-1) (kafka.server.ReplicaFetcherManager)
[2024-08-26 15:58:53,569] INFO [LogLoader partition=numbers-1, dir=/tmp/kafka-logs-102] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-08-26 15:58:53,570] INFO Created log for partition numbers-1 in /tmp/kafka-logs-102/numbers-1 with properties {cleanup.policy=delete} (kafka.log.LogManager)
[2024-08-26 15:58:53,571] INFO [Partition numbers-1 broker=102] No checkpointed highwatermark is found for partition numbers-1 (kafka.cluster.Partition)
[2024-08-26 15:58:53,571] INFO [Partition numbers-1 broker=102] Log loaded for partition numbers-1 with initial high watermark 0 (kafka.cluster.Partition)
[2024-08-26 15:59:32,630] INFO [LocalLog partition=even-numbers-0, dir=/tmp/kafka-logs-102] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=5395437, lastModifiedTime=1724665802936, largestRecordTimestamp=1724665802936) (kafka.log.LocalLog)
[2024-08-26 15:59:32,633] INFO [LocalLog partition=even-numbers-0, dir=/tmp/kafka-logs-102] Deleting segment files LogSegment(baseOffset=0, size=5395437, lastModifiedTime=1724665802936, largestRecordTimestamp=1724665802936) (kafka.log.LocalLog$)
[2024-08-26 15:59:32,730] INFO Deleted log /tmp/kafka-logs-102/even-numbers-0.5ed1f12a3a5a4d0fa8ebd65e928a4892-delete/00000000000000000000.log.deleted. (org.apache.kafka.storage.internals.log.LogSegment)
[2024-08-26 15:59:32,734] INFO Deleted offset index /tmp/kafka-logs-102/even-numbers-0.5ed1f12a3a5a4d0fa8ebd65e928a4892-delete/00000000000000000000.index.deleted. (org.apache.kafka.storage.internals.log.LogSegment)
[2024-08-26 15:59:32,735] INFO Deleted time index /tmp/kafka-logs-102/even-numbers-0.5ed1f12a3a5a4d0fa8ebd65e928a4892-delete/00000000000000000000.timeindex.deleted. (org.apache.kafka.storage.internals.log.LogSegment)
[2024-08-26 15:59:32,739] INFO Deleted log for partition even-numbers-0 in /tmp/kafka-logs-102/even-numbers-0.5ed1f12a3a5a4d0fa8ebd65e928a4892-delete. (kafka.log.LogManager)
[2024-08-26 15:59:32,785] INFO [LocalLog partition=doubled-numbers-2, dir=/tmp/kafka-logs-102] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=2170519, lastModifiedTime=1724666288658, largestRecordTimestamp=1724666288658) (kafka.log.LocalLog)
[2024-08-26 15:59:32,786] INFO [LocalLog partition=doubled-numbers-2, dir=/tmp/kafka-logs-102] Deleting segment files LogSegment(baseOffset=0, size=2170519, lastModifiedTime=1724666288658, largestRecordTimestamp=1724666288658) (kafka.log.LocalLog$)
[2024-08-26 15:59:32,800] INFO Deleted log /tmp/kafka-logs-102/doubled-numbers-2.746c5be866644fe19e719ed137460d03-delete/00000000000000000000.log.deleted. (org.apache.kafka.storage.internals.log.LogSegment)
[2024-08-26 15:59:32,800] INFO Deleted offset index /tmp/kafka-logs-102/doubled-numbers-2.746c5be866644fe19e719ed137460d03-delete/00000000000000000000.index.deleted. (org.apache.kafka.storage.internals.log.LogSegment)
[2024-08-26 15:59:32,800] INFO Deleted time index /tmp/kafka-logs-102/doubled-numbers-2.746c5be866644fe19e719ed137460d03-delete/00000000000000000000.timeindex.deleted. (org.apache.kafka.storage.internals.log.LogSegment)
[2024-08-26 15:59:32,801] INFO Deleted log for partition doubled-numbers-2 in /tmp/kafka-logs-102/doubled-numbers-2.746c5be866644fe19e719ed137460d03-delete. (kafka.log.LogManager)
[2024-08-26 15:59:32,961] INFO [LocalLog partition=merged-numbers-1, dir=/tmp/kafka-logs-102] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=698835, lastModifiedTime=1724666475538, largestRecordTimestamp=1724666475538) (kafka.log.LocalLog)
[2024-08-26 15:59:32,961] INFO [LocalLog partition=merged-numbers-1, dir=/tmp/kafka-logs-102] Deleting segment files LogSegment(baseOffset=0, size=698835, lastModifiedTime=1724666475538, largestRecordTimestamp=1724666475538) (kafka.log.LocalLog$)
[2024-08-26 15:59:32,964] INFO Deleted log /tmp/kafka-logs-102/merged-numbers-1.f5f13aab3b3b462f9950b01d294e7ee3-delete/00000000000000000000.log.deleted. (org.apache.kafka.storage.internals.log.LogSegment)
[2024-08-26 15:59:32,965] INFO Deleted offset index /tmp/kafka-logs-102/merged-numbers-1.f5f13aab3b3b462f9950b01d294e7ee3-delete/00000000000000000000.index.deleted. (org.apache.kafka.storage.internals.log.LogSegment)
[2024-08-26 15:59:32,965] INFO Deleted time index /tmp/kafka-logs-102/merged-numbers-1.f5f13aab3b3b462f9950b01d294e7ee3-delete/00000000000000000000.timeindex.deleted. (org.apache.kafka.storage.internals.log.LogSegment)
[2024-08-26 15:59:32,965] INFO Deleted log for partition merged-numbers-1 in /tmp/kafka-logs-102/merged-numbers-1.f5f13aab3b3b462f9950b01d294e7ee3-delete. (kafka.log.LogManager)
[2024-08-26 15:59:33,140] INFO [LocalLog partition=odd-numbers-0, dir=/tmp/kafka-logs-102] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=5398725, lastModifiedTime=1724665802936, largestRecordTimestamp=1724665802936) (kafka.log.LocalLog)
[2024-08-26 15:59:33,144] INFO [LocalLog partition=odd-numbers-0, dir=/tmp/kafka-logs-102] Deleting segment files LogSegment(baseOffset=0, size=5398725, lastModifiedTime=1724665802936, largestRecordTimestamp=1724665802936) (kafka.log.LocalLog$)
[2024-08-26 15:59:33,181] INFO Deleted log /tmp/kafka-logs-102/odd-numbers-0.31967729a88e41f9a4bfcd48a45b5630-delete/00000000000000000000.log.deleted. (org.apache.kafka.storage.internals.log.LogSegment)
[2024-08-26 15:59:33,182] INFO Deleted offset index /tmp/kafka-logs-102/odd-numbers-0.31967729a88e41f9a4bfcd48a45b5630-delete/00000000000000000000.index.deleted. (org.apache.kafka.storage.internals.log.LogSegment)
[2024-08-26 15:59:33,182] INFO Deleted time index /tmp/kafka-logs-102/odd-numbers-0.31967729a88e41f9a4bfcd48a45b5630-delete/00000000000000000000.timeindex.deleted. (org.apache.kafka.storage.internals.log.LogSegment)
[2024-08-26 15:59:33,182] INFO Deleted log for partition odd-numbers-0 in /tmp/kafka-logs-102/odd-numbers-0.31967729a88e41f9a4bfcd48a45b5630-delete. (kafka.log.LogManager)
[2024-08-26 15:59:33,427] INFO [LocalLog partition=numbers-2, dir=/tmp/kafka-logs-102] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=26776202, lastModifiedTime=1724666474288, largestRecordTimestamp=1724666474288) (kafka.log.LocalLog)
[2024-08-26 15:59:33,428] INFO [LocalLog partition=numbers-2, dir=/tmp/kafka-logs-102] Deleting segment files LogSegment(baseOffset=0, size=26776202, lastModifiedTime=1724666474288, largestRecordTimestamp=1724666474288) (kafka.log.LocalLog$)
[2024-08-26 15:59:33,724] INFO Deleted log /tmp/kafka-logs-102/numbers-2.8a790f2661b84008ae56d7c414271d87-delete/00000000000000000000.log.deleted. (org.apache.kafka.storage.internals.log.LogSegment)
[2024-08-26 15:59:33,726] INFO Deleted offset index /tmp/kafka-logs-102/numbers-2.8a790f2661b84008ae56d7c414271d87-delete/00000000000000000000.index.deleted. (org.apache.kafka.storage.internals.log.LogSegment)
[2024-08-26 15:59:33,728] INFO Deleted time index /tmp/kafka-logs-102/numbers-2.8a790f2661b84008ae56d7c414271d87-delete/00000000000000000000.timeindex.deleted. (org.apache.kafka.storage.internals.log.LogSegment)
[2024-08-26 15:59:33,729] INFO Deleted log for partition numbers-2 in /tmp/kafka-logs-102/numbers-2.8a790f2661b84008ae56d7c414271d87-delete. (kafka.log.LogManager)
[2024-08-26 15:59:34,414] INFO [ReplicaFetcherManager on broker 102] Removed fetcher for partitions Set(streams-client-KSTREAM-AGGREGATE-STATE-STORE-0000000002-repartition-2) (kafka.server.ReplicaFetcherManager)
[2024-08-26 15:59:34,418] INFO [LogLoader partition=streams-client-KSTREAM-AGGREGATE-STATE-STORE-0000000002-repartition-2, dir=/tmp/kafka-logs-102] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-08-26 15:59:34,419] INFO Created log for partition streams-client-KSTREAM-AGGREGATE-STATE-STORE-0000000002-repartition-2 in /tmp/kafka-logs-102/streams-client-KSTREAM-AGGREGATE-STATE-STORE-0000000002-repartition-2 with properties {cleanup.policy=delete, message.timestamp.type="CreateTime", retention.ms=-1, segment.bytes=52428800} (kafka.log.LogManager)
[2024-08-26 15:59:34,419] INFO [Partition streams-client-KSTREAM-AGGREGATE-STATE-STORE-0000000002-repartition-2 broker=102] No checkpointed highwatermark is found for partition streams-client-KSTREAM-AGGREGATE-STATE-STORE-0000000002-repartition-2 (kafka.cluster.Partition)
[2024-08-26 15:59:34,419] INFO [Partition streams-client-KSTREAM-AGGREGATE-STATE-STORE-0000000002-repartition-2 broker=102] Log loaded for partition streams-client-KSTREAM-AGGREGATE-STATE-STORE-0000000002-repartition-2 with initial high watermark 0 (kafka.cluster.Partition)
[2024-08-26 15:59:34,842] INFO [ReplicaFetcherManager on broker 102] Removed fetcher for partitions Set(streams-client-KSTREAM-AGGREGATE-STATE-STORE-0000000002-changelog-2) (kafka.server.ReplicaFetcherManager)
[2024-08-26 15:59:34,846] INFO [LogLoader partition=streams-client-KSTREAM-AGGREGATE-STATE-STORE-0000000002-changelog-2, dir=/tmp/kafka-logs-102] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-08-26 15:59:34,847] INFO Created log for partition streams-client-KSTREAM-AGGREGATE-STATE-STORE-0000000002-changelog-2 in /tmp/kafka-logs-102/streams-client-KSTREAM-AGGREGATE-STATE-STORE-0000000002-changelog-2 with properties {cleanup.policy=compact, message.timestamp.type="CreateTime"} (kafka.log.LogManager)
[2024-08-26 15:59:34,859] INFO [Partition streams-client-KSTREAM-AGGREGATE-STATE-STORE-0000000002-changelog-2 broker=102] No checkpointed highwatermark is found for partition streams-client-KSTREAM-AGGREGATE-STATE-STORE-0000000002-changelog-2 (kafka.cluster.Partition)
[2024-08-26 15:59:34,873] INFO [Partition streams-client-KSTREAM-AGGREGATE-STATE-STORE-0000000002-changelog-2 broker=102] Log loaded for partition streams-client-KSTREAM-AGGREGATE-STATE-STORE-0000000002-changelog-2 with initial high watermark 0 (kafka.cluster.Partition)
[2024-08-26 15:59:35,198] INFO [TransactionCoordinator id=102] Initialized transactionalId streams-client-1_0 with producerId 1001 and producer epoch 0 on partition __transaction_state-42 (kafka.coordinator.transaction.TransactionCoordinator)
[2024-08-26 15:59:36,787] INFO [TransactionCoordinator id=102] Initialized transactionalId streams-client-0_0 with producerId 1000 and producer epoch 6 on partition __transaction_state-3 (kafka.coordinator.transaction.TransactionCoordinator)
